{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0fOWhqwW-AT",
        "outputId": "a9825051-1226-47c3-9c61-2cb811f10968"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (4.66.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.23.5)\n",
            "Requirement already satisfied: pandas>=0.25 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.5.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25->seaborn) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n"
          ]
        }
      ],
      "source": [
        "!pip install pandas\n",
        "!pip install torch\n",
        "!pip install nltk\n",
        "!pip install tqdm\n",
        "!pip install seaborn\n",
        "!pip install numpy\n",
        "!pip install sklearn\n",
        "!pip install pymorphy2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3wugeOHW-AV",
        "outputId": "34c9d0de-7f16-4e57-b8ca-9b046dc89cbb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9XIrxSmW-AX"
      },
      "source": [
        "# Скачиваем данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep1FB3IBW-AY",
        "outputId": "7daf792c-f61e-4891-9909-256d8c01a86b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-12-09 14:59:25--  https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 28717126 (27M) [text/plain]\n",
            "Saving to: ‘answers_subsample.csv’\n",
            "\n",
            "answers_subsample.c 100%[===================>]  27.39M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2023-12-09 14:59:25 (412 MB/s) - ‘answers_subsample.csv’ saved [28717126/28717126]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/semensorokin/DLforNLP_course_material/master/Homework2/answers_subsample.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWA7IClKW-Aa"
      },
      "outputs": [],
      "source": [
        "# если ругается на то, что нет wget\n",
        "# !apt-get install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJpFTPpsW-Ac",
        "outputId": "f6201f97-4460-489e-f77d-72696ee39326"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 28052\n",
            "-rw-r--r-- 1 root root 28717126 Dec  9 14:59 answers_subsample.csv\n",
            "drwxr-xr-x 1 root root     4096 Dec  4 14:27 sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmzaEwy9W-Ae"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbDKxq4EW-Ag"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('answers_subsample.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "hcAdsbS7W-Ai",
        "outputId": "0c2a42a4-4a54-4bdb-fda7-9ed6647d3185"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-80089a09-710b-4fa8-843a-e539f7124322\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>law</td>\n",
              "      <td>Может ли срочник перевестись на контракт после...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>law</td>\n",
              "      <td>часть 1 статья 158 похитил телефон</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237774</th>\n",
              "      <td>relax</td>\n",
              "      <td>елку нарядили? =)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237775</th>\n",
              "      <td>law</td>\n",
              "      <td>Имеется переработка при 75% ставки, отгулы не ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237776</th>\n",
              "      <td>food</td>\n",
              "      <td>Попробовала варить рис с половиной кубика для ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237777</th>\n",
              "      <td>food</td>\n",
              "      <td>Почему рекоменд... Почему рекомендуют есть фру...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237778</th>\n",
              "      <td>business</td>\n",
              "      <td>Подскажите какие риски бывают в семье среднест...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>237779 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80089a09-710b-4fa8-843a-e539f7124322')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-80089a09-710b-4fa8-843a-e539f7124322 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-80089a09-710b-4fa8-843a-e539f7124322');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-e785bf2a-6741-470f-850c-e465b3c9a2b5\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e785bf2a-6741-470f-850c-e465b3c9a2b5')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-e785bf2a-6741-470f-850c-e465b3c9a2b5 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "        category                                               text\n",
              "0       business  Могут ли в россельхозбанке дать в залог норков...\n",
              "1            law  Может ли срочник перевестись на контракт после...\n",
              "2       business  Продажа недвижимости по ипотеки ? ( арестованы...\n",
              "3       business  В чем смысл криптовалюты, какая от неё выгода ...\n",
              "4            law                 часть 1 статья 158 похитил телефон\n",
              "...          ...                                                ...\n",
              "237774     relax                                  елку нарядили? =)\n",
              "237775       law  Имеется переработка при 75% ставки, отгулы не ...\n",
              "237776      food  Попробовала варить рис с половиной кубика для ...\n",
              "237777      food  Почему рекоменд... Почему рекомендуют есть фру...\n",
              "237778  business  Подскажите какие риски бывают в семье среднест...\n",
              "\n",
              "[237779 rows x 2 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90tXLjfsW-Aj",
        "outputId": "f8ad418b-6bba-49a0-ac3c-d80778edc806"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "law         29.793211\n",
              "relax       22.016242\n",
              "business    19.309527\n",
              "food        18.367055\n",
              "love        10.513965\n",
              "Name: category, dtype: float64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.category.value_counts() * 100 / data.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfHbifWIW-Al"
      },
      "source": [
        "# Предобученные эмбеддинги\n",
        "[Источник](https://fasttext.cc/docs/en/crawl-vectors.html)  \n",
        "Вы можете взять любые word2vec подобные эмббединги. Если вы хотите использовать elmo, bert, etc сначала попробуйте с word2vec подобными эмббедингами, а потом можете перейти к более сложным моделям.  \n",
        "Ниже мы сначала скачиваем, а потом распоковываем эмбеддинги."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVhCzM3LW-Al",
        "outputId": "9926ed6b-e15f-447c-fc4d-66eedf31afbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-12-09 15:00:05--  https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 52.84.251.106, 52.84.251.15, 52.84.251.114, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|52.84.251.106|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1306357571 (1.2G) [binary/octet-stream]\n",
            "Saving to: ‘cc.ru.300.vec.gz’\n",
            "\n",
            "cc.ru.300.vec.gz    100%[===================>]   1.22G   198MB/s    in 8.5s    \n",
            "\n",
            "2023-12-09 15:00:13 (146 MB/s) - ‘cc.ru.300.vec.gz’ saved [1306357571/1306357571]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.vec.gz\n",
        "!gzip -d cc.ru.300.vec.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eJcT1qPZW-An",
        "outputId": "ac7d0440-393e-4d23-bc51-cb7bb218d4a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total 4458144\n",
            "-rw-r--r-- 1 root root   28717126 Dec  9 14:59 answers_subsample.csv\n",
            "-rw-r--r-- 1 root root 4536408847 Jan 18  2019 cc.ru.300.vec\n",
            "drwxr-xr-x 1 root root       4096 Dec  4 14:27 sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0lwyZUFW-Ap"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQpX51Y4W-Aq"
      },
      "outputs": [],
      "source": [
        "# потом можете добавить свою предобработку\n",
        "\n",
        "def process_text(text):\n",
        "\n",
        "    words = wordpunct_tokenize(text.lower())\n",
        "\n",
        "    return words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyI2erCDW-Ar",
        "outputId": "0864a0f5-8251-468c-f584-7639424389e4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 237779/237779 [00:02<00:00, 94395.84it/s]\n"
          ]
        }
      ],
      "source": [
        "word2freq = {}\n",
        "lengths = []\n",
        "\n",
        "for text in tqdm(data.text):\n",
        "\n",
        "    words = process_text(text)\n",
        "\n",
        "    lengths.append(len(words))\n",
        "\n",
        "    for word in words:\n",
        "\n",
        "        if word in word2freq:\n",
        "            word2freq[word] += 1\n",
        "        else:\n",
        "            word2freq[word] = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGzDm0ptW-At"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "id": "iZBR-aYDW-Av",
        "outputId": "98a86d4e-09fa-4a4f-ae91-530eaac3e53b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-15-71ec2d8d2434>:5: UserWarning: \n",
            "\n",
            "`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
            "\n",
            "Please adapt your code to use either `displot` (a figure-level function with\n",
            "similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "\n",
            "For a guide to updating your code to use the new functions, please see\n",
            "https://gist.github.com/mwaskom/de44147ed2974457ad6372750bbe5751\n",
            "\n",
            "  sns.distplot(lengths)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Axes: title={'center': 'Распределение длин слов в текстах'}, xlabel='Длина предложения', ylabel='Доля'>"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1600x1000 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.figure(figsize=(16, 10))\n",
        "plt.title('Распределение длин слов в текстах')\n",
        "plt.xlabel('Длина предложения')\n",
        "plt.ylabel('Доля')\n",
        "sns.distplot(lengths)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "OBzmPqXIW-Aw",
        "outputId": "84371cc5-93d9-4b05-f4ae-95528889e88e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'99.66 % наших текстов входят в промежуток от 3 до 32 слов'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "upper_threshold = 32\n",
        "lower_threshold = 3\n",
        "\n",
        "correct_percent = len([sent_len for sent_len in lengths\n",
        "                       if sent_len <= upper_threshold and sent_len >= lower_threshold]) * 100 / len(lengths)\n",
        "\n",
        "'{:.2f} % наших текстов входят в промежуток от {} до {} слов'.format(correct_percent, lower_threshold, upper_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbSer_0bW-Ay",
        "outputId": "63c7d130-1fe1-4426-ba88-26109dc25226"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "152179"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(word2freq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "szg6XD3EW-Az",
        "outputId": "d580f0bf-ebe8-44d6-c8fd-a1eda939ff88"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'114332 слов, которые встречались 3 и менее раз'"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'{} слов, которые встречались 3 и менее раз'.format(len([word for word in word2freq if word2freq[word] <= 3]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bZbOg0FqW-A1"
      },
      "source": [
        "# Читаем файл с эмбеддингами\n",
        "### Этот файл с 300 числами для 2 000 000 слов и он может не влезть в память\n",
        "Поэтому прочитаем только те слова, которые мы знаем"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1Yx_qr-W-A2"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLEgfnaWW-A4",
        "outputId": "8f85b41d-7b43-452e-a8d8-198496b53c69"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Read word2vec: 100%|██████████| 2000000/2000000 [01:14<00:00, 27014.94it/s]\n"
          ]
        }
      ],
      "source": [
        "word2index = {'PAD': 0}\n",
        "vectors = []\n",
        "\n",
        "word2vec_file = open('cc.ru.300.vec')\n",
        "\n",
        "n_words, embedding_dim = word2vec_file.readline().split()\n",
        "n_words, embedding_dim = int(n_words), int(embedding_dim)\n",
        "\n",
        "# Zero vector for PAD\n",
        "vectors.append(np.zeros((1, embedding_dim)))\n",
        "\n",
        "progress_bar = tqdm(desc='Read word2vec', total=n_words)\n",
        "\n",
        "while True:\n",
        "\n",
        "    line = word2vec_file.readline().strip()\n",
        "\n",
        "    if not line:\n",
        "        break\n",
        "\n",
        "    current_parts = line.split()\n",
        "\n",
        "    current_word = ' '.join(current_parts[:-embedding_dim])\n",
        "\n",
        "    if current_word in word2freq:\n",
        "\n",
        "        word2index[current_word] = len(word2index)\n",
        "\n",
        "        current_vectors = current_parts[-embedding_dim:]\n",
        "        current_vectors = np.array(list(map(float, current_vectors)))\n",
        "        current_vectors = np.expand_dims(current_vectors, 0)\n",
        "\n",
        "        vectors.append(current_vectors)\n",
        "\n",
        "    progress_bar.update(1)\n",
        "\n",
        "progress_bar.close()\n",
        "\n",
        "word2vec_file.close()\n",
        "\n",
        "vectors = np.concatenate(vectors)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYJMzgpnW-A7",
        "outputId": "f3d7d3a9-5ac9-45d1-fd47-f924fee591ae"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "117619"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(word2index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KE06fafiW-A8",
        "outputId": "b305f534-d543-4c10-a5f2-ca64f41e7d8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Мы не знаем 2.50 % слов в датасете\n",
            "Количество неизвестных слов 34561 из 152179, то есть 22.71 % уникальных слов в словаре\n",
            "В среднем каждое встречается 1.98 раз\n",
            "\n",
            "Топ 5 невошедших слов:\n",
            "??? с количеством вхождениий - 3641\n",
            "?? с количеством вхождениий - 2448\n",
            "!!! с количеством вхождениий - 2214\n",
            "?) с количеством вхождениий - 2069\n",
            "\"? с количеством вхождениий - 1429\n"
          ]
        }
      ],
      "source": [
        "unk_words = [word for word in word2freq if word not in word2index]\n",
        "unk_counts = [word2freq[word] for word in unk_words]\n",
        "n_unk = sum(unk_counts) * 100 / sum(list(word2freq.values()))\n",
        "\n",
        "sub_sample_unk_words = {word: word2freq[word] for word in unk_words}\n",
        "sorted_unk_words = list(sorted(sub_sample_unk_words, key=lambda x: sub_sample_unk_words[x], reverse=True))\n",
        "\n",
        "print('Мы не знаем {:.2f} % слов в датасете'.format(n_unk))\n",
        "print('Количество неизвестных слов {} из {}, то есть {:.2f} % уникальных слов в словаре'.format(\n",
        "    len(unk_words), len(word2freq), len(unk_words) * 100 / len(word2freq)))\n",
        "print('В среднем каждое встречается {:.2f} раз'.format(np.mean(unk_counts)))\n",
        "print()\n",
        "print('Топ 5 невошедших слов:')\n",
        "\n",
        "for i in range(5):\n",
        "    print(sorted_unk_words[i], 'с количеством вхождениий -', word2freq[sorted_unk_words[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFPNApUjW-A9"
      },
      "source": [
        "# Потеря 2.5 % слов в датасете\n",
        "Эта ситуация не то, чтобы сильно плохая, в учебных целях нормально, к тому же в среднем они редко встречаются. Вы можете поиграть с предобработкой."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fo1fB6JW-A-"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEKAjCg3W-BA"
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D19pDyQBW-BA"
      },
      "outputs": [],
      "source": [
        "x = torch.rand(128, 64, 1024)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yxsxr7edW-BB"
      },
      "outputs": [],
      "source": [
        "lstm = torch.nn.LSTM(1024, 512, batch_first=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZy0lKr2W-BC",
        "outputId": "59abc315-0b24-4002-fc4e-b65200a54d34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "929 ms ± 176 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "pred = lstm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s611e34SW-BE"
      },
      "source": [
        "# А что GPU?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjFlWdgtW-BE",
        "outputId": "b19f605b-af6a-49fc-f678-458db472b80e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Доступна ли видеокарта: True\n",
            "Если недоступна, поменяйте runtime, если в колабе\n"
          ]
        }
      ],
      "source": [
        "print('Доступна ли видеокарта:', torch.cuda.is_available())\n",
        "print('Если недоступна, поменяйте runtime, если в колабе')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jaMMD5CDW-BG"
      },
      "outputs": [],
      "source": [
        "# универсальных способ задать device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "# если доступна gpu, то давайте ее использовать, но в этом задании должны использовать"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GeQCiSYdW-BH"
      },
      "outputs": [],
      "source": [
        "# перенесли x на gpu\n",
        "x_gpu = x.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_qUdMcbW-BJ"
      },
      "outputs": [],
      "source": [
        "# зададим lstm на gpu\n",
        "lstm_gpu = torch.nn.LSTM(1024, 512, batch_first=True)\n",
        "lstm_gpu = lstm_gpu.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hSUQmRgtW-BK",
        "outputId": "df428791-654f-4b71-b839-5794f201a422"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The slowest run took 26.70 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "9.21 ms ± 9.91 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit\n",
        "\n",
        "pred = lstm_gpu(x_gpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPvqNWkQW-BM"
      },
      "source": [
        "# У меня на 1070 TI скорость уменьшилась с 381мс до 41мс, то есть в 9.29 раз"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaPKGO5aW-BN"
      },
      "outputs": [],
      "source": [
        "# если у нас модель на гпу, а то, что мы туда подаем нет, то работать не будет\n",
        "# справедлива и обратная ситуация\n",
        "\n",
        "# выскочит ошибка\n",
        "# посмотрите на нее, возможно, вы еще встретитесь\n",
        "# pred = lstm_gpu(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NX5HHDOW-BO"
      },
      "source": [
        "# Важные и не очень интуитивные моменты про LSTM и CNN в торче"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKr22rklW-BP"
      },
      "source": [
        "По умолчанию LSTM принимает данные с такой размерностью:\n",
        "```python\n",
        "(seq_len, batch, input_size)\n",
        "```\n",
        "Сделано это с целью оптимизации на более низком уровне.  \n",
        "Мы оперируем такими объектами:\n",
        "```python\n",
        "(batch, seq_len, input_size)\n",
        "```\n",
        "Чтобы LSTM у нас заработала правильно, мы можем либо передать параметр ```batch_first=True``` во время инициализации слоя,\n",
        "либо транспонировать (поменять) первую и вторую размерность у нашего x перед подачей в слой.  \n",
        "[Подробнее про LSTM](https://pytorch.org/docs/stable/nn.html#lstm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bny8SvCgW-BQ"
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vc-bLok2W-BQ"
      },
      "outputs": [],
      "source": [
        "# первый способ\n",
        "lstm = torch.nn.LSTM(1024, 512, batch_first=True)\n",
        "\n",
        "pred, mem = lstm(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHpit-1tW-BR",
        "outputId": "7e561938-a9d4-44ff-884d-746566f6d33b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 512])"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ru_WzGSJW-BS"
      },
      "outputs": [],
      "source": [
        "lstm = torch.nn.LSTM(1024, 512)\n",
        "\n",
        "# меняем размерность batch и seq_len местами\n",
        "x_transposed = x.transpose(0, 1)\n",
        "pred_transposed, mem = lstm(x_transposed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHdBavTWW-BT",
        "outputId": "52559f89-8288-48a3-cab8-1bac1a40330a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([64, 128, 512])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# у нас все еще осталась размерность (seq_len, batch, input_size)\n",
        "pred_transposed.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rcxv55j7W-BV",
        "outputId": "700c7f7e-9ad2-41f5-e557-cf549bac549a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 512])"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# просто транспонируем еще раз\n",
        "pred = pred_transposed.transpose(0, 1)\n",
        "pred.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PmJt6cqkW-BW"
      },
      "source": [
        "## Conv1d & MaxPool1d\n",
        "Примерно такая же ситуация происходит со сверточными слоями и пулингами.  \n",
        "1d реализация как раз для текстов, в ней матрица-фильтр ходит только по одной размерности.  \n",
        "[Подробнее про CNN](https://pytorch.org/docs/stable/nn.html#conv1d)  \n",
        "[Подробнее про пулинг](https://pytorch.org/docs/stable/nn.html#maxpool1d)  \n",
        "Ожидается такая размерность:\n",
        "```python\n",
        "(batch, input_size, seq_len)\n",
        "```\n",
        "Мы все еще хоти подавать такую размерность:\n",
        "```python\n",
        "(batch, seq_len, input_size)\n",
        "```\n",
        "В случае со свертками и пулингами у нас есть вариант только транспонировать x перед подачей и транспонировать полученный результат. Обратите внимание, что транспонируем мы первую и вторую размерность (индексация с нуля)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TyM8Xl24W-BX",
        "outputId": "ebdf531e-8500-4bb8-d2fb-a5edac1cdb4b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 1024])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "grPNMjEZW-BY"
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - количество слов\n",
        "- 1024 - эмбеддинг слова"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "btJ-ApiOW-BY"
      },
      "outputs": [],
      "source": [
        "# in_channels - размер входных эмбеддингов\n",
        "# out_channels - количество/какой размер эмбеддингов мы хотим получить\n",
        "# kernel_size - размер окна/н-граммы\n",
        "cnn = torch.nn.Conv1d(in_channels=1024, out_channels=512, kernel_size=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIYff7YyW-Bb"
      },
      "outputs": [],
      "source": [
        "# выпадет ошибка, посмотрите какая\n",
        "# pred = cnn(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tVn6YKLW-Bd",
        "outputId": "19e1f934-7656-47e5-b325-aee4b5cc295b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128, 1024, 64])"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_transposed = x.transpose(1, 2)\n",
        "x_transposed.shape\n",
        "# перевели в (batch, input_size, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N4w6-iWW-Be",
        "outputId": "6a0900b0-f8d7-43f2-c7f8-2cc4af8932c9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128, 512, 62])"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred_transposed = cnn(x_transposed)\n",
        "pred_transposed.shape\n",
        "# осталась разрмерность (batch, output_size, seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7-C3_phaW-Bf",
        "outputId": "cca01e37-6f4f-43fa-ae08-fa4d15660e37"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([128, 62, 512])"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# переведем обратно в (batch, seq_len, input_size)\n",
        "pred = pred_transposed.transpose(1, 2)\n",
        "pred.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "stBQ3yhqW-Bi"
      },
      "source": [
        "# Подготовим данные в DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPX_m5M4W-Bi"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hV76BdN0W-Bj",
        "outputId": "af1c4407-b23d-47df-a822-f2891a6df721"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "'UNK' in word2index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "INB_dPAnW-Bk",
        "outputId": "8e6f481c-0427-455d-fedb-7398a74db83c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-967235b5-2316-423f-ab32-334bcb107824\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>business</td>\n",
              "      <td>Могут ли в россельхозбанке дать в залог норков...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>law</td>\n",
              "      <td>Может ли срочник перевестись на контракт после...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>business</td>\n",
              "      <td>Продажа недвижимости по ипотеки ? ( арестованы...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>business</td>\n",
              "      <td>В чем смысл криптовалюты, какая от неё выгода ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>law</td>\n",
              "      <td>часть 1 статья 158 похитил телефон</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-967235b5-2316-423f-ab32-334bcb107824')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-967235b5-2316-423f-ab32-334bcb107824 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-967235b5-2316-423f-ab32-334bcb107824');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c05c1618-ba5a-4fd9-acac-1fd12f9f1eac\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c05c1618-ba5a-4fd9-acac-1fd12f9f1eac')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c05c1618-ba5a-4fd9-acac-1fd12f9f1eac button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   category                                               text\n",
              "0  business  Могут ли в россельхозбанке дать в залог норков...\n",
              "1       law  Может ли срочник перевестись на контракт после...\n",
              "2  business  Продажа недвижимости по ипотеки ? ( арестованы...\n",
              "3  business  В чем смысл криптовалюты, какая от неё выгода ...\n",
              "4       law                 часть 1 статья 158 похитил телефон"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qv1mKAeW-Bl"
      },
      "source": [
        "# Замапим категории в индексы"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHeFzZe1W-Bl"
      },
      "outputs": [],
      "source": [
        "cat_mapper = {cat: n for n, cat in enumerate(data.category.unique())}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3x9QhXYW-Bn",
        "outputId": "57cdc02f-2d98-4be0-9409-4a1c0784c91f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'business': 0, 'law': 1, 'love': 2, 'relax': 3, 'food': 4}"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cat_mapper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ef--8SWbW-Bo"
      },
      "outputs": [],
      "source": [
        "data.category = data.category.map(cat_mapper)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc48ALg_W-Bp"
      },
      "source": [
        "# Читалка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WFIQEv6nvE4c"
      },
      "source": [
        "## Что происходит ниже\n",
        "1. Мы задаем x_data, y_data (таргеты), word2index (маппер из слова в индекс слова), sequence_length (максимальная длина последовательности, если больше, ограничить ею), pad_token (токен паддинга и задаем его индекс pad_index).\n",
        "1. Загружаем данные:\n",
        "    1. Проходимся по датасету\n",
        "    1. Предобрабатываем каждый текст в датасете\n",
        "    1. Индексируем его\n",
        "    1. Паддим до нужной длины\n",
        "1. Когда нам нужно достать пример из датасета мы берем индексированный ```x``` и соответствующий этому индексу ```y```, наш ```x``` также паддим (или ограничиваем длину) и переводим в ```torch.Tensor(x).long()```. Для ```y``` этого делать не потребуется, в dataloader'е таргеты преобразуются в тензор сами.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zsq2ydh0K8aZ",
        "outputId": "a235e95e-aa60-4133-cc65-869162d679e4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xu-Y2Vb4J9YO"
      },
      "outputs": [],
      "source": [
        "import pymorphy2\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "morph = pymorphy2.MorphAnalyzer()\n",
        "stops = stopwords.words('russian')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkX8SC_sW-Bp"
      },
      "outputs": [],
      "source": [
        "class WordData(Dataset):\n",
        "\n",
        "    def __init__(self, x_data, y_data, word2index, sequence_length=32, pad_token='PAD', verbose=True):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.x_data = []\n",
        "        self.y_data = y_data\n",
        "\n",
        "        self.word2index = word2index\n",
        "        self.sequence_length = sequence_length\n",
        "\n",
        "        self.pad_token = pad_token\n",
        "        self.pad_index = self.word2index[self.pad_token]\n",
        "\n",
        "        self.load(x_data, verbose=verbose)\n",
        "\n",
        "    @staticmethod\n",
        "    def process_text(text): #предобработка текста\n",
        "      lemmas = []\n",
        "      for word in word_tokenize(text):\n",
        "          if word.isalpha():\n",
        "              word = morph.parse(word.lower())[0]\n",
        "              lemma = word.normal_form\n",
        "              if lemma not in stops:\n",
        "                  lemmas.append(lemma)\n",
        "      return ' '.join(lemmas)\n",
        "\n",
        "    def load(self, data, verbose=True):\n",
        "\n",
        "        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n",
        "\n",
        "        for text in data_iterator:\n",
        "\n",
        "            words = self.process_text(text)\n",
        "\n",
        "            indexed_words = self.indexing(words)\n",
        "\n",
        "            self.x_data.append(indexed_words)\n",
        "\n",
        "    def indexing(self, tokenized_text):\n",
        "\n",
        "        # здесь мы не используем токен UNK, потому что мы его специально не учили\n",
        "        # становится непонятно какой же эмбеддинг присвоить неизвестному слову,\n",
        "        # поэтому просто выбрасываем наши неизветсные слова\n",
        "\n",
        "        return [self.word2index[word] for word in tokenized_text if word in self.word2index]\n",
        "\n",
        "    def padding(self, sequence):\n",
        "\n",
        "        # Ограничить длину self.sequence_length\n",
        "        # если длина меньше максимально - западить\n",
        "        if len(sequence)< self.sequence_length:\n",
        "          add_pad = self.sequence_length - len(sequence)\n",
        "          return sequence+[self.pad_index]*add_pad\n",
        "        else:\n",
        "          return sequence[:self.sequence_length]\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return len(self.x_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        x = self.x_data[idx]\n",
        "        x = self.padding(x)\n",
        "        x = torch.Tensor(x).long()\n",
        "\n",
        "        y = self.y_data[idx]\n",
        "\n",
        "        return x, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3WW8V9lyLm0"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lnc2nD8gW-Br",
        "outputId": "8ff269f3-adae-4d03-e4ba-a1a7bfdfa007"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading data: 100%|██████████| 214001/214001 [09:17<00:00, 383.75it/s]\n",
            "Loading data: 100%|██████████| 23778/23778 [01:02<00:00, 381.07it/s]\n"
          ]
        }
      ],
      "source": [
        "x_train, x_validation, y_train, y_validation = train_test_split(data.text, data.category, test_size=0.1)\n",
        "\n",
        "train_dataset = WordData(list(x_train), list(y_train), word2index)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64)\n",
        "\n",
        "validation_dataset = WordData(list(x_validation), list(y_validation), word2index)\n",
        "validation_loader = DataLoader(validation_dataset, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGeftxdgW-Br"
      },
      "outputs": [],
      "source": [
        "for x, y in train_loader:\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNkGQffBW-Bs",
        "outputId": "398a7823-7e04-4982-9a05-eba5ce6b11ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 528, 1900,  585,  ..., 5173, 4467, 1582],\n",
              "        [   4,   30,  528,  ...,    0,    0,    0],\n",
              "        [ 528, 1900,  585,  ...,   30,   10,  604],\n",
              "        ...,\n",
              "        [  10,   23,   30,  ...,  528,   26, 1041],\n",
              "        [ 585,   26,   10,  ...,    0,    0,    0],\n",
              "        [  23,   26,  202,  ...,    0,    0,    0]])"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxUk4nGcW-Bt",
        "outputId": "9e99301d-523e-493f-9dc2-0ec260e8648f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([1, 0, 0, 0, 0, 1, 3, 1, 1, 2, 3, 1, 3, 1, 4, 1, 3, 4, 1, 1, 4, 0, 3, 1,\n",
              "        3, 3, 1, 0, 1, 1, 0, 1, 3, 0, 3, 4, 3, 1, 2, 2, 0, 1, 2, 4, 1, 0, 2, 0,\n",
              "        3, 2, 1, 3, 1, 1, 3, 3, 2, 3, 3, 1, 0, 4, 1, 1])"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy0dkkTIW-Bw"
      },
      "source": [
        "# Обучить нейронку"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3wwkxZm1vE43"
      },
      "outputs": [],
      "source": [
        "from math import sqrt\n",
        "\n",
        "class model_with_att(torch.nn.Module):\n",
        "  def __init__(self, matrix_w, n, hidden_size=300): #n - количетсво категорий\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        self.n = n\n",
        "\n",
        "        self.emb_layer = torch.nn.Embedding.from_pretrained(torch.Tensor(matrix_w))\n",
        "\n",
        "        # задайте лстм, можно 2 уровня, лучше бидирекциональный, в доке торча есть инофрмация как это сделать в одну строчку\n",
        "        self.LSTM = torch.nn.LSTM(input_size = self.emb_layer.embedding_dim, hidden_size = hidden_size, num_layers = 2, bidirectional = True)\n",
        "\n",
        "        # три линейных преобразования, размерность совпадает с выходом из лстм (если БИлстм то надо умножить ее на 2)\n",
        "        self.q_proj = torch.nn.Linear(hidden_size*2, hidden_size*2)\n",
        "        self.k_proj = torch.nn.Linear(hidden_size*2, hidden_size*2)\n",
        "        self.v_proj = torch.nn.Linear(hidden_size*2, hidden_size*2)\n",
        "\n",
        "        self.att_soft = torch.nn.Softmax(dim = 2)\n",
        "\n",
        "        # три конволюционных фильтра с разными ядрами (3,4,5) чтобы были всякие нграммы ловить\n",
        "        self.cnn_3gr = torch.nn.Conv1d(hidden_size*2, hidden_size, 3)\n",
        "        self.cnn_4gr = torch.nn.Conv1d(hidden_size*2, hidden_size, 4)\n",
        "        self.cnn_5gr = torch.nn.Conv1d(hidden_size*2, hidden_size, 5)\n",
        "\n",
        "        # сверху накидываем два полносвязных слоя для классификации\n",
        "        self.linear_1 = torch.nn.Linear(hidden_size*3, hidden_size)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.linear_2 = torch.nn.Linear(hidden_size, out_features=n)\n",
        "\n",
        "\n",
        "  def forward(self, x):\n",
        "      x_emb = self.emb_layer(x) #применим эмбеддинги\n",
        "      x_emb = x_emb.transpose(0, 1) # транспонируем тензор для лстм как было описано выше\n",
        "      x, _ = self.LSTM(x_emb) # применим лстм, не забываем что на выходе у него много всяких последовательностей, нам нужна только эта\n",
        "      x.transpose(1, 0) # транспонируем обратно\n",
        "\n",
        "      x_q = self.q_proj(x) #применим линейные преобразования для селф-эттеншена\n",
        "      x_k = self.k_proj(x)\n",
        "      x_v = self.v_proj(x)\n",
        "\n",
        "      att_scores = torch.bmm(x_q, x_k.transpose(1, 2)) / np.sqrt(x_q.shape[-1])\n",
        "      # посмотрите в презентацию и перемножьте нужные тензора изспольуя функцию bmm из торча, перед этим одну из матриц обзательно транспонируйте\n",
        "      # результат обязательно поделите на корень из последней размерности (то есть на рземер эмбеддинга из предыдущего слоя)\n",
        "      att_dist = self.att_soft(att_scores) # накидываем софтмакс\n",
        "      attention_vectors = torch.bmm(att_dist, x_v) # тут тоже что то с чем то нужно перемножить :)\n",
        "\n",
        "      x_att = attention_vectors.transpose(2,1) #транспонируем для конфолючионнах фильтров\n",
        "\n",
        "      x_cnn3 = self.cnn_3gr(x_att)\n",
        "      x_cnn4 = self.cnn_4gr(x_att)\n",
        "      x_cnn5 = self.cnn_5gr(x_att)\n",
        "\n",
        "      frst, _ =  x_cnn3.max(dim= -1,) # cделаем макс пуллинг\n",
        "      sc, _ = x_cnn4.max(dim= -1,)\n",
        "      thr, _ = x_cnn5.max(dim= -1,)\n",
        "\n",
        "      x_cat = torch.cat((frst, sc, thr), dim=-1) # а теперь объединим результаты\n",
        "\n",
        "      # пару полносвязных слоев с релу для классификации\n",
        "      x = self.linear_1(x_cat)\n",
        "      x = self.relu(x)\n",
        "      x = self.linear_2(x)\n",
        "\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFbyUXLE0WPv"
      },
      "outputs": [],
      "source": [
        "n_classes = data.category.unique().shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OZgh4ONx0HvT"
      },
      "outputs": [],
      "source": [
        "model = model_with_att(vectors, n_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNO6VSbJgQ36",
        "outputId": "c699c252-6480-4279-87be-efa00701929a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "model_with_att(\n",
              "  (emb_layer): Embedding(117619, 300)\n",
              "  (LSTM): LSTM(300, 300, num_layers=2, bidirectional=True)\n",
              "  (q_proj): Linear(in_features=600, out_features=600, bias=True)\n",
              "  (k_proj): Linear(in_features=600, out_features=600, bias=True)\n",
              "  (v_proj): Linear(in_features=600, out_features=600, bias=True)\n",
              "  (att_soft): Softmax(dim=2)\n",
              "  (cnn_3gr): Conv1d(600, 300, kernel_size=(3,), stride=(1,))\n",
              "  (cnn_4gr): Conv1d(600, 300, kernel_size=(4,), stride=(1,))\n",
              "  (cnn_5gr): Conv1d(600, 300, kernel_size=(5,), stride=(1,))\n",
              "  (linear_1): Linear(in_features=900, out_features=300, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (linear_2): Linear(in_features=300, out_features=5, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model #если сделать batch_first=True, то можно не транспонировать батчи"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E66MWNgM0QKM"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "    pred = model(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ErboeQbv0dnC",
        "outputId": "d3da2b88-1c5d-4a71-e63f-7683a4043bd8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([32, 5])"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pred.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bL6zIZSt0h9W"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vsxw4M2m0m2B"
      },
      "outputs": [],
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters())\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBQnr0Sqi4F3",
        "outputId": "66527018-9a3d-4ac5-c9ef-3a9df6b3fb65"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2:  44%|████▍     | 94144/214001 [05:03<06:26, 310.01it/s, train_loss=0.661]\n",
            "\n",
            "Epoch 1:   0%|          | 0/107000 [00:01<?, ?it/s, train_loss=0.722]\u001b[A\n",
            "Epoch 1:   0%|          | 32/107000 [00:01<1:07:41, 26.34it/s, train_loss=0.722]\u001b[A\n",
            "Epoch 1:   0%|          | 32/107000 [00:01<1:07:41, 26.34it/s, train_loss=0.698]\u001b[A\n",
            "Epoch 1:   0%|          | 64/107000 [00:01<32:11, 55.36it/s, train_loss=0.698]  \u001b[A\n",
            "Epoch 1:   0%|          | 64/107000 [00:01<32:11, 55.36it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:   0%|          | 96/107000 [00:01<20:11, 88.26it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:   0%|          | 96/107000 [00:01<20:11, 88.26it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:   0%|          | 128/107000 [00:01<20:10, 88.26it/s, train_loss=0.719]\u001b[A\n",
            "Epoch 1:   0%|          | 160/107000 [00:01<11:44, 151.68it/s, train_loss=0.719]\u001b[A\n",
            "Epoch 1:   0%|          | 160/107000 [00:01<11:44, 151.68it/s, train_loss=0.71] \u001b[A\n",
            "Epoch 1:   0%|          | 192/107000 [00:01<11:44, 151.68it/s, train_loss=0.669]\u001b[A\n",
            "Epoch 1:   0%|          | 224/107000 [00:01<08:45, 203.25it/s, train_loss=0.669]\u001b[A\n",
            "Epoch 1:   0%|          | 224/107000 [00:01<08:45, 203.25it/s, train_loss=0.671]\u001b[A\n",
            "Epoch 1:   0%|          | 256/107000 [00:02<08:45, 203.25it/s, train_loss=0.659]\u001b[A\n",
            "Epoch 1:   0%|          | 288/107000 [00:02<07:44, 229.71it/s, train_loss=0.659]\u001b[A\n",
            "Epoch 1:   0%|          | 288/107000 [00:02<07:44, 229.71it/s, train_loss=0.664]\u001b[A\n",
            "Epoch 1:   0%|          | 320/107000 [00:02<07:44, 229.71it/s, train_loss=0.64] \u001b[A\n",
            "Epoch 1:   0%|          | 352/107000 [00:02<06:42, 265.01it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:   0%|          | 352/107000 [00:02<06:42, 265.01it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:   0%|          | 384/107000 [00:02<06:42, 265.01it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:   0%|          | 416/107000 [00:02<05:46, 307.65it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:   0%|          | 416/107000 [00:02<05:46, 307.65it/s, train_loss=0.668]\u001b[A\n",
            "Epoch 1:   0%|          | 448/107000 [00:02<05:46, 307.65it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   0%|          | 480/107000 [00:02<05:21, 331.80it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   0%|          | 480/107000 [00:02<05:21, 331.80it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:   0%|          | 512/107000 [00:02<05:20, 331.80it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:   1%|          | 544/107000 [00:02<04:51, 365.63it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:   1%|          | 544/107000 [00:02<04:51, 365.63it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:   1%|          | 576/107000 [00:02<04:51, 365.63it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   1%|          | 608/107000 [00:02<04:25, 400.46it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   1%|          | 608/107000 [00:02<04:25, 400.46it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:   1%|          | 640/107000 [00:02<04:25, 400.46it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:   1%|          | 672/107000 [00:02<04:04, 434.69it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:   1%|          | 672/107000 [00:02<04:04, 434.69it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:   1%|          | 704/107000 [00:03<04:04, 434.69it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:   1%|          | 736/107000 [00:03<04:19, 409.93it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:   1%|          | 736/107000 [00:03<04:19, 409.93it/s, train_loss=0.658]\u001b[A\n",
            "Epoch 1:   1%|          | 768/107000 [00:03<04:19, 409.93it/s, train_loss=0.667]\u001b[A\n",
            "Epoch 1:   1%|          | 800/107000 [00:03<04:20, 407.12it/s, train_loss=0.667]\u001b[A\n",
            "Epoch 1:   1%|          | 800/107000 [00:03<04:20, 407.12it/s, train_loss=0.67] \u001b[A\n",
            "Epoch 1:   1%|          | 832/107000 [00:03<04:20, 407.12it/s, train_loss=0.675]\u001b[A\n",
            "Epoch 1:   1%|          | 864/107000 [00:03<04:11, 422.25it/s, train_loss=0.675]\u001b[A\n",
            "Epoch 1:   1%|          | 864/107000 [00:03<04:11, 422.25it/s, train_loss=0.673]\u001b[A\n",
            "Epoch 1:   1%|          | 896/107000 [00:03<04:11, 422.25it/s, train_loss=0.668]\u001b[A\n",
            "Epoch 1:   1%|          | 928/107000 [00:03<04:09, 424.37it/s, train_loss=0.668]\u001b[A\n",
            "Epoch 1:   1%|          | 928/107000 [00:03<04:09, 424.37it/s, train_loss=0.675]\u001b[A\n",
            "Epoch 1:   1%|          | 960/107000 [00:03<04:09, 424.37it/s, train_loss=0.67] \u001b[A\n",
            "Epoch 1:   1%|          | 992/107000 [00:03<03:54, 451.40it/s, train_loss=0.67]\u001b[A\n",
            "Epoch 1:   1%|          | 992/107000 [00:03<03:54, 451.40it/s, train_loss=0.667]\u001b[A\n",
            "Epoch 1:   1%|          | 1024/107000 [00:03<03:54, 451.40it/s, train_loss=0.669]\u001b[A\n",
            "Epoch 1:   1%|          | 1056/107000 [00:03<03:38, 485.07it/s, train_loss=0.669]\u001b[A\n",
            "Epoch 1:   1%|          | 1056/107000 [00:03<03:38, 485.07it/s, train_loss=0.667]\u001b[A\n",
            "Epoch 1:   1%|          | 1088/107000 [00:03<03:38, 485.07it/s, train_loss=0.672]\u001b[A\n",
            "Epoch 1:   1%|          | 1120/107000 [00:03<03:32, 499.27it/s, train_loss=0.672]\u001b[A\n",
            "Epoch 1:   1%|          | 1120/107000 [00:03<03:32, 499.27it/s, train_loss=0.671]\u001b[A\n",
            "Epoch 1:   1%|          | 1152/107000 [00:03<03:32, 499.27it/s, train_loss=0.668]\u001b[A\n",
            "Epoch 1:   1%|          | 1184/107000 [00:04<03:29, 505.77it/s, train_loss=0.668]\u001b[A\n",
            "Epoch 1:   1%|          | 1184/107000 [00:04<03:29, 505.77it/s, train_loss=0.664]\u001b[A\n",
            "Epoch 1:   1%|          | 1216/107000 [00:04<03:29, 505.77it/s, train_loss=0.665]\u001b[A\n",
            "Epoch 1:   1%|          | 1248/107000 [00:04<03:22, 521.60it/s, train_loss=0.665]\u001b[A\n",
            "Epoch 1:   1%|          | 1248/107000 [00:04<03:22, 521.60it/s, train_loss=0.667]\u001b[A\n",
            "Epoch 1:   1%|          | 1280/107000 [00:04<03:22, 521.60it/s, train_loss=0.661]\u001b[A\n",
            "Epoch 1:   1%|          | 1312/107000 [00:04<03:18, 532.40it/s, train_loss=0.661]\u001b[A\n",
            "Epoch 1:   1%|          | 1312/107000 [00:04<03:18, 532.40it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:   1%|▏         | 1344/107000 [00:04<03:18, 532.40it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   1%|▏         | 1376/107000 [00:04<03:15, 540.59it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   1%|▏         | 1376/107000 [00:04<03:15, 540.59it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:   1%|▏         | 1408/107000 [00:04<03:15, 540.59it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:   1%|▏         | 1440/107000 [00:04<03:27, 508.59it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:   1%|▏         | 1440/107000 [00:04<03:27, 508.59it/s, train_loss=0.658]\u001b[A\n",
            "Epoch 1:   1%|▏         | 1472/107000 [00:04<03:27, 508.59it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:   1%|▏         | 1504/107000 [00:04<03:34, 492.41it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:   1%|▏         | 1504/107000 [00:04<03:34, 492.41it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   1%|▏         | 1536/107000 [00:04<03:34, 492.41it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:   1%|▏         | 1568/107000 [00:04<03:41, 476.23it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:   1%|▏         | 1568/107000 [00:04<03:41, 476.23it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:   1%|▏         | 1600/107000 [00:04<03:41, 476.23it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:   2%|▏         | 1632/107000 [00:04<03:43, 472.20it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:   2%|▏         | 1632/107000 [00:04<03:43, 472.20it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:   2%|▏         | 1664/107000 [00:05<03:43, 472.20it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:   2%|▏         | 1696/107000 [00:05<03:31, 497.91it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:   2%|▏         | 1696/107000 [00:05<03:31, 497.91it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:   2%|▏         | 1728/107000 [00:05<03:31, 497.91it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:   2%|▏         | 1760/107000 [00:05<03:24, 514.07it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:   2%|▏         | 1760/107000 [00:05<03:24, 514.07it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:   2%|▏         | 1792/107000 [00:05<03:24, 514.07it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:   2%|▏         | 1824/107000 [00:05<03:20, 523.73it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:   2%|▏         | 1824/107000 [00:05<03:20, 523.73it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:   2%|▏         | 1856/107000 [00:05<03:20, 523.73it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:   2%|▏         | 1888/107000 [00:05<03:18, 530.05it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:   2%|▏         | 1888/107000 [00:05<03:18, 530.05it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:   2%|▏         | 1920/107000 [00:05<03:18, 530.05it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:   2%|▏         | 1952/107000 [00:05<03:14, 540.08it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:   2%|▏         | 1952/107000 [00:05<03:14, 540.08it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:   2%|▏         | 1984/107000 [00:05<03:14, 540.08it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2016/107000 [00:05<03:10, 550.19it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2016/107000 [00:05<03:10, 550.19it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2048/107000 [00:05<03:10, 550.19it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2080/107000 [00:05<03:13, 541.68it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2080/107000 [00:05<03:13, 541.68it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2112/107000 [00:05<03:13, 541.68it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2144/107000 [00:05<03:07, 560.45it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2144/107000 [00:05<03:07, 560.45it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2176/107000 [00:05<03:07, 560.45it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2208/107000 [00:05<03:01, 577.05it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2208/107000 [00:05<03:01, 577.05it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2240/107000 [00:06<03:01, 577.05it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2272/107000 [00:06<03:01, 577.05it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2304/107000 [00:06<02:53, 604.50it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2304/107000 [00:06<02:53, 604.50it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2336/107000 [00:06<02:53, 604.50it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2368/107000 [00:06<02:53, 604.50it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2400/107000 [00:06<02:48, 620.45it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2400/107000 [00:06<02:48, 620.45it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2432/107000 [00:06<02:48, 620.45it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2464/107000 [00:06<02:48, 620.45it/s, train_loss=0.64] \u001b[A\n",
            "Epoch 1:   2%|▏         | 2496/107000 [00:06<02:43, 640.14it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2496/107000 [00:06<02:43, 640.14it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2528/107000 [00:06<02:43, 640.14it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2560/107000 [00:06<02:43, 640.14it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2592/107000 [00:06<02:37, 664.14it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2592/107000 [00:06<02:37, 664.14it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2624/107000 [00:06<02:37, 664.14it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   2%|▏         | 2656/107000 [00:06<02:37, 664.14it/s, train_loss=0.64] \u001b[A\n",
            "Epoch 1:   3%|▎         | 2688/107000 [00:06<02:33, 677.87it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:   3%|▎         | 2688/107000 [00:06<02:33, 677.87it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   3%|▎         | 2720/107000 [00:06<02:33, 677.87it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:   3%|▎         | 2752/107000 [00:06<02:33, 677.87it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:   3%|▎         | 2784/107000 [00:06<02:31, 689.95it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:   3%|▎         | 2784/107000 [00:06<02:31, 689.95it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:   3%|▎         | 2816/107000 [00:06<02:31, 689.95it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:   3%|▎         | 2848/107000 [00:06<02:30, 689.95it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:   3%|▎         | 2880/107000 [00:06<02:29, 695.95it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:   3%|▎         | 2880/107000 [00:06<02:29, 695.95it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:   3%|▎         | 2912/107000 [00:06<02:29, 695.95it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   3%|▎         | 2944/107000 [00:07<02:29, 695.95it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   3%|▎         | 2976/107000 [00:07<02:24, 720.68it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   3%|▎         | 2976/107000 [00:07<02:24, 720.68it/s, train_loss=0.64] \u001b[A\n",
            "Epoch 1:   3%|▎         | 3008/107000 [00:07<02:24, 720.68it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3040/107000 [00:07<02:24, 720.68it/s, train_loss=0.64] \u001b[A\n",
            "Epoch 1:   3%|▎         | 3072/107000 [00:07<02:21, 734.11it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3072/107000 [00:07<02:21, 734.11it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3104/107000 [00:07<02:21, 734.11it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3136/107000 [00:07<02:21, 734.11it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3168/107000 [00:07<02:19, 744.17it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3168/107000 [00:07<02:19, 744.17it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3200/107000 [00:07<02:19, 744.17it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3232/107000 [00:07<02:19, 744.17it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3264/107000 [00:07<02:18, 748.53it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3264/107000 [00:07<02:18, 748.53it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3296/107000 [00:07<02:18, 748.53it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3328/107000 [00:07<02:18, 748.53it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3360/107000 [00:07<02:20, 739.89it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3360/107000 [00:07<02:20, 739.89it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3392/107000 [00:07<02:20, 739.89it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3424/107000 [00:07<02:19, 739.89it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3456/107000 [00:07<02:21, 730.90it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3456/107000 [00:07<02:21, 730.90it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3488/107000 [00:07<02:21, 730.90it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3520/107000 [00:07<02:21, 730.90it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3552/107000 [00:07<02:21, 733.04it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3552/107000 [00:07<02:21, 733.04it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3584/107000 [00:07<02:21, 733.04it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3616/107000 [00:07<02:21, 733.04it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3648/107000 [00:07<02:23, 720.95it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3648/107000 [00:07<02:23, 720.95it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3680/107000 [00:08<02:23, 720.95it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3712/107000 [00:08<02:23, 720.95it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3744/107000 [00:08<02:25, 707.39it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:   3%|▎         | 3744/107000 [00:08<02:25, 707.39it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:   4%|▎         | 3776/107000 [00:08<02:25, 707.39it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:   4%|▎         | 3808/107000 [00:08<02:25, 707.39it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:   4%|▎         | 3840/107000 [00:08<02:22, 722.69it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:   4%|▎         | 3840/107000 [00:08<02:22, 722.69it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:   4%|▎         | 3872/107000 [00:08<02:22, 722.69it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:   4%|▎         | 3904/107000 [00:08<02:22, 722.69it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:   4%|▎         | 3936/107000 [00:08<02:21, 726.55it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:   4%|▎         | 3936/107000 [00:08<02:21, 726.55it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:   4%|▎         | 3968/107000 [00:08<02:21, 726.55it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:   4%|▎         | 4000/107000 [00:08<02:21, 726.55it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4032/107000 [00:08<02:21, 728.52it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4032/107000 [00:08<02:21, 728.52it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4064/107000 [00:08<02:21, 728.52it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4096/107000 [00:08<02:21, 728.52it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4128/107000 [00:08<02:19, 739.23it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4128/107000 [00:08<02:19, 739.23it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4160/107000 [00:08<02:19, 739.23it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4192/107000 [00:08<02:19, 739.23it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4224/107000 [00:08<02:21, 724.70it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4224/107000 [00:08<02:21, 724.70it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4256/107000 [00:08<02:21, 724.70it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4288/107000 [00:08<02:21, 724.70it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4320/107000 [00:08<02:20, 730.76it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4320/107000 [00:08<02:20, 730.76it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4352/107000 [00:08<02:20, 730.76it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4384/107000 [00:08<02:20, 730.76it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4416/107000 [00:08<02:22, 722.28it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4416/107000 [00:09<02:22, 722.28it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4448/107000 [00:09<02:21, 722.28it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4480/107000 [00:09<02:21, 722.28it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4512/107000 [00:09<02:22, 721.54it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4512/107000 [00:09<02:22, 721.54it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4544/107000 [00:09<02:21, 721.54it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4576/107000 [00:09<02:21, 721.54it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4608/107000 [00:09<02:23, 713.01it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4608/107000 [00:09<02:23, 713.01it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4640/107000 [00:09<02:23, 713.01it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4672/107000 [00:09<02:23, 713.01it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4704/107000 [00:09<02:21, 722.26it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4704/107000 [00:09<02:21, 722.26it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4736/107000 [00:09<02:21, 722.26it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4768/107000 [00:09<02:21, 722.26it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4800/107000 [00:09<02:20, 726.64it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:   4%|▍         | 4800/107000 [00:09<02:20, 726.64it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:   5%|▍         | 4832/107000 [00:09<02:20, 726.64it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:   5%|▍         | 4864/107000 [00:09<02:20, 726.64it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:   5%|▍         | 4896/107000 [00:09<02:18, 735.24it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:   5%|▍         | 4896/107000 [00:09<02:18, 735.24it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:   5%|▍         | 4928/107000 [00:09<02:18, 735.24it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:   5%|▍         | 4960/107000 [00:09<02:18, 735.24it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:   5%|▍         | 4992/107000 [00:09<02:18, 735.93it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:   5%|▍         | 4992/107000 [00:09<02:18, 735.93it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:   5%|▍         | 5024/107000 [00:09<02:18, 735.93it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:   5%|▍         | 5056/107000 [00:09<02:18, 735.93it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:   5%|▍         | 5088/107000 [00:09<02:18, 735.22it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:   5%|▍         | 5088/107000 [00:09<02:18, 735.22it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:   5%|▍         | 5120/107000 [00:09<02:18, 735.22it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:   5%|▍         | 5152/107000 [00:10<02:18, 735.22it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:   5%|▍         | 5184/107000 [00:10<02:20, 727.12it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:   5%|▍         | 5184/107000 [00:10<02:20, 727.12it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:   5%|▍         | 5216/107000 [00:10<02:19, 727.12it/s, train_loss=0.64] \u001b[A\n",
            "Epoch 1:   5%|▍         | 5248/107000 [00:10<02:19, 727.12it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:   5%|▍         | 5280/107000 [00:10<02:21, 717.89it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:   5%|▍         | 5280/107000 [00:10<02:21, 717.89it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:   5%|▍         | 5312/107000 [00:10<02:21, 717.89it/s, train_loss=0.64] \u001b[A\n",
            "Epoch 1:   5%|▍         | 5344/107000 [00:10<02:21, 717.89it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:   5%|▌         | 5376/107000 [00:10<02:19, 727.54it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:   5%|▌         | 5376/107000 [00:10<02:19, 727.54it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:   5%|▌         | 5408/107000 [00:10<02:19, 727.54it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:   5%|▌         | 5440/107000 [00:10<02:19, 727.54it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:   5%|▌         | 5472/107000 [00:10<02:16, 746.50it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:   5%|▌         | 5472/107000 [00:10<02:16, 746.50it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:   5%|▌         | 5504/107000 [00:10<02:15, 746.50it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:   5%|▌         | 5536/107000 [00:10<02:15, 746.50it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:   5%|▌         | 5568/107000 [00:10<02:18, 729.85it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:   5%|▌         | 5568/107000 [00:10<02:18, 729.85it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:   5%|▌         | 5600/107000 [00:10<02:18, 729.85it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:   5%|▌         | 5632/107000 [00:10<02:18, 729.85it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:   5%|▌         | 5664/107000 [00:10<02:20, 720.54it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:   5%|▌         | 5664/107000 [00:10<02:20, 720.54it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:   5%|▌         | 5696/107000 [00:10<02:20, 720.54it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:   5%|▌         | 5728/107000 [00:10<02:20, 720.54it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   5%|▌         | 5760/107000 [00:10<02:19, 726.29it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   5%|▌         | 5760/107000 [00:10<02:19, 726.29it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   5%|▌         | 5792/107000 [00:10<02:19, 726.29it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   5%|▌         | 5824/107000 [00:10<02:19, 726.29it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:   5%|▌         | 5856/107000 [00:10<02:19, 727.50it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:   5%|▌         | 5856/107000 [00:11<02:19, 727.50it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   6%|▌         | 5888/107000 [00:11<02:18, 727.50it/s, train_loss=0.64] \u001b[A\n",
            "Epoch 1:   6%|▌         | 5920/107000 [00:11<02:18, 727.50it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   6%|▌         | 5952/107000 [00:11<02:17, 735.32it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   6%|▌         | 5952/107000 [00:11<02:17, 735.32it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:   6%|▌         | 5984/107000 [00:11<02:17, 735.32it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6016/107000 [00:11<02:17, 735.32it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6048/107000 [00:11<02:16, 738.01it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6048/107000 [00:11<02:16, 738.01it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6080/107000 [00:11<02:16, 738.01it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6112/107000 [00:11<02:16, 738.01it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6144/107000 [00:11<02:18, 726.68it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6144/107000 [00:11<02:18, 726.68it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6176/107000 [00:11<02:18, 726.68it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6208/107000 [00:11<02:18, 726.68it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6240/107000 [00:11<02:18, 725.60it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6240/107000 [00:11<02:18, 725.60it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6272/107000 [00:11<02:18, 725.60it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6304/107000 [00:11<02:18, 725.60it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6336/107000 [00:11<02:17, 729.83it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6336/107000 [00:11<02:17, 729.83it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6368/107000 [00:11<02:17, 729.83it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6400/107000 [00:11<02:17, 729.83it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6432/107000 [00:11<02:16, 739.07it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6432/107000 [00:11<02:16, 739.07it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6464/107000 [00:11<02:16, 739.07it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6496/107000 [00:11<02:15, 739.07it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6528/107000 [00:11<02:18, 722.92it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6528/107000 [00:11<02:18, 722.92it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6560/107000 [00:11<02:18, 722.92it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6592/107000 [00:12<02:18, 722.92it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6624/107000 [00:12<02:16, 734.94it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6624/107000 [00:12<02:16, 734.94it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:   6%|▌         | 6656/107000 [00:12<02:16, 734.94it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:   6%|▋         | 6688/107000 [00:12<02:16, 734.94it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:   6%|▋         | 6720/107000 [00:12<02:18, 722.01it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:   6%|▋         | 6720/107000 [00:12<02:18, 722.01it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:   6%|▋         | 6752/107000 [00:12<02:18, 722.01it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:   6%|▋         | 6784/107000 [00:12<02:18, 722.01it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:   6%|▋         | 6816/107000 [00:12<02:20, 714.50it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:   6%|▋         | 6816/107000 [00:12<02:20, 714.50it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:   6%|▋         | 6848/107000 [00:12<02:20, 714.50it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   6%|▋         | 6880/107000 [00:12<02:20, 714.50it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   6%|▋         | 6912/107000 [00:12<02:16, 730.92it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   6%|▋         | 6912/107000 [00:12<02:16, 730.92it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   6%|▋         | 6944/107000 [00:12<02:16, 730.92it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   7%|▋         | 6976/107000 [00:12<02:16, 730.92it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7008/107000 [00:12<02:19, 717.10it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7008/107000 [00:12<02:19, 717.10it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7040/107000 [00:12<02:19, 717.10it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7072/107000 [00:12<02:19, 717.10it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7104/107000 [00:12<02:17, 726.37it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7104/107000 [00:12<02:17, 726.37it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7136/107000 [00:12<02:17, 726.37it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7168/107000 [00:12<02:17, 726.37it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7200/107000 [00:12<02:18, 718.05it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7200/107000 [00:12<02:18, 718.05it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7232/107000 [00:12<02:18, 718.05it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7264/107000 [00:12<02:18, 718.05it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7296/107000 [00:12<02:18, 719.43it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7296/107000 [00:13<02:18, 719.43it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7328/107000 [00:13<02:18, 719.43it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7360/107000 [00:13<02:18, 719.43it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7392/107000 [00:13<02:18, 720.32it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7392/107000 [00:13<02:18, 720.32it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7424/107000 [00:13<02:18, 720.32it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7456/107000 [00:13<02:18, 720.32it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7488/107000 [00:13<02:15, 736.62it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7488/107000 [00:13<02:15, 736.62it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7520/107000 [00:13<02:15, 736.62it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7552/107000 [00:13<02:15, 736.62it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7584/107000 [00:13<02:18, 717.33it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7584/107000 [00:13<02:18, 717.33it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7616/107000 [00:13<02:18, 717.33it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7648/107000 [00:13<02:18, 717.33it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7680/107000 [00:13<02:18, 718.02it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7680/107000 [00:13<02:18, 718.02it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7712/107000 [00:13<02:18, 718.02it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7744/107000 [00:13<02:18, 718.02it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7776/107000 [00:13<02:14, 737.08it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7776/107000 [00:13<02:14, 737.08it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7808/107000 [00:13<02:14, 737.08it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7840/107000 [00:13<02:14, 737.08it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7872/107000 [00:13<02:17, 722.38it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7872/107000 [00:13<02:17, 722.38it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7904/107000 [00:13<02:17, 722.38it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7936/107000 [00:13<02:17, 722.38it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7968/107000 [00:13<02:15, 729.75it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   7%|▋         | 7968/107000 [00:13<02:15, 729.75it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:   7%|▋         | 8000/107000 [00:13<02:15, 729.75it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8032/107000 [00:14<02:15, 729.75it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8064/107000 [00:14<02:16, 727.31it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8064/107000 [00:14<02:16, 727.31it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8096/107000 [00:14<02:15, 727.31it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8128/107000 [00:14<02:15, 727.31it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8160/107000 [00:14<02:16, 723.79it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8160/107000 [00:14<02:16, 723.79it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8192/107000 [00:14<02:16, 723.79it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8224/107000 [00:14<02:16, 723.79it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8256/107000 [00:14<02:17, 719.84it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8256/107000 [00:14<02:17, 719.84it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8288/107000 [00:14<02:17, 719.84it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8320/107000 [00:14<02:17, 719.84it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8352/107000 [00:14<02:19, 706.22it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8352/107000 [00:14<02:19, 706.22it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8384/107000 [00:14<02:19, 706.22it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8416/107000 [00:14<02:19, 706.22it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8448/107000 [00:14<02:19, 707.42it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8448/107000 [00:14<02:19, 707.42it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8480/107000 [00:14<02:19, 707.42it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8512/107000 [00:14<02:19, 707.42it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8544/107000 [00:14<02:17, 713.99it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8544/107000 [00:14<02:17, 713.99it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8576/107000 [00:14<02:17, 713.99it/s, train_loss=0.658]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8608/107000 [00:14<02:17, 713.99it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8640/107000 [00:14<02:13, 737.71it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8640/107000 [00:14<02:13, 737.71it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8672/107000 [00:14<02:13, 737.71it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8704/107000 [00:14<02:13, 737.71it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8736/107000 [00:14<02:14, 729.85it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8736/107000 [00:14<02:14, 729.85it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8768/107000 [00:15<02:14, 729.85it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8800/107000 [00:15<02:14, 729.85it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8832/107000 [00:15<02:16, 720.92it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8832/107000 [00:15<02:16, 720.92it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8864/107000 [00:15<02:16, 720.92it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8896/107000 [00:15<02:16, 720.92it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8928/107000 [00:15<02:18, 705.90it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8928/107000 [00:15<02:18, 705.90it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8960/107000 [00:15<02:18, 705.90it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   8%|▊         | 8992/107000 [00:15<02:18, 705.90it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   8%|▊         | 9024/107000 [00:15<02:17, 712.22it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   8%|▊         | 9024/107000 [00:15<02:17, 712.22it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   8%|▊         | 9056/107000 [00:15<02:17, 712.22it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:   8%|▊         | 9088/107000 [00:15<02:17, 712.22it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   9%|▊         | 9120/107000 [00:15<02:15, 723.28it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   9%|▊         | 9120/107000 [00:15<02:15, 723.28it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   9%|▊         | 9152/107000 [00:15<02:15, 723.28it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   9%|▊         | 9184/107000 [00:15<02:15, 723.28it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   9%|▊         | 9216/107000 [00:15<02:15, 723.98it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   9%|▊         | 9216/107000 [00:15<02:15, 723.98it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   9%|▊         | 9248/107000 [00:15<02:15, 723.98it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   9%|▊         | 9280/107000 [00:15<02:14, 723.98it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   9%|▊         | 9312/107000 [00:15<02:14, 727.91it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   9%|▊         | 9312/107000 [00:15<02:14, 727.91it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   9%|▊         | 9344/107000 [00:15<02:14, 727.91it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9376/107000 [00:15<02:14, 727.91it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9408/107000 [00:15<02:14, 725.33it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9408/107000 [00:15<02:14, 725.33it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9440/107000 [00:15<02:14, 725.33it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9472/107000 [00:16<02:14, 725.33it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9504/107000 [00:16<02:12, 734.79it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9504/107000 [00:16<02:12, 734.79it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9536/107000 [00:16<02:12, 734.79it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9568/107000 [00:16<02:12, 734.79it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9600/107000 [00:16<02:15, 720.08it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9600/107000 [00:16<02:15, 720.08it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9632/107000 [00:16<02:15, 720.08it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9664/107000 [00:16<02:15, 720.08it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9696/107000 [00:16<02:14, 724.92it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9696/107000 [00:16<02:14, 724.92it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9728/107000 [00:16<02:14, 724.92it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9760/107000 [00:16<02:14, 724.92it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9792/107000 [00:16<02:14, 720.19it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9792/107000 [00:16<02:14, 720.19it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9824/107000 [00:16<02:14, 720.19it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9856/107000 [00:16<02:14, 720.19it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9888/107000 [00:16<02:11, 736.83it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9888/107000 [00:16<02:11, 736.83it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9920/107000 [00:16<02:11, 736.83it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9952/107000 [00:16<02:11, 736.83it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9984/107000 [00:16<02:08, 753.64it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   9%|▉         | 9984/107000 [00:16<02:08, 753.64it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   9%|▉         | 10016/107000 [00:16<02:08, 753.64it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:   9%|▉         | 10048/107000 [00:16<02:08, 753.64it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:   9%|▉         | 10080/107000 [00:16<02:07, 759.58it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:   9%|▉         | 10080/107000 [00:16<02:07, 759.58it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:   9%|▉         | 10112/107000 [00:16<02:07, 759.58it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:   9%|▉         | 10144/107000 [00:16<02:07, 759.58it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  10%|▉         | 10176/107000 [00:16<02:05, 770.85it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  10%|▉         | 10176/107000 [00:16<02:05, 770.85it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  10%|▉         | 10208/107000 [00:16<02:05, 770.85it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|▉         | 10240/107000 [00:17<02:05, 770.85it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|▉         | 10272/107000 [00:17<02:05, 769.60it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|▉         | 10272/107000 [00:17<02:05, 769.60it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|▉         | 10304/107000 [00:17<02:05, 769.60it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|▉         | 10336/107000 [00:17<02:05, 769.60it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|▉         | 10368/107000 [00:17<02:06, 766.87it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|▉         | 10368/107000 [00:17<02:06, 766.87it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|▉         | 10400/107000 [00:17<02:05, 766.87it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|▉         | 10432/107000 [00:17<02:05, 766.87it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|▉         | 10464/107000 [00:17<02:07, 758.75it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|▉         | 10464/107000 [00:17<02:07, 758.75it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|▉         | 10496/107000 [00:17<02:07, 758.75it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|▉         | 10528/107000 [00:17<02:07, 758.75it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|▉         | 10560/107000 [00:17<02:10, 736.58it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|▉         | 10560/107000 [00:17<02:10, 736.58it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|▉         | 10592/107000 [00:17<02:10, 736.58it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  10%|▉         | 10624/107000 [00:17<02:10, 736.58it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  10%|▉         | 10656/107000 [00:17<02:14, 718.42it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|▉         | 10656/107000 [00:17<02:14, 718.42it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|▉         | 10688/107000 [00:17<02:14, 718.42it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|█         | 10720/107000 [00:17<02:14, 718.42it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|█         | 10752/107000 [00:17<02:12, 728.47it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|█         | 10752/107000 [00:17<02:12, 728.47it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  10%|█         | 10784/107000 [00:17<02:12, 728.47it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  10%|█         | 10816/107000 [00:17<02:12, 728.47it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|█         | 10848/107000 [00:17<02:13, 720.21it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|█         | 10848/107000 [00:17<02:13, 720.21it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|█         | 10880/107000 [00:17<02:13, 720.21it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  10%|█         | 10912/107000 [00:17<02:13, 720.21it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  10%|█         | 10944/107000 [00:17<02:12, 722.89it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  10%|█         | 10944/107000 [00:17<02:12, 722.89it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  10%|█         | 10976/107000 [00:18<02:12, 722.89it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  10%|█         | 11008/107000 [00:18<02:12, 722.89it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  10%|█         | 11040/107000 [00:18<02:09, 738.22it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  10%|█         | 11040/107000 [00:18<02:09, 738.22it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  10%|█         | 11072/107000 [00:18<02:09, 738.22it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  10%|█         | 11104/107000 [00:18<02:09, 738.22it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  10%|█         | 11136/107000 [00:18<02:08, 745.67it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  10%|█         | 11136/107000 [00:18<02:08, 745.67it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  10%|█         | 11168/107000 [00:18<02:08, 745.67it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  10%|█         | 11200/107000 [00:18<02:08, 745.67it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  10%|█         | 11232/107000 [00:18<02:08, 744.51it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  10%|█         | 11232/107000 [00:18<02:08, 744.51it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  11%|█         | 11264/107000 [00:18<02:08, 744.51it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11296/107000 [00:18<02:08, 744.51it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11328/107000 [00:18<02:07, 752.88it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11328/107000 [00:18<02:07, 752.88it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11360/107000 [00:18<02:07, 752.88it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11392/107000 [00:18<02:06, 752.88it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11424/107000 [00:18<02:05, 761.57it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11424/107000 [00:18<02:05, 761.57it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  11%|█         | 11456/107000 [00:18<02:05, 761.57it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11488/107000 [00:18<02:05, 761.57it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  11%|█         | 11520/107000 [00:18<02:04, 769.72it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  11%|█         | 11520/107000 [00:18<02:04, 769.72it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11552/107000 [00:18<02:04, 769.72it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11584/107000 [00:18<02:03, 769.72it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11616/107000 [00:18<02:03, 773.87it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11616/107000 [00:18<02:03, 773.87it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11648/107000 [00:18<02:03, 773.87it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11680/107000 [00:18<02:03, 773.87it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11712/107000 [00:18<02:02, 776.48it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11712/107000 [00:18<02:02, 776.48it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11744/107000 [00:19<02:02, 776.48it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11776/107000 [00:19<02:02, 776.48it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11808/107000 [00:19<02:03, 773.27it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11808/107000 [00:19<02:03, 773.27it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11840/107000 [00:19<02:03, 773.27it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11872/107000 [00:19<02:03, 773.27it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11904/107000 [00:19<02:02, 775.29it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11904/107000 [00:19<02:02, 775.29it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11936/107000 [00:19<02:02, 775.29it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█         | 11968/107000 [00:19<02:02, 775.29it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  11%|█         | 12000/107000 [00:19<02:04, 762.25it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  11%|█         | 12000/107000 [00:19<02:04, 762.25it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  11%|█         | 12032/107000 [00:19<02:04, 762.25it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 12064/107000 [00:19<02:04, 762.25it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 12096/107000 [00:19<02:03, 766.57it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 12096/107000 [00:19<02:03, 766.57it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 12128/107000 [00:19<02:03, 766.57it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 12160/107000 [00:19<02:03, 766.57it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 12192/107000 [00:19<02:03, 769.35it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 12192/107000 [00:19<02:03, 769.35it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 12224/107000 [00:19<02:03, 769.35it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 12256/107000 [00:19<02:03, 769.35it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 12288/107000 [00:19<02:02, 770.24it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  11%|█▏        | 12288/107000 [00:19<02:02, 770.24it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12320/107000 [00:19<02:02, 770.24it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12352/107000 [00:19<02:02, 770.24it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12384/107000 [00:19<02:02, 771.37it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12384/107000 [00:19<02:02, 771.37it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12416/107000 [00:19<02:02, 771.37it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12448/107000 [00:19<02:02, 771.37it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12480/107000 [00:19<02:02, 773.16it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12480/107000 [00:19<02:02, 773.16it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12512/107000 [00:20<02:02, 773.16it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12544/107000 [00:20<02:02, 773.16it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12576/107000 [00:20<02:04, 761.32it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12576/107000 [00:20<02:04, 761.32it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12608/107000 [00:20<02:03, 761.32it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12640/107000 [00:20<02:03, 761.32it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  12%|█▏        | 12672/107000 [00:20<02:03, 762.44it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12672/107000 [00:20<02:03, 762.44it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12704/107000 [00:20<02:03, 762.44it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12736/107000 [00:20<02:03, 762.44it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12768/107000 [00:20<02:02, 768.58it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12768/107000 [00:20<02:02, 768.58it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12800/107000 [00:20<02:02, 768.58it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12832/107000 [00:20<02:02, 768.58it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12864/107000 [00:20<02:01, 772.97it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12864/107000 [00:20<02:01, 772.97it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12896/107000 [00:20<02:01, 772.97it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12928/107000 [00:20<02:01, 772.97it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  12%|█▏        | 12960/107000 [00:20<02:03, 762.09it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12960/107000 [00:20<02:03, 762.09it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 12992/107000 [00:20<02:03, 762.09it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 13024/107000 [00:20<02:03, 762.09it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 13056/107000 [00:20<02:04, 755.31it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 13056/107000 [00:20<02:04, 755.31it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  12%|█▏        | 13088/107000 [00:20<02:04, 755.31it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 13120/107000 [00:20<02:04, 755.31it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 13152/107000 [00:20<02:04, 755.88it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 13152/107000 [00:20<02:04, 755.88it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 13184/107000 [00:20<02:04, 755.88it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 13216/107000 [00:20<02:04, 755.88it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 13248/107000 [00:20<02:05, 745.83it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 13248/107000 [00:21<02:05, 745.83it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 13280/107000 [00:21<02:05, 745.83it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 13312/107000 [00:21<02:05, 745.83it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 13344/107000 [00:21<02:05, 744.85it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  12%|█▏        | 13344/107000 [00:21<02:05, 744.85it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13376/107000 [00:21<02:05, 744.85it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13408/107000 [00:21<02:05, 744.85it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13440/107000 [00:21<02:05, 743.39it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13440/107000 [00:21<02:05, 743.39it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13472/107000 [00:21<02:05, 743.39it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13504/107000 [00:21<02:05, 743.39it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13536/107000 [00:21<02:06, 739.46it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13536/107000 [00:21<02:06, 739.46it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13568/107000 [00:21<02:06, 739.46it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13600/107000 [00:21<02:06, 739.46it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13632/107000 [00:21<02:05, 741.06it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13632/107000 [00:21<02:05, 741.06it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13664/107000 [00:21<02:05, 741.06it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13696/107000 [00:21<02:05, 741.06it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13728/107000 [00:21<02:07, 729.59it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13728/107000 [00:21<02:07, 729.59it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13760/107000 [00:21<02:07, 729.59it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13792/107000 [00:21<02:07, 729.59it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13824/107000 [00:21<02:07, 728.01it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13824/107000 [00:21<02:07, 728.01it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13856/107000 [00:21<02:07, 728.01it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13888/107000 [00:21<02:07, 728.01it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13920/107000 [00:21<02:07, 732.53it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13920/107000 [00:21<02:07, 732.53it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13952/107000 [00:21<02:07, 732.53it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 13984/107000 [00:22<02:06, 732.53it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 14016/107000 [00:22<02:05, 739.62it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 14016/107000 [00:22<02:05, 739.62it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 14048/107000 [00:22<02:05, 739.62it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 14080/107000 [00:22<02:05, 739.62it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 14112/107000 [00:22<02:06, 734.36it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 14112/107000 [00:22<02:06, 734.36it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 14144/107000 [00:22<02:06, 734.36it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 14176/107000 [00:22<02:06, 734.36it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 14208/107000 [00:22<02:04, 744.46it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 14208/107000 [00:22<02:04, 744.46it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  13%|█▎        | 14240/107000 [00:22<02:04, 744.46it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 14272/107000 [00:22<02:04, 744.46it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 14304/107000 [00:22<02:03, 749.41it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 14304/107000 [00:22<02:03, 749.41it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 14336/107000 [00:22<02:03, 749.41it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 14368/107000 [00:22<02:03, 749.41it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 14400/107000 [00:22<02:03, 751.32it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 14400/107000 [00:22<02:03, 751.32it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  13%|█▎        | 14432/107000 [00:22<02:03, 751.32it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 14464/107000 [00:22<02:03, 751.32it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 14496/107000 [00:22<02:04, 745.69it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 14496/107000 [00:22<02:04, 745.69it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 14528/107000 [00:22<02:04, 745.69it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 14560/107000 [00:22<02:03, 745.69it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 14592/107000 [00:22<02:05, 735.67it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 14592/107000 [00:22<02:05, 735.67it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 14624/107000 [00:22<02:05, 735.67it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 14656/107000 [00:22<02:05, 735.67it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 14688/107000 [00:22<02:06, 731.05it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▎        | 14688/107000 [00:22<02:06, 731.05it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 14720/107000 [00:23<02:06, 731.05it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 14752/107000 [00:23<02:06, 731.05it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 14784/107000 [00:23<02:08, 720.44it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 14784/107000 [00:23<02:08, 720.44it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 14816/107000 [00:23<02:07, 720.44it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 14848/107000 [00:23<02:07, 720.44it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 14880/107000 [00:23<02:05, 733.60it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 14880/107000 [00:23<02:05, 733.60it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 14912/107000 [00:23<02:05, 733.60it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 14944/107000 [00:23<02:05, 733.60it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 14976/107000 [00:23<02:05, 732.42it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 14976/107000 [00:23<02:05, 732.42it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 15008/107000 [00:23<02:05, 732.42it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 15040/107000 [00:23<02:05, 732.42it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 15072/107000 [00:23<02:06, 727.92it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 15072/107000 [00:23<02:06, 727.92it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 15104/107000 [00:23<02:06, 727.92it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 15136/107000 [00:23<02:06, 727.92it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 15168/107000 [00:23<02:08, 713.12it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 15168/107000 [00:23<02:08, 713.12it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 15200/107000 [00:23<02:08, 713.12it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 15232/107000 [00:23<02:08, 713.12it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 15264/107000 [00:23<02:05, 730.75it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 15264/107000 [00:23<02:05, 730.75it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 15296/107000 [00:23<02:05, 730.75it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 15328/107000 [00:23<02:05, 730.75it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 15360/107000 [00:23<02:06, 726.94it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 15360/107000 [00:23<02:06, 726.94it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 15392/107000 [00:23<02:06, 726.94it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 15424/107000 [00:23<02:05, 726.94it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 15456/107000 [00:23<02:05, 729.43it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 15456/107000 [00:24<02:05, 729.43it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  14%|█▍        | 15488/107000 [00:24<02:05, 729.43it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 15520/107000 [00:24<02:05, 729.43it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 15552/107000 [00:24<02:02, 745.30it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 15552/107000 [00:24<02:02, 745.30it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 15584/107000 [00:24<02:02, 745.30it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 15616/107000 [00:24<02:02, 745.30it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 15648/107000 [00:24<02:01, 749.15it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 15648/107000 [00:24<02:01, 749.15it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 15680/107000 [00:24<02:01, 749.15it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 15712/107000 [00:24<02:01, 749.15it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 15744/107000 [00:24<02:03, 736.52it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 15744/107000 [00:24<02:03, 736.52it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 15776/107000 [00:24<02:03, 736.52it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 15808/107000 [00:24<02:03, 736.52it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 15840/107000 [00:24<02:01, 748.86it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 15840/107000 [00:24<02:01, 748.86it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 15872/107000 [00:24<02:01, 748.86it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 15904/107000 [00:24<02:01, 748.86it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 15936/107000 [00:24<01:59, 761.39it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 15936/107000 [00:24<01:59, 761.39it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 15968/107000 [00:24<01:59, 761.39it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 16000/107000 [00:24<01:59, 761.39it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 16032/107000 [00:24<02:00, 755.86it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  15%|█▍        | 16032/107000 [00:24<02:00, 755.86it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 16064/107000 [00:24<02:00, 755.86it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 16096/107000 [00:24<02:00, 755.86it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 16128/107000 [00:24<02:00, 753.95it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 16128/107000 [00:24<02:00, 753.95it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 16160/107000 [00:24<02:00, 753.95it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 16192/107000 [00:24<02:00, 753.95it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 16224/107000 [00:24<01:59, 760.85it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 16224/107000 [00:25<01:59, 760.85it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 16256/107000 [00:25<01:59, 760.85it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 16288/107000 [00:25<01:59, 760.85it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 16320/107000 [00:25<01:57, 771.15it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 16320/107000 [00:25<01:57, 771.15it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 16352/107000 [00:25<01:57, 771.15it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 16384/107000 [00:25<01:57, 771.15it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 16416/107000 [00:25<01:57, 773.59it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 16416/107000 [00:25<01:57, 773.59it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 16448/107000 [00:25<01:57, 773.59it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 16480/107000 [00:25<01:57, 773.59it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 16512/107000 [00:25<01:55, 785.43it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 16512/107000 [00:25<01:55, 785.43it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 16544/107000 [00:25<01:55, 785.43it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  15%|█▌        | 16576/107000 [00:25<01:55, 785.43it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 16608/107000 [00:25<01:55, 782.36it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 16608/107000 [00:25<01:55, 782.36it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 16640/107000 [00:25<01:55, 782.36it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 16672/107000 [00:25<01:55, 782.36it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 16704/107000 [00:25<01:56, 775.11it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 16704/107000 [00:25<01:56, 775.11it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 16736/107000 [00:25<01:56, 775.11it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 16768/107000 [00:25<01:56, 775.11it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 16800/107000 [00:25<01:56, 776.71it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 16800/107000 [00:25<01:56, 776.71it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 16832/107000 [00:25<01:56, 776.71it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 16864/107000 [00:25<01:56, 776.71it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 16896/107000 [00:25<01:57, 765.44it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 16896/107000 [00:25<01:57, 765.44it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 16928/107000 [00:25<01:57, 765.44it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 16960/107000 [00:25<01:57, 765.44it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 16992/107000 [00:25<01:57, 763.00it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 16992/107000 [00:26<01:57, 763.00it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 17024/107000 [00:26<01:57, 763.00it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 17056/107000 [00:26<01:57, 763.00it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 17088/107000 [00:26<01:56, 771.30it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 17088/107000 [00:26<01:56, 771.30it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 17120/107000 [00:26<01:56, 771.30it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  16%|█▌        | 17152/107000 [00:26<01:56, 771.30it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 17184/107000 [00:26<01:57, 766.46it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 17184/107000 [00:26<01:57, 766.46it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 17216/107000 [00:26<01:57, 766.46it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 17248/107000 [00:26<01:57, 766.46it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 17280/107000 [00:26<01:58, 758.56it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 17280/107000 [00:26<01:58, 758.56it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 17312/107000 [00:26<01:58, 758.56it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 17344/107000 [00:26<01:58, 758.56it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 17376/107000 [00:26<01:59, 748.05it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▌        | 17376/107000 [00:26<01:59, 748.05it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 17408/107000 [00:26<01:59, 748.05it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 17440/107000 [00:26<01:59, 748.05it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 17472/107000 [00:26<02:01, 738.20it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 17472/107000 [00:26<02:01, 738.20it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 17504/107000 [00:26<02:01, 738.20it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 17536/107000 [00:26<02:01, 738.20it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 17568/107000 [00:26<02:02, 732.40it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 17568/107000 [00:26<02:02, 732.40it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 17600/107000 [00:26<02:02, 732.40it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  16%|█▋        | 17632/107000 [00:26<02:02, 732.40it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 17664/107000 [00:26<02:00, 740.73it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 17664/107000 [00:26<02:00, 740.73it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 17696/107000 [00:26<02:00, 740.73it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 17728/107000 [00:27<02:00, 740.73it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 17760/107000 [00:27<02:01, 734.05it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 17760/107000 [00:27<02:01, 734.05it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 17792/107000 [00:27<02:01, 734.05it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 17824/107000 [00:27<02:01, 734.05it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 17856/107000 [00:27<01:58, 751.39it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 17856/107000 [00:27<01:58, 751.39it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 17888/107000 [00:27<01:58, 751.39it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 17920/107000 [00:27<01:58, 751.39it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 17952/107000 [00:27<01:57, 757.35it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 17952/107000 [00:27<01:57, 757.35it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 17984/107000 [00:27<01:57, 757.35it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18016/107000 [00:27<01:57, 757.35it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18048/107000 [00:27<01:56, 766.54it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18048/107000 [00:27<01:56, 766.54it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18080/107000 [00:27<01:56, 766.54it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18112/107000 [00:27<01:55, 766.54it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18144/107000 [00:27<01:57, 755.45it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18144/107000 [00:27<01:57, 755.45it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18176/107000 [00:27<01:57, 755.45it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18208/107000 [00:27<01:57, 755.45it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18240/107000 [00:27<02:01, 730.99it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18240/107000 [00:27<02:01, 730.99it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18272/107000 [00:27<02:01, 730.99it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18304/107000 [00:27<02:01, 730.99it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18336/107000 [00:27<02:00, 733.46it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18336/107000 [00:27<02:00, 733.46it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18368/107000 [00:27<02:00, 733.46it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18400/107000 [00:27<02:00, 733.46it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18432/107000 [00:27<01:58, 750.17it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18432/107000 [00:27<01:58, 750.17it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18464/107000 [00:27<01:58, 750.17it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18496/107000 [00:28<01:57, 750.17it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18528/107000 [00:28<01:56, 761.15it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18528/107000 [00:28<01:56, 761.15it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18560/107000 [00:28<01:56, 761.15it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18592/107000 [00:28<01:56, 761.15it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18624/107000 [00:28<01:54, 771.50it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18624/107000 [00:28<01:54, 771.50it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18656/107000 [00:28<01:54, 771.50it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18688/107000 [00:28<01:54, 771.50it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18720/107000 [00:28<01:53, 775.23it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  17%|█▋        | 18720/107000 [00:28<01:53, 775.23it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 18752/107000 [00:28<01:53, 775.23it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 18784/107000 [00:28<01:53, 775.23it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 18816/107000 [00:28<01:53, 780.33it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 18816/107000 [00:28<01:53, 780.33it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 18848/107000 [00:28<01:52, 780.33it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 18880/107000 [00:28<01:52, 780.33it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 18912/107000 [00:28<01:54, 768.35it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 18912/107000 [00:28<01:54, 768.35it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 18944/107000 [00:28<01:54, 768.35it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 18976/107000 [00:28<01:54, 768.35it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19008/107000 [00:28<01:56, 756.12it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19008/107000 [00:28<01:56, 756.12it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19040/107000 [00:28<01:56, 756.12it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19072/107000 [00:28<01:56, 756.12it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19104/107000 [00:28<01:56, 756.12it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19104/107000 [00:28<01:56, 756.12it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19136/107000 [00:28<01:56, 756.12it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19168/107000 [00:28<01:56, 756.12it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19200/107000 [00:28<01:57, 746.52it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19200/107000 [00:28<01:57, 746.52it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19232/107000 [00:28<01:57, 746.52it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19264/107000 [00:29<01:57, 746.52it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19296/107000 [00:29<01:57, 747.41it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19296/107000 [00:29<01:57, 747.41it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19328/107000 [00:29<01:57, 747.41it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19360/107000 [00:29<01:57, 747.41it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19392/107000 [00:29<01:54, 762.71it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19392/107000 [00:29<01:54, 762.71it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19424/107000 [00:29<01:54, 762.71it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19456/107000 [00:29<01:54, 762.71it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19488/107000 [00:29<01:53, 769.59it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19488/107000 [00:29<01:53, 769.59it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19520/107000 [00:29<01:53, 769.59it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19552/107000 [00:29<01:53, 769.59it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19584/107000 [00:29<01:53, 771.03it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19584/107000 [00:29<01:53, 771.03it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19616/107000 [00:29<01:53, 771.03it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19648/107000 [00:29<01:53, 771.03it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19680/107000 [00:29<01:52, 773.97it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19680/107000 [00:29<01:52, 773.97it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19712/107000 [00:29<01:52, 773.97it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19744/107000 [00:29<01:52, 773.97it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19776/107000 [00:29<01:55, 756.34it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  18%|█▊        | 19776/107000 [00:29<01:55, 756.34it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 19808/107000 [00:29<01:55, 756.34it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 19840/107000 [00:29<01:55, 756.34it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 19872/107000 [00:29<01:54, 758.19it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 19872/107000 [00:29<01:54, 758.19it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 19904/107000 [00:29<01:54, 758.19it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 19936/107000 [00:29<01:54, 758.19it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 19968/107000 [00:29<01:54, 762.25it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 19968/107000 [00:29<01:54, 762.25it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 20000/107000 [00:29<01:54, 762.25it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  19%|█▊        | 20032/107000 [00:30<01:54, 762.25it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20064/107000 [00:30<01:52, 772.19it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20064/107000 [00:30<01:52, 772.19it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20096/107000 [00:30<01:52, 772.19it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20128/107000 [00:30<01:52, 772.19it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20160/107000 [00:30<01:53, 767.94it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20160/107000 [00:30<01:53, 767.94it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20192/107000 [00:30<01:53, 767.94it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20224/107000 [00:30<01:52, 767.94it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20256/107000 [00:30<01:52, 769.43it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20256/107000 [00:30<01:52, 769.43it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20288/107000 [00:30<01:52, 769.43it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20320/107000 [00:30<01:52, 769.43it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20352/107000 [00:30<01:54, 754.89it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20352/107000 [00:30<01:54, 754.89it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20384/107000 [00:30<01:54, 754.89it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20416/107000 [00:30<01:54, 754.89it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20448/107000 [00:30<01:53, 761.15it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20448/107000 [00:30<01:53, 761.15it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20480/107000 [00:30<01:53, 761.15it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20512/107000 [00:30<01:53, 761.15it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20544/107000 [00:30<01:51, 773.26it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20544/107000 [00:30<01:51, 773.26it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20576/107000 [00:30<01:51, 773.26it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20608/107000 [00:30<01:51, 773.26it/s, train_loss=0.658]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20640/107000 [00:30<01:51, 772.70it/s, train_loss=0.658]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20640/107000 [00:30<01:51, 772.70it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20672/107000 [00:30<01:51, 772.70it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20704/107000 [00:30<01:51, 772.70it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20736/107000 [00:30<01:50, 781.22it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20736/107000 [00:30<01:50, 781.22it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20768/107000 [00:30<01:50, 781.22it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20800/107000 [00:31<01:50, 781.22it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20832/107000 [00:31<01:50, 780.27it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20832/107000 [00:31<01:50, 780.27it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  19%|█▉        | 20864/107000 [00:31<01:50, 780.27it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 20896/107000 [00:31<01:50, 780.27it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 20928/107000 [00:31<01:49, 783.80it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 20928/107000 [00:31<01:49, 783.80it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 20960/107000 [00:31<01:49, 783.80it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 20992/107000 [00:31<01:49, 783.80it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 21024/107000 [00:31<01:52, 765.57it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 21024/107000 [00:31<01:52, 765.57it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 21056/107000 [00:31<01:52, 765.57it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 21088/107000 [00:31<01:52, 765.57it/s, train_loss=0.658]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 21120/107000 [00:31<01:53, 758.12it/s, train_loss=0.658]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 21120/107000 [00:31<01:53, 758.12it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 21152/107000 [00:31<01:53, 758.12it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 21184/107000 [00:31<01:53, 758.12it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 21216/107000 [00:31<01:52, 759.88it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 21216/107000 [00:31<01:52, 759.88it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 21248/107000 [00:31<01:52, 759.88it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 21280/107000 [00:31<01:52, 759.88it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 21312/107000 [00:31<01:52, 760.37it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 21312/107000 [00:31<01:52, 760.37it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 21344/107000 [00:31<01:52, 760.37it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  20%|█▉        | 21376/107000 [00:31<01:52, 760.37it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  20%|██        | 21408/107000 [00:31<01:54, 747.82it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  20%|██        | 21408/107000 [00:31<01:54, 747.82it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  20%|██        | 21440/107000 [00:31<01:54, 747.82it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  20%|██        | 21472/107000 [00:31<01:54, 747.82it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  20%|██        | 21504/107000 [00:31<01:54, 749.66it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  20%|██        | 21504/107000 [00:31<01:54, 749.66it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  20%|██        | 21536/107000 [00:32<01:54, 749.66it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  20%|██        | 21568/107000 [00:32<01:53, 749.66it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  20%|██        | 21600/107000 [00:32<01:50, 769.75it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  20%|██        | 21600/107000 [00:32<01:50, 769.75it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  20%|██        | 21632/107000 [00:32<01:50, 769.75it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  20%|██        | 21664/107000 [00:32<01:50, 769.75it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  20%|██        | 21696/107000 [00:32<01:50, 774.41it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  20%|██        | 21696/107000 [00:32<01:50, 774.41it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  20%|██        | 21728/107000 [00:32<01:50, 774.41it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  20%|██        | 21760/107000 [00:32<01:50, 774.41it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  20%|██        | 21792/107000 [00:32<01:49, 780.32it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  20%|██        | 21792/107000 [00:32<01:49, 780.32it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  20%|██        | 21824/107000 [00:32<01:49, 780.32it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  20%|██        | 21856/107000 [00:32<01:49, 780.32it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  20%|██        | 21888/107000 [00:32<01:49, 774.35it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  20%|██        | 21888/107000 [00:32<01:49, 774.35it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  20%|██        | 21920/107000 [00:32<01:49, 774.35it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  21%|██        | 21952/107000 [00:32<01:49, 774.35it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  21%|██        | 21984/107000 [00:32<01:50, 770.36it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  21%|██        | 21984/107000 [00:32<01:50, 770.36it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  21%|██        | 22016/107000 [00:32<01:50, 770.36it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  21%|██        | 22048/107000 [00:32<01:50, 770.36it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  21%|██        | 22080/107000 [00:32<01:51, 763.83it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  21%|██        | 22080/107000 [00:32<01:51, 763.83it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  21%|██        | 22112/107000 [00:32<01:51, 763.83it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  21%|██        | 22144/107000 [00:32<01:51, 763.83it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  21%|██        | 22176/107000 [00:32<01:51, 763.55it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  21%|██        | 22176/107000 [00:32<01:51, 763.55it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  21%|██        | 22208/107000 [00:32<01:51, 763.55it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  21%|██        | 22240/107000 [00:32<01:51, 763.55it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  21%|██        | 22272/107000 [00:32<01:50, 769.39it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  21%|██        | 22272/107000 [00:32<01:50, 769.39it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  21%|██        | 22304/107000 [00:33<01:50, 769.39it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  21%|██        | 22336/107000 [00:33<01:50, 769.39it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  21%|██        | 22368/107000 [00:33<01:51, 759.66it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  21%|██        | 22368/107000 [00:33<01:51, 759.66it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  21%|██        | 22400/107000 [00:33<01:51, 759.66it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  21%|██        | 22432/107000 [00:33<01:51, 759.66it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  21%|██        | 22464/107000 [00:33<01:54, 739.27it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  21%|██        | 22464/107000 [00:33<01:54, 739.27it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  21%|██        | 22496/107000 [00:33<01:54, 739.27it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  21%|██        | 22528/107000 [00:33<01:54, 739.27it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  21%|██        | 22560/107000 [00:33<01:52, 752.51it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  21%|██        | 22560/107000 [00:33<01:52, 752.51it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  21%|██        | 22592/107000 [00:33<01:52, 752.51it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  21%|██        | 22624/107000 [00:33<01:52, 752.51it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  21%|██        | 22656/107000 [00:33<01:50, 764.22it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  21%|██        | 22656/107000 [00:33<01:50, 764.22it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  21%|██        | 22688/107000 [00:33<01:50, 764.22it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  21%|██        | 22720/107000 [00:33<01:50, 764.22it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 22752/107000 [00:33<01:48, 774.26it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 22752/107000 [00:33<01:48, 774.26it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 22784/107000 [00:33<01:48, 774.26it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 22816/107000 [00:33<01:48, 774.26it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  21%|██▏       | 22848/107000 [00:33<01:48, 778.80it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 22848/107000 [00:33<01:48, 778.80it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 22880/107000 [00:33<01:48, 778.80it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 22912/107000 [00:33<01:47, 778.80it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 22944/107000 [00:33<01:47, 783.25it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 22944/107000 [00:33<01:47, 783.25it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  21%|██▏       | 22976/107000 [00:33<01:47, 783.25it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23008/107000 [00:33<01:47, 783.25it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23040/107000 [00:33<01:46, 786.35it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23040/107000 [00:33<01:46, 786.35it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23072/107000 [00:33<01:46, 786.35it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23104/107000 [00:34<01:46, 786.35it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23136/107000 [00:34<01:47, 783.74it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23136/107000 [00:34<01:47, 783.74it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23168/107000 [00:34<01:46, 783.74it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23200/107000 [00:34<01:46, 783.74it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  22%|██▏       | 23232/107000 [00:34<01:46, 786.84it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23232/107000 [00:34<01:46, 786.84it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23264/107000 [00:34<01:46, 786.84it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23296/107000 [00:34<01:46, 786.84it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23328/107000 [00:34<01:46, 784.85it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23328/107000 [00:34<01:46, 784.85it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23360/107000 [00:34<01:46, 784.85it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23392/107000 [00:34<01:46, 784.85it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23424/107000 [00:34<01:45, 789.04it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23424/107000 [00:34<01:45, 789.04it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23456/107000 [00:34<01:45, 789.04it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23488/107000 [00:34<01:45, 789.04it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23520/107000 [00:34<01:46, 786.21it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23520/107000 [00:34<01:46, 786.21it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23552/107000 [00:34<01:46, 786.21it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23584/107000 [00:34<01:46, 786.21it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23616/107000 [00:34<01:45, 788.95it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23616/107000 [00:34<01:45, 788.95it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23648/107000 [00:34<01:45, 788.95it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23680/107000 [00:34<01:45, 788.95it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23712/107000 [00:34<01:45, 786.67it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23712/107000 [00:34<01:45, 786.67it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23744/107000 [00:34<01:45, 786.67it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23776/107000 [00:34<01:45, 786.67it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23808/107000 [00:34<01:45, 788.85it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23808/107000 [00:34<01:45, 788.85it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23840/107000 [00:34<01:45, 788.85it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23872/107000 [00:35<01:45, 788.85it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23904/107000 [00:35<01:45, 789.80it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23904/107000 [00:35<01:45, 789.80it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23936/107000 [00:35<01:45, 789.80it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 23968/107000 [00:35<01:45, 789.80it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 24000/107000 [00:35<01:45, 787.57it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 24000/107000 [00:35<01:45, 787.57it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 24032/107000 [00:35<01:45, 787.57it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  22%|██▏       | 24064/107000 [00:35<01:45, 787.57it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24096/107000 [00:35<01:45, 787.28it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24096/107000 [00:35<01:45, 787.28it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24128/107000 [00:35<01:45, 787.28it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24160/107000 [00:35<01:45, 787.28it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24192/107000 [00:35<01:45, 782.83it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24192/107000 [00:35<01:45, 782.83it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24224/107000 [00:35<01:45, 782.83it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24256/107000 [00:35<01:45, 782.83it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24288/107000 [00:35<01:45, 783.43it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24288/107000 [00:35<01:45, 783.43it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24320/107000 [00:35<01:45, 783.43it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24352/107000 [00:35<01:45, 783.43it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24384/107000 [00:35<01:44, 787.14it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24384/107000 [00:35<01:44, 787.14it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24416/107000 [00:35<01:44, 787.14it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24448/107000 [00:35<01:44, 787.14it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24480/107000 [00:35<01:44, 789.39it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24480/107000 [00:35<01:44, 789.39it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24512/107000 [00:35<01:44, 789.39it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24544/107000 [00:35<01:44, 789.39it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24576/107000 [00:35<01:44, 789.93it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24576/107000 [00:35<01:44, 789.93it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24608/107000 [00:35<01:44, 789.93it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24640/107000 [00:35<01:44, 789.93it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24672/107000 [00:35<01:43, 793.55it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24672/107000 [00:36<01:43, 793.55it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24704/107000 [00:36<01:43, 793.55it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24736/107000 [00:36<01:43, 793.55it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24768/107000 [00:36<01:44, 790.35it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24768/107000 [00:36<01:44, 790.35it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24800/107000 [00:36<01:44, 790.35it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24832/107000 [00:36<01:43, 790.35it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24864/107000 [00:36<01:43, 792.35it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24864/107000 [00:36<01:43, 792.35it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24896/107000 [00:36<01:43, 792.35it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24928/107000 [00:36<01:43, 792.35it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24960/107000 [00:36<01:43, 790.84it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24960/107000 [00:36<01:43, 790.84it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 24992/107000 [00:36<01:43, 790.84it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 25024/107000 [00:36<01:43, 790.84it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 25056/107000 [00:36<01:44, 784.67it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 25056/107000 [00:36<01:44, 784.67it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 25088/107000 [00:36<01:44, 784.67it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  23%|██▎       | 25120/107000 [00:36<01:44, 784.67it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 25152/107000 [00:36<01:43, 788.16it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 25152/107000 [00:36<01:43, 788.16it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 25184/107000 [00:36<01:43, 788.16it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 25216/107000 [00:36<01:43, 788.16it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 25248/107000 [00:36<01:43, 789.38it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 25248/107000 [00:36<01:43, 789.38it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 25280/107000 [00:36<01:43, 789.38it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 25312/107000 [00:36<01:43, 789.38it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 25344/107000 [00:36<01:43, 790.46it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 25344/107000 [00:36<01:43, 790.46it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 25376/107000 [00:36<01:43, 790.46it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  24%|██▎       | 25408/107000 [00:36<01:43, 790.46it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 25440/107000 [00:36<01:43, 788.30it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 25440/107000 [00:36<01:43, 788.30it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 25472/107000 [00:37<01:43, 788.30it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 25504/107000 [00:37<01:43, 788.30it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 25536/107000 [00:37<01:42, 791.37it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 25536/107000 [00:37<01:42, 791.37it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 25568/107000 [00:37<01:42, 791.37it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 25600/107000 [00:37<01:42, 791.37it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 25632/107000 [00:37<01:42, 790.05it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 25632/107000 [00:37<01:42, 790.05it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 25664/107000 [00:37<01:42, 790.05it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 25696/107000 [00:37<01:42, 790.05it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 25728/107000 [00:37<01:43, 786.77it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 25728/107000 [00:37<01:43, 786.77it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 25760/107000 [00:37<01:43, 786.77it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  24%|██▍       | 25792/107000 [00:37<01:43, 786.77it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 25824/107000 [00:37<01:44, 779.42it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 25824/107000 [00:37<01:44, 779.42it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 25856/107000 [00:37<01:44, 779.42it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 25888/107000 [00:37<01:44, 779.42it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 25920/107000 [00:37<01:43, 782.98it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 25920/107000 [00:37<01:43, 782.98it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 25952/107000 [00:37<01:43, 782.98it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 25984/107000 [00:37<01:43, 782.98it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 26016/107000 [00:37<01:44, 774.59it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 26016/107000 [00:37<01:44, 774.59it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 26048/107000 [00:37<01:44, 774.59it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 26080/107000 [00:37<01:44, 774.59it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 26112/107000 [00:37<01:44, 773.22it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 26112/107000 [00:37<01:44, 773.22it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 26144/107000 [00:37<01:44, 773.22it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 26176/107000 [00:37<01:44, 773.22it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 26208/107000 [00:37<01:45, 763.00it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  24%|██▍       | 26208/107000 [00:37<01:45, 763.00it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 26240/107000 [00:38<01:45, 763.00it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 26272/107000 [00:38<01:45, 763.00it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 26304/107000 [00:38<01:44, 769.66it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 26304/107000 [00:38<01:44, 769.66it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 26336/107000 [00:38<01:44, 769.66it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 26368/107000 [00:38<01:44, 769.66it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 26400/107000 [00:38<01:44, 774.46it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 26400/107000 [00:38<01:44, 774.46it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 26432/107000 [00:38<01:44, 774.46it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 26464/107000 [00:38<01:43, 774.46it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 26496/107000 [00:38<01:43, 780.47it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 26496/107000 [00:38<01:43, 780.47it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 26528/107000 [00:38<01:43, 780.47it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 26560/107000 [00:38<01:43, 780.47it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 26592/107000 [00:38<01:42, 781.47it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 26592/107000 [00:38<01:42, 781.47it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 26624/107000 [00:38<01:42, 781.47it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 26656/107000 [00:38<01:42, 781.47it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 26688/107000 [00:38<01:42, 780.02it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 26688/107000 [00:38<01:42, 780.02it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  25%|██▍       | 26720/107000 [00:38<01:42, 780.02it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 26752/107000 [00:38<01:42, 780.02it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 26784/107000 [00:38<01:42, 784.56it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 26784/107000 [00:38<01:42, 784.56it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 26816/107000 [00:38<01:42, 784.56it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 26848/107000 [00:38<01:42, 784.56it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 26880/107000 [00:38<01:41, 788.02it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 26880/107000 [00:38<01:41, 788.02it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 26912/107000 [00:38<01:41, 788.02it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 26944/107000 [00:38<01:41, 788.02it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 26976/107000 [00:38<01:41, 788.32it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 26976/107000 [00:38<01:41, 788.32it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 27008/107000 [00:39<01:41, 788.32it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 27040/107000 [00:39<01:41, 788.32it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 27072/107000 [00:39<01:42, 781.78it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 27072/107000 [00:39<01:42, 781.78it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 27104/107000 [00:39<01:42, 781.78it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 27136/107000 [00:39<01:42, 781.78it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 27168/107000 [00:39<01:41, 782.97it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 27168/107000 [00:39<01:41, 782.97it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 27200/107000 [00:39<01:41, 782.97it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 27232/107000 [00:39<01:41, 782.97it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 27264/107000 [00:39<01:41, 788.74it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  25%|██▌       | 27264/107000 [00:39<01:41, 788.74it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27296/107000 [00:39<01:41, 788.74it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27328/107000 [00:39<01:41, 788.74it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27360/107000 [00:39<01:41, 787.09it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27360/107000 [00:39<01:41, 787.09it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27392/107000 [00:39<01:41, 787.09it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27424/107000 [00:39<01:41, 787.09it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27456/107000 [00:39<01:41, 785.49it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27456/107000 [00:39<01:41, 785.49it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27488/107000 [00:39<01:41, 785.49it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27520/107000 [00:39<01:41, 785.49it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27552/107000 [00:39<01:41, 783.22it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27552/107000 [00:39<01:41, 783.22it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27584/107000 [00:39<01:41, 783.22it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27616/107000 [00:39<01:41, 783.22it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27648/107000 [00:39<01:40, 786.19it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27648/107000 [00:39<01:40, 786.19it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27680/107000 [00:39<01:40, 786.19it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27712/107000 [00:39<01:40, 786.19it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27744/107000 [00:39<01:40, 792.03it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27744/107000 [00:39<01:40, 792.03it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27776/107000 [00:39<01:40, 792.03it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27808/107000 [00:40<01:39, 792.03it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27840/107000 [00:40<01:40, 788.64it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27840/107000 [00:40<01:40, 788.64it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27872/107000 [00:40<01:40, 788.64it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27904/107000 [00:40<01:40, 788.64it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27936/107000 [00:40<01:39, 792.26it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27936/107000 [00:40<01:39, 792.26it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 27968/107000 [00:40<01:39, 792.26it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 28000/107000 [00:40<01:39, 792.26it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 28032/107000 [00:40<01:40, 785.94it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 28032/107000 [00:40<01:40, 785.94it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▌       | 28064/107000 [00:40<01:40, 785.94it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 28096/107000 [00:40<01:40, 785.94it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 28128/107000 [00:40<01:41, 780.66it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 28128/107000 [00:40<01:41, 780.66it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 28160/107000 [00:40<01:40, 780.66it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 28192/107000 [00:40<01:40, 780.66it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 28224/107000 [00:40<01:40, 780.62it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 28224/107000 [00:40<01:40, 780.62it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 28256/107000 [00:40<01:40, 780.62it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 28288/107000 [00:40<01:40, 780.62it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 28320/107000 [00:40<01:40, 784.51it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 28320/107000 [00:40<01:40, 784.51it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  26%|██▋       | 28352/107000 [00:40<01:40, 784.51it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28384/107000 [00:40<01:40, 784.51it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28416/107000 [00:40<01:39, 792.92it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28416/107000 [00:40<01:39, 792.92it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28448/107000 [00:40<01:39, 792.92it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28480/107000 [00:40<01:39, 792.92it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28512/107000 [00:40<01:39, 785.93it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28512/107000 [00:40<01:39, 785.93it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28544/107000 [00:40<01:39, 785.93it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28576/107000 [00:40<01:39, 785.93it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28608/107000 [00:41<01:40, 779.17it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28608/107000 [00:41<01:40, 779.17it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28640/107000 [00:41<01:40, 779.17it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28672/107000 [00:41<01:40, 779.17it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28704/107000 [00:41<01:39, 785.38it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28704/107000 [00:41<01:39, 785.38it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28736/107000 [00:41<01:39, 785.38it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28768/107000 [00:41<01:39, 785.38it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28800/107000 [00:41<01:38, 791.67it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28800/107000 [00:41<01:38, 791.67it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28832/107000 [00:41<01:38, 791.67it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28864/107000 [00:41<01:38, 791.67it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28896/107000 [00:41<01:38, 790.50it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28896/107000 [00:41<01:38, 790.50it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28928/107000 [00:41<01:38, 790.50it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28960/107000 [00:41<01:38, 790.50it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28992/107000 [00:41<01:38, 795.04it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 28992/107000 [00:41<01:38, 795.04it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 29024/107000 [00:41<01:38, 795.04it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 29056/107000 [00:41<01:38, 795.04it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  27%|██▋       | 29088/107000 [00:41<01:38, 793.19it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 29088/107000 [00:41<01:38, 793.19it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 29120/107000 [00:41<01:38, 793.19it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 29152/107000 [00:41<01:38, 793.19it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 29184/107000 [00:41<01:38, 791.36it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 29184/107000 [00:41<01:38, 791.36it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  27%|██▋       | 29216/107000 [00:41<01:38, 791.36it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 29248/107000 [00:41<01:38, 791.36it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 29280/107000 [00:41<01:37, 793.81it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 29280/107000 [00:41<01:37, 793.81it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 29312/107000 [00:41<01:37, 793.81it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 29344/107000 [00:41<01:37, 793.81it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 29376/107000 [00:41<01:38, 787.87it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 29376/107000 [00:42<01:38, 787.87it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  27%|██▋       | 29408/107000 [00:42<01:38, 787.87it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29440/107000 [00:42<01:38, 787.87it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29472/107000 [00:42<01:38, 790.20it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29472/107000 [00:42<01:38, 790.20it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29504/107000 [00:42<01:38, 790.20it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29536/107000 [00:42<01:38, 790.20it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29568/107000 [00:42<01:37, 791.67it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29568/107000 [00:42<01:37, 791.67it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29600/107000 [00:42<01:37, 791.67it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29632/107000 [00:42<01:37, 791.67it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29664/107000 [00:42<01:37, 789.72it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29664/107000 [00:42<01:37, 789.72it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29696/107000 [00:42<01:37, 789.72it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29728/107000 [00:42<01:37, 789.72it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29760/107000 [00:42<01:38, 788.05it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29760/107000 [00:42<01:38, 788.05it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29792/107000 [00:42<01:37, 788.05it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29824/107000 [00:42<01:37, 788.05it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29856/107000 [00:42<01:37, 789.43it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29856/107000 [00:42<01:37, 789.43it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29888/107000 [00:42<01:37, 789.43it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29920/107000 [00:42<01:37, 789.43it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29952/107000 [00:42<01:37, 789.20it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29952/107000 [00:42<01:37, 789.20it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 29984/107000 [00:42<01:37, 789.20it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 30016/107000 [00:42<01:37, 789.20it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 30048/107000 [00:42<01:38, 783.62it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 30048/107000 [00:42<01:38, 783.62it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 30080/107000 [00:42<01:38, 783.62it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 30112/107000 [00:42<01:38, 783.62it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 30144/107000 [00:42<01:37, 787.67it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 30144/107000 [00:42<01:37, 787.67it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 30176/107000 [00:43<01:37, 787.67it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 30208/107000 [00:43<01:37, 787.67it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 30240/107000 [00:43<01:37, 788.08it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 30240/107000 [00:43<01:37, 788.08it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 30272/107000 [00:43<01:37, 788.08it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 30304/107000 [00:43<01:37, 788.08it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 30336/107000 [00:43<01:38, 780.65it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 30336/107000 [00:43<01:38, 780.65it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 30368/107000 [00:43<01:38, 780.65it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 30400/107000 [00:43<01:38, 780.65it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 30432/107000 [00:43<01:37, 786.70it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 30432/107000 [00:43<01:37, 786.70it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  28%|██▊       | 30464/107000 [00:43<01:37, 786.70it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 30496/107000 [00:43<01:37, 786.70it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 30528/107000 [00:43<01:36, 790.53it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 30528/107000 [00:43<01:36, 790.53it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 30560/107000 [00:43<01:36, 790.53it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 30592/107000 [00:43<01:36, 790.53it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 30624/107000 [00:43<01:36, 789.92it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 30624/107000 [00:43<01:36, 789.92it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 30656/107000 [00:43<01:36, 789.92it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 30688/107000 [00:43<01:36, 789.92it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 30720/107000 [00:43<01:36, 789.85it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 30720/107000 [00:43<01:36, 789.85it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  29%|██▊       | 30752/107000 [00:43<01:36, 789.85it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 30784/107000 [00:43<01:36, 789.85it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 30816/107000 [00:43<01:36, 789.41it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 30816/107000 [00:43<01:36, 789.41it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 30848/107000 [00:43<01:36, 789.41it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 30880/107000 [00:43<01:36, 789.41it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 30912/107000 [00:43<01:37, 784.16it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 30912/107000 [00:43<01:37, 784.16it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 30944/107000 [00:43<01:36, 784.16it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 30976/107000 [00:44<01:36, 784.16it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31008/107000 [00:44<01:36, 787.81it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31008/107000 [00:44<01:36, 787.81it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31040/107000 [00:44<01:36, 787.81it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31072/107000 [00:44<01:36, 787.81it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31104/107000 [00:44<01:39, 764.98it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31104/107000 [00:44<01:39, 764.98it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31136/107000 [00:44<01:39, 764.98it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31168/107000 [00:44<01:39, 764.98it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31200/107000 [00:44<01:37, 778.11it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31200/107000 [00:44<01:37, 778.11it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31232/107000 [00:44<01:37, 778.11it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31264/107000 [00:44<01:37, 778.11it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31296/107000 [00:44<01:36, 785.38it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31296/107000 [00:44<01:36, 785.38it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31328/107000 [00:44<01:36, 785.38it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31360/107000 [00:44<01:36, 785.38it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31392/107000 [00:44<01:35, 793.67it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31392/107000 [00:44<01:35, 793.67it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31424/107000 [00:44<01:35, 793.67it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31456/107000 [00:44<01:35, 793.67it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31488/107000 [00:44<01:34, 795.60it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31488/107000 [00:44<01:34, 795.60it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31520/107000 [00:44<01:34, 795.60it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  29%|██▉       | 31552/107000 [00:44<01:34, 795.60it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 31584/107000 [00:44<01:34, 795.81it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 31584/107000 [00:44<01:34, 795.81it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 31616/107000 [00:44<01:34, 795.81it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 31648/107000 [00:44<01:34, 795.81it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 31680/107000 [00:44<01:36, 784.33it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 31680/107000 [00:44<01:36, 784.33it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 31712/107000 [00:44<01:35, 784.33it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 31744/107000 [00:45<01:35, 784.33it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 31776/107000 [00:45<01:35, 787.69it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 31776/107000 [00:45<01:35, 787.69it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 31808/107000 [00:45<01:35, 787.69it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 31840/107000 [00:45<01:35, 787.69it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 31872/107000 [00:45<01:34, 791.11it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 31872/107000 [00:45<01:34, 791.11it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 31904/107000 [00:45<01:34, 791.11it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 31936/107000 [00:45<01:34, 791.11it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 31968/107000 [00:45<01:34, 792.77it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 31968/107000 [00:45<01:34, 792.77it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 32000/107000 [00:45<01:34, 792.77it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 32032/107000 [00:45<01:34, 792.77it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 32064/107000 [00:45<01:34, 791.85it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 32064/107000 [00:45<01:34, 791.85it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  30%|██▉       | 32096/107000 [00:45<01:34, 791.85it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  30%|███       | 32128/107000 [00:45<01:34, 791.85it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  30%|███       | 32160/107000 [00:45<01:34, 789.71it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  30%|███       | 32160/107000 [00:45<01:34, 789.71it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  30%|███       | 32192/107000 [00:45<01:34, 789.71it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  30%|███       | 32224/107000 [00:45<01:34, 789.71it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  30%|███       | 32256/107000 [00:45<01:34, 791.18it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  30%|███       | 32256/107000 [00:45<01:34, 791.18it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  30%|███       | 32288/107000 [00:45<01:34, 791.18it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  30%|███       | 32320/107000 [00:45<01:34, 791.18it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  30%|███       | 32352/107000 [00:45<01:34, 786.48it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  30%|███       | 32352/107000 [00:45<01:34, 786.48it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  30%|███       | 32384/107000 [00:45<01:34, 786.48it/s, train_loss=0.64] \u001b[A\n",
            "Epoch 1:  30%|███       | 32416/107000 [00:45<01:34, 786.48it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  30%|███       | 32448/107000 [00:45<01:34, 790.10it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  30%|███       | 32448/107000 [00:45<01:34, 790.10it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  30%|███       | 32480/107000 [00:45<01:34, 790.10it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  30%|███       | 32512/107000 [00:45<01:34, 790.10it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  30%|███       | 32544/107000 [00:45<01:34, 784.63it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  30%|███       | 32544/107000 [00:46<01:34, 784.63it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  30%|███       | 32576/107000 [00:46<01:34, 784.63it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  30%|███       | 32608/107000 [00:46<01:34, 784.63it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  31%|███       | 32640/107000 [00:46<01:34, 789.01it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  31%|███       | 32640/107000 [00:46<01:34, 789.01it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  31%|███       | 32672/107000 [00:46<01:34, 789.01it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  31%|███       | 32704/107000 [00:46<01:34, 789.01it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  31%|███       | 32736/107000 [00:46<01:34, 788.96it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  31%|███       | 32736/107000 [00:46<01:34, 788.96it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  31%|███       | 32768/107000 [00:46<01:34, 788.96it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  31%|███       | 32800/107000 [00:46<01:34, 788.96it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  31%|███       | 32832/107000 [00:46<01:33, 789.17it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  31%|███       | 32832/107000 [00:46<01:33, 789.17it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  31%|███       | 32864/107000 [00:46<01:33, 789.17it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  31%|███       | 32896/107000 [00:46<01:33, 789.17it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  31%|███       | 32928/107000 [00:46<01:34, 787.45it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  31%|███       | 32928/107000 [00:46<01:34, 787.45it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  31%|███       | 32960/107000 [00:46<01:34, 787.45it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  31%|███       | 32992/107000 [00:46<01:33, 787.45it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  31%|███       | 33024/107000 [00:46<01:35, 777.19it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  31%|███       | 33024/107000 [00:46<01:35, 777.19it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  31%|███       | 33056/107000 [00:46<01:35, 777.19it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  31%|███       | 33088/107000 [00:46<01:35, 777.19it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  31%|███       | 33120/107000 [00:46<01:34, 785.12it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  31%|███       | 33120/107000 [00:46<01:34, 785.12it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  31%|███       | 33152/107000 [00:46<01:34, 785.12it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  31%|███       | 33184/107000 [00:46<01:34, 785.12it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  31%|███       | 33216/107000 [00:46<01:33, 787.28it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  31%|███       | 33216/107000 [00:46<01:33, 787.28it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  31%|███       | 33248/107000 [00:46<01:33, 787.28it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  31%|███       | 33280/107000 [00:46<01:33, 787.28it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  31%|███       | 33312/107000 [00:46<01:33, 788.49it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  31%|███       | 33312/107000 [00:47<01:33, 788.49it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  31%|███       | 33344/107000 [00:47<01:33, 788.49it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  31%|███       | 33376/107000 [00:47<01:33, 788.49it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  31%|███       | 33408/107000 [00:47<01:33, 789.36it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  31%|███       | 33408/107000 [00:47<01:33, 789.36it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 33440/107000 [00:47<01:33, 789.36it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 33472/107000 [00:47<01:33, 789.36it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 33504/107000 [00:47<01:33, 788.22it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 33504/107000 [00:47<01:33, 788.22it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 33536/107000 [00:47<01:33, 788.22it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 33568/107000 [00:47<01:33, 788.22it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 33600/107000 [00:47<01:32, 789.62it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 33600/107000 [00:47<01:32, 789.62it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 33632/107000 [00:47<01:32, 789.62it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 33664/107000 [00:47<01:32, 789.62it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 33696/107000 [00:47<01:33, 782.46it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  31%|███▏      | 33696/107000 [00:47<01:33, 782.46it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 33728/107000 [00:47<01:33, 782.46it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 33760/107000 [00:47<01:33, 782.46it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 33792/107000 [00:47<01:32, 787.47it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 33792/107000 [00:47<01:32, 787.47it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 33824/107000 [00:47<01:32, 787.47it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 33856/107000 [00:47<01:32, 787.47it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 33888/107000 [00:47<01:32, 787.54it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 33888/107000 [00:47<01:32, 787.54it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 33920/107000 [00:47<01:32, 787.54it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 33952/107000 [00:47<01:32, 787.54it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 33984/107000 [00:47<01:32, 787.46it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 33984/107000 [00:47<01:32, 787.46it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34016/107000 [00:47<01:32, 787.46it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34048/107000 [00:47<01:32, 787.46it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34080/107000 [00:47<01:32, 790.08it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34080/107000 [00:47<01:32, 790.08it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34112/107000 [00:48<01:32, 790.08it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34144/107000 [00:48<01:32, 790.08it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34176/107000 [00:48<01:32, 784.52it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34176/107000 [00:48<01:32, 784.52it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34208/107000 [00:48<01:32, 784.52it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34240/107000 [00:48<01:32, 784.52it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34272/107000 [00:48<01:32, 790.27it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34272/107000 [00:48<01:32, 790.27it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34304/107000 [00:48<01:31, 790.27it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34336/107000 [00:48<01:31, 790.27it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34368/107000 [00:48<01:31, 789.50it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34368/107000 [00:48<01:31, 789.50it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34400/107000 [00:48<01:31, 789.50it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34432/107000 [00:48<01:31, 789.50it/s, train_loss=0.64] \u001b[A\n",
            "Epoch 1:  32%|███▏      | 34464/107000 [00:48<01:31, 791.44it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34464/107000 [00:48<01:31, 791.44it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34496/107000 [00:48<01:31, 791.44it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34528/107000 [00:48<01:31, 791.44it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34560/107000 [00:48<01:31, 790.09it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34560/107000 [00:48<01:31, 790.09it/s, train_loss=0.64] \u001b[A\n",
            "Epoch 1:  32%|███▏      | 34592/107000 [00:48<01:31, 790.09it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34624/107000 [00:48<01:31, 790.09it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34656/107000 [00:48<01:31, 789.34it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34656/107000 [00:48<01:31, 789.34it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34688/107000 [00:48<01:31, 789.34it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34720/107000 [00:48<01:31, 789.34it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34752/107000 [00:48<01:31, 788.24it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  32%|███▏      | 34752/107000 [00:48<01:31, 788.24it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 34784/107000 [00:48<01:31, 788.24it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 34816/107000 [00:48<01:31, 788.24it/s, train_loss=0.64] \u001b[A\n",
            "Epoch 1:  33%|███▎      | 34848/107000 [00:48<01:31, 785.34it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 34848/107000 [00:48<01:31, 785.34it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 34880/107000 [00:48<01:31, 785.34it/s, train_loss=0.64] \u001b[A\n",
            "Epoch 1:  33%|███▎      | 34912/107000 [00:49<01:31, 785.34it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 34944/107000 [00:49<01:31, 786.64it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 34944/107000 [00:49<01:31, 786.64it/s, train_loss=0.64] \u001b[A\n",
            "Epoch 1:  33%|███▎      | 34976/107000 [00:49<01:31, 786.64it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35008/107000 [00:49<01:31, 786.64it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35040/107000 [00:49<01:31, 785.85it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35040/107000 [00:49<01:31, 785.85it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35072/107000 [00:49<01:31, 785.85it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35104/107000 [00:49<01:31, 785.85it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35136/107000 [00:49<01:31, 785.44it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35136/107000 [00:49<01:31, 785.44it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35168/107000 [00:49<01:31, 785.44it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35200/107000 [00:49<01:31, 785.44it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35232/107000 [00:49<01:30, 790.60it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35232/107000 [00:49<01:30, 790.60it/s, train_loss=0.64] \u001b[A\n",
            "Epoch 1:  33%|███▎      | 35264/107000 [00:49<01:30, 790.60it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35296/107000 [00:49<01:30, 790.60it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35328/107000 [00:49<01:30, 787.97it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35328/107000 [00:49<01:30, 787.97it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35360/107000 [00:49<01:30, 787.97it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35392/107000 [00:49<01:30, 787.97it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35424/107000 [00:49<01:30, 789.77it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35424/107000 [00:49<01:30, 789.77it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35456/107000 [00:49<01:30, 789.77it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35488/107000 [00:49<01:30, 789.77it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35520/107000 [00:49<01:30, 789.50it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35520/107000 [00:49<01:30, 789.50it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35552/107000 [00:49<01:30, 789.50it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35584/107000 [00:49<01:30, 789.50it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35616/107000 [00:49<01:30, 789.70it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35616/107000 [00:49<01:30, 789.70it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35648/107000 [00:49<01:30, 789.70it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35680/107000 [00:50<01:30, 789.70it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35712/107000 [00:50<01:30, 788.23it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35712/107000 [00:50<01:30, 788.23it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35744/107000 [00:50<01:30, 788.23it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35776/107000 [00:50<01:30, 788.23it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35808/107000 [00:50<01:30, 787.20it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35808/107000 [00:50<01:30, 787.20it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  33%|███▎      | 35840/107000 [00:50<01:30, 787.20it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 35872/107000 [00:50<01:30, 787.20it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 35904/107000 [00:50<01:30, 787.61it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 35904/107000 [00:50<01:30, 787.61it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 35936/107000 [00:50<01:30, 787.61it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 35968/107000 [00:50<01:30, 787.61it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 36000/107000 [00:50<01:30, 780.97it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 36000/107000 [00:50<01:30, 780.97it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 36032/107000 [00:50<01:30, 780.97it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 36064/107000 [00:50<01:30, 780.97it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 36096/107000 [00:50<01:30, 785.88it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  34%|███▎      | 36096/107000 [00:50<01:30, 785.88it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36128/107000 [00:50<01:30, 785.88it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36160/107000 [00:50<01:30, 785.88it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36192/107000 [00:50<01:30, 783.07it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36192/107000 [00:50<01:30, 783.07it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36224/107000 [00:50<01:30, 783.07it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36256/107000 [00:50<01:30, 783.07it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36288/107000 [00:50<01:29, 785.69it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36288/107000 [00:50<01:29, 785.69it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36320/107000 [00:50<01:29, 785.69it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36352/107000 [00:50<01:29, 785.69it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36384/107000 [00:50<01:29, 791.23it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36384/107000 [00:50<01:29, 791.23it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36416/107000 [00:50<01:29, 791.23it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36448/107000 [00:50<01:29, 791.23it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36480/107000 [00:50<01:28, 792.54it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36480/107000 [00:51<01:28, 792.54it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36512/107000 [00:51<01:28, 792.54it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36544/107000 [00:51<01:28, 792.54it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36576/107000 [00:51<01:28, 793.09it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36576/107000 [00:51<01:28, 793.09it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36608/107000 [00:51<01:28, 793.09it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36640/107000 [00:51<01:28, 793.09it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36672/107000 [00:51<01:29, 789.97it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36672/107000 [00:51<01:29, 789.97it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36704/107000 [00:51<01:28, 789.97it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36736/107000 [00:51<01:28, 789.97it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36768/107000 [00:51<01:29, 784.81it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36768/107000 [00:51<01:29, 784.81it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36800/107000 [00:51<01:29, 784.81it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36832/107000 [00:51<01:29, 784.81it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36864/107000 [00:51<01:29, 786.00it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36864/107000 [00:51<01:29, 786.00it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  34%|███▍      | 36896/107000 [00:51<01:29, 786.00it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 36928/107000 [00:51<01:29, 786.00it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 36960/107000 [00:51<01:31, 768.63it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 36960/107000 [00:51<01:31, 768.63it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 36992/107000 [00:51<01:31, 768.63it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 37024/107000 [00:51<01:31, 768.63it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 37056/107000 [00:51<01:32, 752.68it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 37056/107000 [00:51<01:32, 752.68it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 37088/107000 [00:51<01:32, 752.68it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 37120/107000 [00:51<01:32, 752.68it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 37152/107000 [00:51<01:31, 764.11it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 37152/107000 [00:51<01:31, 764.11it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 37184/107000 [00:51<01:31, 764.11it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 37216/107000 [00:51<01:31, 764.11it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 37248/107000 [00:51<01:30, 766.72it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 37248/107000 [00:52<01:30, 766.72it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 37280/107000 [00:52<01:30, 766.72it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 37312/107000 [00:52<01:30, 766.72it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 37344/107000 [00:52<01:30, 766.06it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 37344/107000 [00:52<01:30, 766.06it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 37376/107000 [00:52<01:30, 766.06it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 37408/107000 [00:52<01:30, 766.06it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 37440/107000 [00:52<01:31, 763.66it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  35%|███▍      | 37440/107000 [00:52<01:31, 763.66it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 37472/107000 [00:52<01:31, 763.66it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 37504/107000 [00:52<01:31, 763.66it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 37536/107000 [00:52<01:32, 753.35it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 37536/107000 [00:52<01:32, 753.35it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 37568/107000 [00:52<01:32, 753.35it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 37600/107000 [00:52<01:32, 753.35it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 37632/107000 [00:52<01:34, 736.52it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 37632/107000 [00:52<01:34, 736.52it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 37664/107000 [00:52<01:34, 736.52it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 37696/107000 [00:52<01:34, 736.52it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 37728/107000 [00:52<01:33, 741.37it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 37728/107000 [00:52<01:33, 741.37it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 37760/107000 [00:52<01:33, 741.37it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 37792/107000 [00:52<01:33, 741.37it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 37824/107000 [00:52<01:33, 740.55it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 37824/107000 [00:52<01:33, 740.55it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 37856/107000 [00:52<01:33, 740.55it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 37888/107000 [00:52<01:33, 740.55it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 37920/107000 [00:52<01:32, 743.35it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 37920/107000 [00:52<01:32, 743.35it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 37952/107000 [00:52<01:32, 743.35it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  35%|███▌      | 37984/107000 [00:53<01:32, 743.35it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38016/107000 [00:53<01:31, 757.02it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38016/107000 [00:53<01:31, 757.02it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38048/107000 [00:53<01:31, 757.02it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38080/107000 [00:53<01:31, 757.02it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38112/107000 [00:53<01:29, 766.79it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38112/107000 [00:53<01:29, 766.79it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38144/107000 [00:53<01:29, 766.79it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38176/107000 [00:53<01:29, 766.79it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38208/107000 [00:53<01:28, 774.38it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38208/107000 [00:53<01:28, 774.38it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38240/107000 [00:53<01:28, 774.38it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38272/107000 [00:53<01:28, 774.38it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38304/107000 [00:53<01:28, 773.93it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38304/107000 [00:53<01:28, 773.93it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38336/107000 [00:53<01:28, 773.93it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38368/107000 [00:53<01:28, 773.93it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38400/107000 [00:53<01:28, 777.83it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38400/107000 [00:53<01:28, 777.83it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38432/107000 [00:53<01:28, 777.83it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38464/107000 [00:53<01:28, 777.83it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38496/107000 [00:53<01:27, 783.92it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38496/107000 [00:53<01:27, 783.92it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38528/107000 [00:53<01:27, 783.92it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38560/107000 [00:53<01:27, 783.92it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38592/107000 [00:53<01:28, 774.63it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38592/107000 [00:53<01:28, 774.63it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38624/107000 [00:53<01:28, 774.63it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38656/107000 [00:53<01:28, 774.63it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38688/107000 [00:53<01:27, 784.63it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38688/107000 [00:53<01:27, 784.63it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38720/107000 [00:53<01:27, 784.63it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38752/107000 [00:53<01:26, 784.63it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38784/107000 [00:53<01:26, 789.64it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  36%|███▌      | 38784/107000 [00:54<01:26, 789.64it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 38816/107000 [00:54<01:26, 789.64it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 38848/107000 [00:54<01:26, 789.64it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 38880/107000 [00:54<01:26, 790.43it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 38880/107000 [00:54<01:26, 790.43it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 38912/107000 [00:54<01:26, 790.43it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 38944/107000 [00:54<01:26, 790.43it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 38976/107000 [00:54<01:26, 788.07it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 38976/107000 [00:54<01:26, 788.07it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 39008/107000 [00:54<01:26, 788.07it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  36%|███▋      | 39040/107000 [00:54<01:26, 788.07it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39072/107000 [00:54<01:26, 788.64it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39072/107000 [00:54<01:26, 788.64it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39104/107000 [00:54<01:26, 788.64it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39136/107000 [00:54<01:26, 788.64it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39168/107000 [00:54<01:26, 781.81it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39168/107000 [00:54<01:26, 781.81it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39200/107000 [00:54<01:26, 781.81it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39232/107000 [00:54<01:26, 781.81it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39264/107000 [00:54<01:25, 790.18it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39264/107000 [00:54<01:25, 790.18it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39296/107000 [00:54<01:25, 790.18it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39328/107000 [00:54<01:25, 790.18it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39360/107000 [00:54<01:25, 790.17it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39360/107000 [00:54<01:25, 790.17it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39392/107000 [00:54<01:25, 790.17it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39424/107000 [00:54<01:25, 790.17it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39456/107000 [00:54<01:25, 790.09it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39456/107000 [00:54<01:25, 790.09it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39488/107000 [00:54<01:25, 790.09it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39520/107000 [00:54<01:25, 790.09it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39552/107000 [00:54<01:25, 786.89it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39552/107000 [00:55<01:25, 786.89it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39584/107000 [00:55<01:25, 786.89it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39616/107000 [00:55<01:25, 786.89it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39648/107000 [00:55<01:25, 788.09it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39648/107000 [00:55<01:25, 788.09it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39680/107000 [00:55<01:25, 788.09it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39712/107000 [00:55<01:25, 788.09it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39744/107000 [00:55<01:25, 789.29it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39744/107000 [00:55<01:25, 789.29it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39776/107000 [00:55<01:25, 789.29it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39808/107000 [00:55<01:25, 789.29it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39840/107000 [00:55<01:25, 789.00it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39840/107000 [00:55<01:25, 789.00it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39872/107000 [00:55<01:25, 789.00it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39904/107000 [00:55<01:25, 789.00it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39936/107000 [00:55<01:25, 788.60it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39936/107000 [00:55<01:25, 788.60it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 39968/107000 [00:55<01:25, 788.60it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 40000/107000 [00:55<01:24, 788.60it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 40032/107000 [00:55<01:26, 776.89it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 40032/107000 [00:55<01:26, 776.89it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 40064/107000 [00:55<01:26, 776.89it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  37%|███▋      | 40096/107000 [00:55<01:26, 776.89it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40128/107000 [00:55<01:28, 757.79it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40128/107000 [00:55<01:28, 757.79it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40160/107000 [00:55<01:28, 757.79it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40192/107000 [00:55<01:28, 757.79it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40224/107000 [00:55<01:29, 746.11it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40224/107000 [00:55<01:29, 746.11it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40256/107000 [00:55<01:29, 746.11it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40288/107000 [00:55<01:29, 746.11it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40320/107000 [00:55<01:30, 735.71it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40320/107000 [00:56<01:30, 735.71it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40352/107000 [00:56<01:30, 735.71it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40384/107000 [00:56<01:30, 735.71it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40416/107000 [00:56<01:31, 724.81it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40416/107000 [00:56<01:31, 724.81it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40448/107000 [00:56<01:31, 724.81it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40480/107000 [00:56<01:31, 724.81it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40512/107000 [00:56<01:30, 732.31it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40512/107000 [00:56<01:30, 732.31it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40544/107000 [00:56<01:30, 732.31it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40576/107000 [00:56<01:30, 732.31it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40608/107000 [00:56<01:28, 753.39it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40608/107000 [00:56<01:28, 753.39it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40640/107000 [00:56<01:28, 753.39it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40672/107000 [00:56<01:28, 753.39it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40704/107000 [00:56<01:27, 758.49it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40704/107000 [00:56<01:27, 758.49it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40736/107000 [00:56<01:27, 758.49it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40768/107000 [00:56<01:27, 758.49it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40800/107000 [00:56<01:26, 767.81it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40800/107000 [00:56<01:26, 767.81it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40832/107000 [00:56<01:26, 767.81it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40864/107000 [00:56<01:26, 767.81it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40896/107000 [00:56<01:25, 776.12it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40896/107000 [00:56<01:25, 776.12it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40928/107000 [00:56<01:25, 776.12it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40960/107000 [00:56<01:25, 776.12it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40992/107000 [00:56<01:25, 770.14it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 40992/107000 [00:56<01:25, 770.14it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 41024/107000 [00:56<01:25, 770.14it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 41056/107000 [00:56<01:25, 770.14it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 41088/107000 [00:56<01:24, 782.89it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 41088/107000 [00:57<01:24, 782.89it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 41120/107000 [00:57<01:24, 782.89it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 41152/107000 [00:57<01:24, 782.89it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 41184/107000 [00:57<01:25, 765.40it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  38%|███▊      | 41184/107000 [00:57<01:25, 765.40it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 41216/107000 [00:57<01:25, 765.40it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 41248/107000 [00:57<01:25, 765.40it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 41280/107000 [00:57<01:28, 746.01it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 41280/107000 [00:57<01:28, 746.01it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 41312/107000 [00:57<01:28, 746.01it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 41344/107000 [00:57<01:28, 746.01it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 41376/107000 [00:57<01:27, 753.30it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 41376/107000 [00:57<01:27, 753.30it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 41408/107000 [00:57<01:27, 753.30it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  39%|███▊      | 41440/107000 [00:57<01:27, 753.30it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 41472/107000 [00:57<01:27, 752.61it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 41472/107000 [00:57<01:27, 752.61it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 41504/107000 [00:57<01:27, 752.61it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 41536/107000 [00:57<01:26, 752.61it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 41568/107000 [00:57<01:28, 742.90it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 41568/107000 [00:57<01:28, 742.90it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 41600/107000 [00:57<01:28, 742.90it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 41632/107000 [00:57<01:27, 742.90it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 41664/107000 [00:57<01:26, 758.75it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 41664/107000 [00:57<01:26, 758.75it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 41696/107000 [00:57<01:26, 758.75it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 41728/107000 [00:57<01:26, 758.75it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 41760/107000 [00:57<01:24, 768.88it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 41760/107000 [00:57<01:24, 768.88it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 41792/107000 [00:57<01:24, 768.88it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 41824/107000 [00:57<01:24, 768.88it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 41856/107000 [00:57<01:23, 775.73it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 41856/107000 [00:58<01:23, 775.73it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 41888/107000 [00:58<01:23, 775.73it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 41920/107000 [00:58<01:23, 775.73it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 41952/107000 [00:58<01:24, 773.96it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 41952/107000 [00:58<01:24, 773.96it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 41984/107000 [00:58<01:24, 773.96it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 42016/107000 [00:58<01:23, 773.96it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 42048/107000 [00:58<01:24, 772.03it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 42048/107000 [00:58<01:24, 772.03it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 42080/107000 [00:58<01:24, 772.03it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 42112/107000 [00:58<01:24, 772.03it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 42144/107000 [00:58<01:23, 781.31it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 42144/107000 [00:58<01:23, 781.31it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 42176/107000 [00:58<01:22, 781.31it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 42208/107000 [00:58<01:22, 781.31it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 42240/107000 [00:58<01:22, 789.02it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  39%|███▉      | 42240/107000 [00:58<01:22, 789.02it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 42272/107000 [00:58<01:22, 789.02it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 42304/107000 [00:58<01:21, 789.02it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 42336/107000 [00:58<01:21, 790.82it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 42336/107000 [00:58<01:21, 790.82it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 42368/107000 [00:58<01:21, 790.82it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 42400/107000 [00:58<01:21, 790.82it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 42432/107000 [00:58<01:22, 781.97it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 42432/107000 [00:58<01:22, 781.97it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 42464/107000 [00:58<01:22, 781.97it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 42496/107000 [00:58<01:22, 781.97it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 42528/107000 [00:58<01:22, 784.04it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 42528/107000 [00:58<01:22, 784.04it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 42560/107000 [00:58<01:22, 784.04it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 42592/107000 [00:58<01:22, 784.04it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 42624/107000 [00:58<01:22, 784.78it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 42624/107000 [00:59<01:22, 784.78it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 42656/107000 [00:59<01:21, 784.78it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 42688/107000 [00:59<01:21, 784.78it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 42720/107000 [00:59<01:21, 787.63it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 42720/107000 [00:59<01:21, 787.63it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 42752/107000 [00:59<01:21, 787.63it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|███▉      | 42784/107000 [00:59<01:21, 787.63it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|████      | 42816/107000 [00:59<01:21, 790.20it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|████      | 42816/107000 [00:59<01:21, 790.20it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  40%|████      | 42848/107000 [00:59<01:21, 790.20it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|████      | 42880/107000 [00:59<01:21, 790.20it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|████      | 42912/107000 [00:59<01:21, 790.20it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|████      | 42912/107000 [00:59<01:21, 790.20it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  40%|████      | 42944/107000 [00:59<01:21, 790.20it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  40%|████      | 42976/107000 [00:59<01:21, 790.20it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  40%|████      | 43008/107000 [00:59<01:21, 789.77it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  40%|████      | 43008/107000 [00:59<01:21, 789.77it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  40%|████      | 43040/107000 [00:59<01:20, 789.77it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|████      | 43072/107000 [00:59<01:20, 789.77it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|████      | 43104/107000 [00:59<01:21, 787.29it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|████      | 43104/107000 [00:59<01:21, 787.29it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|████      | 43136/107000 [00:59<01:21, 787.29it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|████      | 43168/107000 [00:59<01:21, 787.29it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|████      | 43200/107000 [00:59<01:21, 779.18it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|████      | 43200/107000 [00:59<01:21, 779.18it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|████      | 43232/107000 [00:59<01:21, 779.18it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|████      | 43264/107000 [00:59<01:21, 779.18it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|████      | 43296/107000 [00:59<01:21, 785.22it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|████      | 43296/107000 [00:59<01:21, 785.22it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  40%|████      | 43328/107000 [00:59<01:21, 785.22it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  41%|████      | 43360/107000 [00:59<01:21, 785.22it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  41%|████      | 43392/107000 [00:59<01:20, 787.28it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  41%|████      | 43392/107000 [00:59<01:20, 787.28it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  41%|████      | 43424/107000 [01:00<01:20, 787.28it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  41%|████      | 43456/107000 [01:00<01:20, 787.28it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  41%|████      | 43488/107000 [01:00<01:20, 787.36it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  41%|████      | 43488/107000 [01:00<01:20, 787.36it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  41%|████      | 43520/107000 [01:00<01:20, 787.36it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  41%|████      | 43552/107000 [01:00<01:20, 787.36it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  41%|████      | 43584/107000 [01:00<01:20, 786.91it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  41%|████      | 43584/107000 [01:00<01:20, 786.91it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  41%|████      | 43616/107000 [01:00<01:20, 786.91it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  41%|████      | 43648/107000 [01:00<01:20, 786.91it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  41%|████      | 43680/107000 [01:00<01:20, 787.94it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  41%|████      | 43680/107000 [01:00<01:20, 787.94it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  41%|████      | 43712/107000 [01:00<01:20, 787.94it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  41%|████      | 43744/107000 [01:00<01:20, 787.94it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  41%|████      | 43776/107000 [01:00<01:20, 787.48it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  41%|████      | 43776/107000 [01:00<01:20, 787.48it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  41%|████      | 43808/107000 [01:00<01:20, 787.48it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  41%|████      | 43840/107000 [01:00<01:20, 787.48it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  41%|████      | 43872/107000 [01:00<01:19, 791.49it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  41%|████      | 43872/107000 [01:00<01:19, 791.49it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  41%|████      | 43904/107000 [01:00<01:19, 791.49it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  41%|████      | 43936/107000 [01:00<01:19, 791.49it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  41%|████      | 43968/107000 [01:00<01:19, 788.67it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  41%|████      | 43968/107000 [01:00<01:19, 788.67it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  41%|████      | 44000/107000 [01:00<01:19, 788.67it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  41%|████      | 44032/107000 [01:00<01:19, 788.67it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  41%|████      | 44064/107000 [01:00<01:20, 785.30it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  41%|████      | 44064/107000 [01:00<01:20, 785.30it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  41%|████      | 44096/107000 [01:00<01:20, 785.30it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  41%|████      | 44128/107000 [01:00<01:20, 785.30it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 44160/107000 [01:00<01:19, 786.80it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 44160/107000 [01:00<01:19, 786.80it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 44192/107000 [01:01<01:19, 786.80it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 44224/107000 [01:01<01:19, 786.80it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 44256/107000 [01:01<01:19, 791.05it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 44256/107000 [01:01<01:19, 791.05it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 44288/107000 [01:01<01:19, 791.05it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 44320/107000 [01:01<01:19, 791.05it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 44352/107000 [01:01<01:19, 790.14it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 44352/107000 [01:01<01:19, 790.14it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  41%|████▏     | 44384/107000 [01:01<01:19, 790.14it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44416/107000 [01:01<01:19, 790.14it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44448/107000 [01:01<01:19, 786.43it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44448/107000 [01:01<01:19, 786.43it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44480/107000 [01:01<01:19, 786.43it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44512/107000 [01:01<01:19, 786.43it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44544/107000 [01:01<01:19, 788.48it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44544/107000 [01:01<01:19, 788.48it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44576/107000 [01:01<01:19, 788.48it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44608/107000 [01:01<01:19, 788.48it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44640/107000 [01:01<01:18, 790.01it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44640/107000 [01:01<01:18, 790.01it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44672/107000 [01:01<01:18, 790.01it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44704/107000 [01:01<01:18, 790.01it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44736/107000 [01:01<01:18, 790.51it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44736/107000 [01:01<01:18, 790.51it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44768/107000 [01:01<01:18, 790.51it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44800/107000 [01:01<01:18, 790.51it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44832/107000 [01:01<01:19, 781.04it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44832/107000 [01:01<01:19, 781.04it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44864/107000 [01:01<01:19, 781.04it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44896/107000 [01:01<01:19, 781.04it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44928/107000 [01:01<01:18, 788.82it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44928/107000 [01:01<01:18, 788.82it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44960/107000 [01:01<01:18, 788.82it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 44992/107000 [01:02<01:18, 788.82it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 45024/107000 [01:02<01:18, 787.36it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 45024/107000 [01:02<01:18, 787.36it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 45056/107000 [01:02<01:18, 787.36it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 45088/107000 [01:02<01:18, 787.36it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 45120/107000 [01:02<01:18, 787.67it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 45120/107000 [01:02<01:18, 787.67it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 45152/107000 [01:02<01:18, 787.67it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 45184/107000 [01:02<01:18, 787.67it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 45216/107000 [01:02<01:18, 788.51it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 45216/107000 [01:02<01:18, 788.51it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 45248/107000 [01:02<01:18, 788.51it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 45280/107000 [01:02<01:18, 788.51it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 45312/107000 [01:02<01:18, 786.49it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 45312/107000 [01:02<01:18, 786.49it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 45344/107000 [01:02<01:18, 786.49it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 45376/107000 [01:02<01:18, 786.49it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 45408/107000 [01:02<01:18, 789.35it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 45408/107000 [01:02<01:18, 789.35it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 45440/107000 [01:02<01:17, 789.35it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  42%|████▏     | 45472/107000 [01:02<01:17, 789.35it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 45504/107000 [01:02<01:17, 788.49it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 45504/107000 [01:02<01:17, 788.49it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 45536/107000 [01:02<01:17, 788.49it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 45568/107000 [01:02<01:17, 788.49it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 45600/107000 [01:02<01:18, 785.25it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 45600/107000 [01:02<01:18, 785.25it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 45632/107000 [01:02<01:18, 785.25it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 45664/107000 [01:02<01:18, 785.25it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 45696/107000 [01:02<01:18, 782.56it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 45696/107000 [01:02<01:18, 782.56it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 45728/107000 [01:02<01:18, 782.56it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 45760/107000 [01:02<01:18, 782.56it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 45792/107000 [01:02<01:17, 789.05it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 45792/107000 [01:03<01:17, 789.05it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 45824/107000 [01:03<01:17, 789.05it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 45856/107000 [01:03<01:17, 789.05it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 45888/107000 [01:03<01:17, 788.02it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 45888/107000 [01:03<01:17, 788.02it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 45920/107000 [01:03<01:17, 788.02it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 45952/107000 [01:03<01:17, 788.02it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 45984/107000 [01:03<01:17, 785.43it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 45984/107000 [01:03<01:17, 785.43it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 46016/107000 [01:03<01:17, 785.43it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 46048/107000 [01:03<01:17, 785.43it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 46080/107000 [01:03<01:17, 783.42it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 46080/107000 [01:03<01:17, 783.42it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 46112/107000 [01:03<01:17, 783.42it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 46144/107000 [01:03<01:17, 783.42it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 46176/107000 [01:03<01:16, 790.98it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 46176/107000 [01:03<01:16, 790.98it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 46208/107000 [01:03<01:16, 790.98it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 46240/107000 [01:03<01:16, 790.98it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 46272/107000 [01:03<01:17, 788.01it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 46272/107000 [01:03<01:17, 788.01it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 46304/107000 [01:03<01:17, 788.01it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 46336/107000 [01:03<01:16, 788.01it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 46368/107000 [01:03<01:16, 788.81it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 46368/107000 [01:03<01:16, 788.81it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 46400/107000 [01:03<01:16, 788.81it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 46432/107000 [01:03<01:16, 788.81it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 46464/107000 [01:03<01:17, 784.51it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 46464/107000 [01:03<01:17, 784.51it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 46496/107000 [01:03<01:17, 784.51it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  43%|████▎     | 46528/107000 [01:03<01:17, 784.51it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 46560/107000 [01:03<01:17, 779.38it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 46560/107000 [01:04<01:17, 779.38it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 46592/107000 [01:04<01:17, 779.38it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 46624/107000 [01:04<01:17, 779.38it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 46656/107000 [01:04<01:17, 782.00it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 46656/107000 [01:04<01:17, 782.00it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 46688/107000 [01:04<01:17, 782.00it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 46720/107000 [01:04<01:17, 782.00it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 46752/107000 [01:04<01:16, 787.18it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 46752/107000 [01:04<01:16, 787.18it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  44%|████▎     | 46784/107000 [01:04<01:16, 787.18it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 46816/107000 [01:04<01:16, 787.18it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 46848/107000 [01:04<01:18, 769.77it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 46848/107000 [01:04<01:18, 769.77it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 46880/107000 [01:04<01:18, 769.77it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 46912/107000 [01:04<01:18, 769.77it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 46944/107000 [01:04<01:18, 769.50it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 46944/107000 [01:04<01:18, 769.50it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 46976/107000 [01:04<01:18, 769.50it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47008/107000 [01:04<01:17, 769.50it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47040/107000 [01:04<01:18, 761.08it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47040/107000 [01:04<01:18, 761.08it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47072/107000 [01:04<01:18, 761.08it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47104/107000 [01:04<01:18, 761.08it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47136/107000 [01:04<01:18, 762.08it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47136/107000 [01:04<01:18, 762.08it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47168/107000 [01:04<01:18, 762.08it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47200/107000 [01:04<01:18, 762.08it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47232/107000 [01:04<01:18, 757.92it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47232/107000 [01:04<01:18, 757.92it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47264/107000 [01:04<01:18, 757.92it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47296/107000 [01:04<01:18, 757.92it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47328/107000 [01:04<01:19, 748.78it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47328/107000 [01:05<01:19, 748.78it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47360/107000 [01:05<01:19, 748.78it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47392/107000 [01:05<01:19, 748.78it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47424/107000 [01:05<01:18, 759.16it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47424/107000 [01:05<01:18, 759.16it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47456/107000 [01:05<01:18, 759.16it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47488/107000 [01:05<01:18, 759.16it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47520/107000 [01:05<01:17, 771.66it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47520/107000 [01:05<01:17, 771.66it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47552/107000 [01:05<01:17, 771.66it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  44%|████▍     | 47584/107000 [01:05<01:16, 771.66it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 47616/107000 [01:05<01:17, 763.42it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 47616/107000 [01:05<01:17, 763.42it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 47648/107000 [01:05<01:17, 763.42it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 47680/107000 [01:05<01:17, 763.42it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 47712/107000 [01:05<01:16, 772.47it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 47712/107000 [01:05<01:16, 772.47it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  45%|████▍     | 47744/107000 [01:05<01:16, 772.47it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 47776/107000 [01:05<01:16, 772.47it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 47808/107000 [01:05<01:17, 761.28it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 47808/107000 [01:05<01:17, 761.28it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 47840/107000 [01:05<01:17, 761.28it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 47872/107000 [01:05<01:17, 761.28it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 47904/107000 [01:05<01:18, 752.99it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 47904/107000 [01:05<01:18, 752.99it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 47936/107000 [01:05<01:18, 752.99it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  45%|████▍     | 47968/107000 [01:05<01:18, 752.99it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 48000/107000 [01:05<01:18, 752.66it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 48000/107000 [01:05<01:18, 752.66it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 48032/107000 [01:05<01:18, 752.66it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 48064/107000 [01:05<01:18, 752.66it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 48096/107000 [01:05<01:17, 757.94it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 48096/107000 [01:06<01:17, 757.94it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  45%|████▍     | 48128/107000 [01:06<01:17, 757.94it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 48160/107000 [01:06<01:17, 757.94it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 48192/107000 [01:06<01:18, 753.48it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 48192/107000 [01:06<01:18, 753.48it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 48224/107000 [01:06<01:18, 753.48it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 48256/107000 [01:06<01:17, 753.48it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 48288/107000 [01:06<01:17, 760.37it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 48288/107000 [01:06<01:17, 760.37it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 48320/107000 [01:06<01:17, 760.37it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 48352/107000 [01:06<01:17, 760.37it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 48384/107000 [01:06<01:17, 752.02it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 48384/107000 [01:06<01:17, 752.02it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 48416/107000 [01:06<01:17, 752.02it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 48448/107000 [01:06<01:17, 752.02it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 48480/107000 [01:06<01:17, 754.09it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 48480/107000 [01:06<01:17, 754.09it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 48512/107000 [01:06<01:17, 754.09it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 48544/107000 [01:06<01:17, 754.09it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 48576/107000 [01:06<01:18, 739.58it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 48576/107000 [01:06<01:18, 739.58it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 48608/107000 [01:06<01:18, 739.58it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 48640/107000 [01:06<01:18, 739.58it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 48672/107000 [01:06<01:18, 741.80it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  45%|████▌     | 48672/107000 [01:06<01:18, 741.80it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 48704/107000 [01:06<01:18, 741.80it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 48736/107000 [01:06<01:18, 741.80it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 48768/107000 [01:06<01:18, 739.18it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 48768/107000 [01:06<01:18, 739.18it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 48800/107000 [01:06<01:18, 739.18it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 48832/107000 [01:07<01:18, 739.18it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 48864/107000 [01:07<01:17, 747.38it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 48864/107000 [01:07<01:17, 747.38it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 48896/107000 [01:07<01:17, 747.38it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 48928/107000 [01:07<01:17, 747.38it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 48960/107000 [01:07<01:16, 762.61it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 48960/107000 [01:07<01:16, 762.61it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 48992/107000 [01:07<01:16, 762.61it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 49024/107000 [01:07<01:16, 762.61it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 49056/107000 [01:07<01:14, 772.96it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 49056/107000 [01:07<01:14, 772.96it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 49088/107000 [01:07<01:14, 772.96it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 49120/107000 [01:07<01:14, 772.96it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 49152/107000 [01:07<01:15, 764.28it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 49152/107000 [01:07<01:15, 764.28it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 49184/107000 [01:07<01:15, 764.28it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 49216/107000 [01:07<01:15, 764.28it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 49248/107000 [01:07<01:16, 755.88it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 49248/107000 [01:07<01:16, 755.88it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 49280/107000 [01:07<01:16, 755.88it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 49312/107000 [01:07<01:16, 755.88it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 49344/107000 [01:07<01:17, 744.57it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 49344/107000 [01:07<01:17, 744.57it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 49376/107000 [01:07<01:17, 744.57it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 49408/107000 [01:07<01:17, 744.57it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 49440/107000 [01:07<01:17, 744.15it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 49440/107000 [01:07<01:17, 744.15it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  46%|████▌     | 49472/107000 [01:07<01:17, 744.15it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 49504/107000 [01:07<01:17, 744.15it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 49536/107000 [01:07<01:16, 748.49it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 49536/107000 [01:07<01:16, 748.49it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 49568/107000 [01:07<01:16, 748.49it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 49600/107000 [01:08<01:16, 748.49it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 49632/107000 [01:08<01:15, 758.16it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 49632/107000 [01:08<01:15, 758.16it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 49664/107000 [01:08<01:15, 758.16it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 49696/107000 [01:08<01:15, 758.16it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 49728/107000 [01:08<01:14, 769.74it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  46%|████▋     | 49728/107000 [01:08<01:14, 769.74it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 49760/107000 [01:08<01:14, 769.74it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 49792/107000 [01:08<01:14, 769.74it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 49824/107000 [01:08<01:13, 776.72it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 49824/107000 [01:08<01:13, 776.72it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 49856/107000 [01:08<01:13, 776.72it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 49888/107000 [01:08<01:13, 776.72it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 49920/107000 [01:08<01:13, 779.33it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 49920/107000 [01:08<01:13, 779.33it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 49952/107000 [01:08<01:13, 779.33it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 49984/107000 [01:08<01:13, 779.33it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50016/107000 [01:08<01:13, 779.06it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50016/107000 [01:08<01:13, 779.06it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50048/107000 [01:08<01:13, 779.06it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50080/107000 [01:08<01:13, 779.06it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50112/107000 [01:08<01:12, 784.38it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50112/107000 [01:08<01:12, 784.38it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50144/107000 [01:08<01:12, 784.38it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50176/107000 [01:08<01:12, 784.38it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50208/107000 [01:08<01:12, 785.60it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50208/107000 [01:08<01:12, 785.60it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50240/107000 [01:08<01:12, 785.60it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50272/107000 [01:08<01:12, 785.60it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50304/107000 [01:08<01:12, 784.58it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50304/107000 [01:08<01:12, 784.58it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50336/107000 [01:08<01:12, 784.58it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50368/107000 [01:09<01:12, 784.58it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50400/107000 [01:09<01:12, 784.84it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50400/107000 [01:09<01:12, 784.84it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50432/107000 [01:09<01:12, 784.84it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50464/107000 [01:09<01:12, 784.84it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50496/107000 [01:09<01:12, 783.44it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50496/107000 [01:09<01:12, 783.44it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50528/107000 [01:09<01:12, 783.44it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50560/107000 [01:09<01:12, 783.44it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50592/107000 [01:09<01:11, 785.61it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50592/107000 [01:09<01:11, 785.61it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50624/107000 [01:09<01:11, 785.61it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50656/107000 [01:09<01:11, 785.61it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50688/107000 [01:09<01:11, 789.89it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50688/107000 [01:09<01:11, 789.89it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50720/107000 [01:09<01:11, 789.89it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50752/107000 [01:09<01:11, 789.89it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50784/107000 [01:09<01:11, 789.22it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50784/107000 [01:09<01:11, 789.22it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  47%|████▋     | 50816/107000 [01:09<01:11, 789.22it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 50848/107000 [01:09<01:11, 789.22it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 50880/107000 [01:09<01:11, 789.64it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 50880/107000 [01:09<01:11, 789.64it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 50912/107000 [01:09<01:11, 789.64it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 50944/107000 [01:09<01:10, 789.64it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 50976/107000 [01:09<01:11, 787.45it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 50976/107000 [01:09<01:11, 787.45it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51008/107000 [01:09<01:11, 787.45it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51040/107000 [01:09<01:11, 787.45it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51072/107000 [01:09<01:11, 787.71it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51072/107000 [01:09<01:11, 787.71it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51104/107000 [01:09<01:10, 787.71it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51136/107000 [01:09<01:10, 787.71it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51168/107000 [01:09<01:10, 789.41it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51168/107000 [01:10<01:10, 789.41it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51200/107000 [01:10<01:10, 789.41it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51232/107000 [01:10<01:10, 789.41it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51264/107000 [01:10<01:10, 790.11it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51264/107000 [01:10<01:10, 790.11it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51296/107000 [01:10<01:10, 790.11it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51328/107000 [01:10<01:10, 790.11it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51360/107000 [01:10<01:11, 781.82it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51360/107000 [01:10<01:11, 781.82it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51392/107000 [01:10<01:11, 781.82it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51424/107000 [01:10<01:11, 781.82it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51456/107000 [01:10<01:10, 788.80it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51456/107000 [01:10<01:10, 788.80it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51488/107000 [01:10<01:10, 788.80it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51520/107000 [01:10<01:10, 788.80it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51552/107000 [01:10<01:10, 790.25it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51552/107000 [01:10<01:10, 790.25it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51584/107000 [01:10<01:10, 790.25it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51616/107000 [01:10<01:10, 790.25it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51648/107000 [01:10<01:10, 790.31it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51648/107000 [01:10<01:10, 790.31it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51680/107000 [01:10<01:09, 790.31it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51712/107000 [01:10<01:09, 790.31it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51744/107000 [01:10<01:09, 789.95it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51744/107000 [01:10<01:09, 789.95it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51776/107000 [01:10<01:09, 789.95it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51808/107000 [01:10<01:09, 789.95it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51840/107000 [01:10<01:10, 786.64it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51840/107000 [01:10<01:10, 786.64it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  48%|████▊     | 51872/107000 [01:10<01:10, 786.64it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 51904/107000 [01:10<01:10, 786.64it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 51936/107000 [01:10<01:10, 778.15it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 51936/107000 [01:10<01:10, 778.15it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 51968/107000 [01:11<01:10, 778.15it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 52000/107000 [01:11<01:10, 778.15it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 52032/107000 [01:11<01:09, 787.24it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 52032/107000 [01:11<01:09, 787.24it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 52064/107000 [01:11<01:09, 787.24it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 52096/107000 [01:11<01:09, 787.24it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 52128/107000 [01:11<01:09, 788.77it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 52128/107000 [01:11<01:09, 788.77it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  49%|████▊     | 52160/107000 [01:11<01:09, 788.77it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52192/107000 [01:11<01:09, 788.77it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52224/107000 [01:11<01:09, 786.18it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52224/107000 [01:11<01:09, 786.18it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52256/107000 [01:11<01:09, 786.18it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52288/107000 [01:11<01:09, 786.18it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52320/107000 [01:11<01:09, 782.99it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52320/107000 [01:11<01:09, 782.99it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52352/107000 [01:11<01:09, 782.99it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52384/107000 [01:11<01:09, 782.99it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52416/107000 [01:11<01:09, 788.45it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52416/107000 [01:11<01:09, 788.45it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52448/107000 [01:11<01:09, 788.45it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52480/107000 [01:11<01:09, 788.45it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52512/107000 [01:11<01:09, 788.11it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52512/107000 [01:11<01:09, 788.11it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52544/107000 [01:11<01:09, 788.11it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52576/107000 [01:11<01:09, 788.11it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52608/107000 [01:11<01:08, 790.76it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52608/107000 [01:11<01:08, 790.76it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52640/107000 [01:11<01:08, 790.76it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52672/107000 [01:11<01:08, 790.76it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  49%|████▉     | 52704/107000 [01:11<01:09, 785.37it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52704/107000 [01:11<01:09, 785.37it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52736/107000 [01:12<01:09, 785.37it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52768/107000 [01:12<01:09, 785.37it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52800/107000 [01:12<01:10, 769.77it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52800/107000 [01:12<01:10, 769.77it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  49%|████▉     | 52832/107000 [01:12<01:10, 769.77it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52864/107000 [01:12<01:10, 769.77it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  49%|████▉     | 52896/107000 [01:12<01:12, 750.84it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52896/107000 [01:12<01:12, 750.84it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52928/107000 [01:12<01:12, 750.84it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  49%|████▉     | 52960/107000 [01:12<01:11, 750.84it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 52992/107000 [01:12<01:12, 748.66it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 52992/107000 [01:12<01:12, 748.66it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 53024/107000 [01:12<01:12, 748.66it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 53056/107000 [01:12<01:12, 748.66it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 53088/107000 [01:12<01:10, 765.48it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 53088/107000 [01:12<01:10, 765.48it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 53120/107000 [01:12<01:10, 765.48it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  50%|████▉     | 53152/107000 [01:12<01:10, 765.48it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 53184/107000 [01:12<01:09, 774.52it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 53184/107000 [01:12<01:09, 774.52it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 53216/107000 [01:12<01:09, 774.52it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 53248/107000 [01:12<01:09, 774.52it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 53280/107000 [01:12<01:09, 776.09it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 53280/107000 [01:12<01:09, 776.09it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 53312/107000 [01:12<01:09, 776.09it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 53344/107000 [01:12<01:09, 776.09it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 53376/107000 [01:12<01:10, 762.22it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 53376/107000 [01:12<01:10, 762.22it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 53408/107000 [01:12<01:10, 762.22it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 53440/107000 [01:12<01:10, 762.22it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 53472/107000 [01:12<01:12, 742.44it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  50%|████▉     | 53472/107000 [01:13<01:12, 742.44it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  50%|█████     | 53504/107000 [01:13<01:12, 742.44it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  50%|█████     | 53536/107000 [01:13<01:12, 742.44it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  50%|█████     | 53568/107000 [01:13<01:17, 690.67it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  50%|█████     | 53568/107000 [01:13<01:17, 690.67it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  50%|█████     | 53600/107000 [01:13<01:17, 690.67it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  50%|█████     | 53632/107000 [01:13<01:17, 690.67it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  50%|█████     | 53664/107000 [01:13<01:19, 669.84it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  50%|█████     | 53664/107000 [01:13<01:19, 669.84it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  50%|█████     | 53696/107000 [01:13<01:19, 669.84it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  50%|█████     | 53728/107000 [01:13<01:19, 669.84it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  50%|█████     | 53760/107000 [01:13<01:21, 654.44it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  50%|█████     | 53760/107000 [01:13<01:21, 654.44it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  50%|█████     | 53792/107000 [01:13<01:21, 654.44it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  50%|█████     | 53824/107000 [01:13<01:21, 654.44it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  50%|█████     | 53856/107000 [01:13<01:20, 662.65it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  50%|█████     | 53856/107000 [01:13<01:20, 662.65it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  50%|█████     | 53888/107000 [01:13<01:20, 662.65it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  50%|█████     | 53920/107000 [01:13<01:20, 662.65it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  50%|█████     | 53952/107000 [01:13<01:19, 668.24it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  50%|█████     | 53952/107000 [01:13<01:19, 668.24it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  50%|█████     | 53984/107000 [01:13<01:19, 668.24it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  50%|█████     | 54016/107000 [01:13<01:19, 668.24it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54048/107000 [01:13<01:18, 675.19it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54048/107000 [01:13<01:18, 675.19it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54080/107000 [01:13<01:18, 675.19it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54112/107000 [01:13<01:18, 675.19it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54144/107000 [01:13<01:17, 678.44it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54144/107000 [01:14<01:17, 678.44it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54176/107000 [01:14<01:17, 678.44it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54208/107000 [01:14<01:17, 678.44it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54240/107000 [01:14<01:16, 687.70it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54240/107000 [01:14<01:16, 687.70it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54272/107000 [01:14<01:16, 687.70it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54304/107000 [01:14<01:16, 687.70it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54336/107000 [01:14<01:17, 683.66it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54336/107000 [01:14<01:17, 683.66it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54368/107000 [01:14<01:16, 683.66it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54400/107000 [01:14<01:16, 683.66it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54432/107000 [01:14<01:15, 693.86it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54432/107000 [01:14<01:15, 693.86it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54464/107000 [01:14<01:15, 693.86it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54496/107000 [01:14<01:15, 693.86it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54528/107000 [01:14<01:15, 693.09it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54528/107000 [01:14<01:15, 693.09it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54560/107000 [01:14<01:15, 693.09it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54592/107000 [01:14<01:15, 693.09it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54624/107000 [01:14<01:13, 713.75it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54624/107000 [01:14<01:13, 713.75it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54656/107000 [01:14<01:13, 713.75it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54688/107000 [01:14<01:13, 713.75it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54720/107000 [01:14<01:14, 704.12it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54720/107000 [01:14<01:14, 704.12it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54752/107000 [01:14<01:14, 704.12it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54784/107000 [01:14<01:14, 704.12it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54816/107000 [01:14<01:15, 690.78it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  51%|█████     | 54816/107000 [01:14<01:15, 690.78it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 54848/107000 [01:15<01:15, 690.78it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 54880/107000 [01:15<01:15, 690.78it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 54912/107000 [01:15<01:15, 691.20it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 54912/107000 [01:15<01:15, 691.20it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 54944/107000 [01:15<01:15, 691.20it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 54976/107000 [01:15<01:15, 691.20it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 55008/107000 [01:15<01:12, 717.52it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 55008/107000 [01:15<01:12, 717.52it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 55040/107000 [01:15<01:12, 717.52it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 55072/107000 [01:15<01:12, 717.52it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 55104/107000 [01:15<01:13, 709.45it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  51%|█████▏    | 55104/107000 [01:15<01:13, 709.45it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55136/107000 [01:15<01:13, 709.45it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55168/107000 [01:15<01:13, 709.45it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55200/107000 [01:15<01:12, 711.13it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55200/107000 [01:15<01:12, 711.13it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55232/107000 [01:15<01:12, 711.13it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55264/107000 [01:15<01:12, 711.13it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55296/107000 [01:15<01:11, 725.51it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55296/107000 [01:15<01:11, 725.51it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55328/107000 [01:15<01:11, 725.51it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55360/107000 [01:15<01:11, 725.51it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55392/107000 [01:15<01:09, 742.42it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55392/107000 [01:15<01:09, 742.42it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55424/107000 [01:15<01:09, 742.42it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55456/107000 [01:15<01:09, 742.42it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55488/107000 [01:15<01:09, 736.88it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55488/107000 [01:15<01:09, 736.88it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55520/107000 [01:15<01:09, 736.88it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55552/107000 [01:15<01:09, 736.88it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55584/107000 [01:16<01:10, 726.99it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55584/107000 [01:16<01:10, 726.99it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55616/107000 [01:16<01:10, 726.99it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55648/107000 [01:16<01:10, 726.99it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55680/107000 [01:16<01:11, 714.67it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55680/107000 [01:16<01:11, 714.67it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55712/107000 [01:16<01:11, 714.67it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55744/107000 [01:16<01:11, 714.67it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55776/107000 [01:16<01:11, 721.18it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55776/107000 [01:16<01:11, 721.18it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55808/107000 [01:16<01:10, 721.18it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55840/107000 [01:16<01:10, 721.18it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55872/107000 [01:16<01:11, 719.10it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55872/107000 [01:16<01:11, 719.10it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55904/107000 [01:16<01:11, 719.10it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55936/107000 [01:16<01:11, 719.10it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55968/107000 [01:16<01:10, 720.47it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 55968/107000 [01:16<01:10, 720.47it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 56000/107000 [01:16<01:10, 720.47it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 56032/107000 [01:16<01:10, 720.47it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 56064/107000 [01:16<01:11, 710.62it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 56064/107000 [01:16<01:11, 710.62it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 56096/107000 [01:16<01:11, 710.62it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 56128/107000 [01:16<01:11, 710.62it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 56160/107000 [01:16<01:11, 711.32it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  52%|█████▏    | 56160/107000 [01:16<01:11, 711.32it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56192/107000 [01:16<01:11, 711.32it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56224/107000 [01:16<01:11, 711.32it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56256/107000 [01:16<01:11, 706.15it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56256/107000 [01:16<01:11, 706.15it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56288/107000 [01:17<01:11, 706.15it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56320/107000 [01:17<01:11, 706.15it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56352/107000 [01:17<01:12, 702.59it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56352/107000 [01:17<01:12, 702.59it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56384/107000 [01:17<01:12, 702.59it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56416/107000 [01:17<01:11, 702.59it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56448/107000 [01:17<01:11, 709.55it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56448/107000 [01:17<01:11, 709.55it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56480/107000 [01:17<01:11, 709.55it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56512/107000 [01:17<01:11, 709.55it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56544/107000 [01:17<01:08, 734.82it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56544/107000 [01:17<01:08, 734.82it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56576/107000 [01:17<01:08, 734.82it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56608/107000 [01:17<01:08, 734.82it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56640/107000 [01:17<01:09, 724.04it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56640/107000 [01:17<01:09, 724.04it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56672/107000 [01:17<01:09, 724.04it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56704/107000 [01:17<01:09, 724.04it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56736/107000 [01:17<01:07, 739.37it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56736/107000 [01:17<01:07, 739.37it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56768/107000 [01:17<01:07, 739.37it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56800/107000 [01:17<01:07, 739.37it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56832/107000 [01:17<01:10, 714.80it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56832/107000 [01:17<01:10, 714.80it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56864/107000 [01:17<01:10, 714.80it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56896/107000 [01:17<01:10, 714.80it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56928/107000 [01:17<01:10, 709.97it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56928/107000 [01:17<01:10, 709.97it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56960/107000 [01:17<01:10, 709.97it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 56992/107000 [01:18<01:10, 709.97it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 57024/107000 [01:18<01:10, 706.07it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 57024/107000 [01:18<01:10, 706.07it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 57056/107000 [01:18<01:10, 706.07it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 57088/107000 [01:18<01:10, 706.07it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 57120/107000 [01:18<01:10, 702.98it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 57120/107000 [01:18<01:10, 702.98it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 57152/107000 [01:18<01:10, 702.98it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 57184/107000 [01:18<01:10, 702.98it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 57216/107000 [01:18<01:10, 710.28it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  53%|█████▎    | 57216/107000 [01:18<01:10, 710.28it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 57248/107000 [01:18<01:10, 710.28it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 57280/107000 [01:18<01:10, 710.28it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 57312/107000 [01:18<01:07, 731.81it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 57312/107000 [01:18<01:07, 731.81it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 57344/107000 [01:18<01:07, 731.81it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 57376/107000 [01:18<01:07, 731.81it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 57408/107000 [01:18<01:05, 752.83it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 57408/107000 [01:18<01:05, 752.83it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 57440/107000 [01:18<01:05, 752.83it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 57472/107000 [01:18<01:05, 752.83it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 57504/107000 [01:18<01:06, 744.62it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  54%|█████▎    | 57504/107000 [01:18<01:06, 744.62it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 57536/107000 [01:18<01:06, 744.62it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 57568/107000 [01:18<01:06, 744.62it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 57600/107000 [01:18<01:07, 735.34it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 57600/107000 [01:18<01:07, 735.34it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 57632/107000 [01:18<01:07, 735.34it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 57664/107000 [01:18<01:07, 735.34it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 57696/107000 [01:18<01:05, 753.51it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 57696/107000 [01:18<01:05, 753.51it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 57728/107000 [01:18<01:05, 753.51it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 57760/107000 [01:19<01:05, 753.51it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 57792/107000 [01:19<01:04, 762.80it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 57792/107000 [01:19<01:04, 762.80it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 57824/107000 [01:19<01:04, 762.80it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 57856/107000 [01:19<01:04, 762.80it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 57888/107000 [01:19<01:03, 770.04it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 57888/107000 [01:19<01:03, 770.04it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 57920/107000 [01:19<01:03, 770.04it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  54%|█████▍    | 57952/107000 [01:19<01:03, 770.04it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 57984/107000 [01:19<01:07, 728.57it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 57984/107000 [01:19<01:07, 728.57it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 58016/107000 [01:19<01:07, 728.57it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 58048/107000 [01:19<01:07, 728.57it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 58080/107000 [01:19<01:08, 718.77it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 58080/107000 [01:19<01:08, 718.77it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 58112/107000 [01:19<01:08, 718.77it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  54%|█████▍    | 58144/107000 [01:19<01:07, 718.77it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 58176/107000 [01:19<01:06, 730.39it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 58176/107000 [01:19<01:06, 730.39it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 58208/107000 [01:19<01:06, 730.39it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 58240/107000 [01:19<01:06, 730.39it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 58272/107000 [01:19<01:06, 733.95it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 58272/107000 [01:19<01:06, 733.95it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  54%|█████▍    | 58304/107000 [01:19<01:06, 733.95it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 58336/107000 [01:19<01:06, 733.95it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 58368/107000 [01:19<01:06, 728.80it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 58368/107000 [01:19<01:06, 728.80it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 58400/107000 [01:19<01:06, 728.80it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 58432/107000 [01:19<01:06, 728.80it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 58464/107000 [01:19<01:06, 724.48it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 58464/107000 [01:20<01:06, 724.48it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 58496/107000 [01:20<01:06, 724.48it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 58528/107000 [01:20<01:06, 724.48it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  55%|█████▍    | 58560/107000 [01:20<01:06, 730.68it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 58560/107000 [01:20<01:06, 730.68it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 58592/107000 [01:20<01:06, 730.68it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 58624/107000 [01:20<01:06, 730.68it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 58656/107000 [01:20<01:06, 729.50it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 58656/107000 [01:20<01:06, 729.50it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 58688/107000 [01:20<01:06, 729.50it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  55%|█████▍    | 58720/107000 [01:20<01:06, 729.50it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 58752/107000 [01:20<01:05, 739.21it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 58752/107000 [01:20<01:05, 739.21it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 58784/107000 [01:20<01:05, 739.21it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 58816/107000 [01:20<01:05, 739.21it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 58848/107000 [01:20<01:04, 742.61it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▍    | 58848/107000 [01:20<01:04, 742.61it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 58880/107000 [01:20<01:04, 742.61it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 58912/107000 [01:20<01:04, 742.61it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 58944/107000 [01:20<01:06, 723.54it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 58944/107000 [01:20<01:06, 723.54it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 58976/107000 [01:20<01:06, 723.54it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 59008/107000 [01:20<01:06, 723.54it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 59040/107000 [01:20<01:08, 697.21it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 59040/107000 [01:20<01:08, 697.21it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 59072/107000 [01:20<01:08, 697.21it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 59104/107000 [01:20<01:08, 697.21it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 59136/107000 [01:20<01:07, 710.20it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 59136/107000 [01:20<01:07, 710.20it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 59168/107000 [01:20<01:07, 710.20it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 59200/107000 [01:21<01:07, 710.20it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 59232/107000 [01:21<01:05, 732.52it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 59232/107000 [01:21<01:05, 732.52it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 59264/107000 [01:21<01:05, 732.52it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 59296/107000 [01:21<01:05, 732.52it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 59328/107000 [01:21<01:06, 720.87it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 59328/107000 [01:21<01:06, 720.87it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  55%|█████▌    | 59360/107000 [01:21<01:06, 720.87it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59392/107000 [01:21<01:06, 720.87it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59424/107000 [01:21<01:06, 718.49it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59424/107000 [01:21<01:06, 718.49it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59456/107000 [01:21<01:06, 718.49it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59488/107000 [01:21<01:06, 718.49it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59520/107000 [01:21<01:06, 715.51it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59520/107000 [01:21<01:06, 715.51it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59552/107000 [01:21<01:06, 715.51it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59584/107000 [01:21<01:06, 715.51it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59616/107000 [01:21<01:06, 717.11it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59616/107000 [01:21<01:06, 717.11it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59648/107000 [01:21<01:06, 717.11it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59680/107000 [01:21<01:05, 717.11it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59712/107000 [01:21<01:05, 720.82it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59712/107000 [01:21<01:05, 720.82it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59744/107000 [01:21<01:05, 720.82it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59776/107000 [01:21<01:05, 720.82it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59808/107000 [01:21<01:06, 714.34it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59808/107000 [01:21<01:06, 714.34it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59840/107000 [01:21<01:06, 714.34it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59872/107000 [01:21<01:05, 714.34it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59904/107000 [01:21<01:06, 711.56it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59904/107000 [01:22<01:06, 711.56it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59936/107000 [01:22<01:06, 711.56it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 59968/107000 [01:22<01:06, 711.56it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 60000/107000 [01:22<01:05, 713.81it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 60000/107000 [01:22<01:05, 713.81it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 60032/107000 [01:22<01:05, 713.81it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 60064/107000 [01:22<01:05, 713.81it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 60096/107000 [01:22<01:05, 713.70it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 60096/107000 [01:22<01:05, 713.70it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 60128/107000 [01:22<01:05, 713.70it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  56%|█████▌    | 60160/107000 [01:22<01:05, 713.70it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 60192/107000 [01:22<01:06, 704.08it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 60192/107000 [01:22<01:06, 704.08it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 60224/107000 [01:22<01:06, 704.08it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 60256/107000 [01:22<01:06, 704.08it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 60288/107000 [01:22<01:05, 708.85it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 60288/107000 [01:22<01:05, 708.85it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 60320/107000 [01:22<01:05, 708.85it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 60352/107000 [01:22<01:05, 708.85it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 60384/107000 [01:22<01:05, 714.08it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 60384/107000 [01:22<01:05, 714.08it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 60416/107000 [01:22<01:05, 714.08it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  56%|█████▋    | 60448/107000 [01:22<01:05, 714.08it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60480/107000 [01:22<01:06, 697.34it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60480/107000 [01:22<01:06, 697.34it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60512/107000 [01:22<01:06, 697.34it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60544/107000 [01:23<01:06, 697.34it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60576/107000 [01:23<01:29, 516.19it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60576/107000 [01:23<01:29, 516.19it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60608/107000 [01:23<01:29, 516.19it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60640/107000 [01:23<01:46, 436.65it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60640/107000 [01:23<01:46, 436.65it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60672/107000 [01:23<01:46, 436.65it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60704/107000 [01:23<01:59, 388.29it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60704/107000 [01:23<01:59, 388.29it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60736/107000 [01:23<01:59, 388.29it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60768/107000 [01:23<02:15, 341.17it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60768/107000 [01:23<02:15, 341.17it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60800/107000 [01:24<02:15, 341.17it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60832/107000 [01:24<02:23, 321.15it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60832/107000 [01:24<02:23, 321.15it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60864/107000 [01:24<02:23, 321.15it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60896/107000 [01:24<02:23, 321.44it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60896/107000 [01:24<02:23, 321.44it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60928/107000 [01:24<02:23, 321.44it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60960/107000 [01:24<02:13, 344.92it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60960/107000 [01:24<02:13, 344.92it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 60992/107000 [01:24<02:13, 344.92it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 61024/107000 [01:24<02:03, 373.50it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 61024/107000 [01:24<02:03, 373.50it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 61056/107000 [01:24<02:03, 373.50it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 61088/107000 [01:24<01:54, 399.66it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 61088/107000 [01:24<01:54, 399.66it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 61120/107000 [01:24<01:54, 399.66it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 61152/107000 [01:24<01:44, 437.58it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 61152/107000 [01:24<01:44, 437.58it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 61184/107000 [01:24<01:44, 437.58it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 61216/107000 [01:24<01:44, 437.58it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 61248/107000 [01:24<01:30, 507.44it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 61248/107000 [01:24<01:30, 507.44it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 61280/107000 [01:24<01:30, 507.44it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 61312/107000 [01:25<01:30, 507.44it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 61344/107000 [01:25<01:20, 563.89it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 61344/107000 [01:25<01:20, 563.89it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 61376/107000 [01:25<01:20, 563.89it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 61408/107000 [01:25<01:20, 563.89it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 61440/107000 [01:25<01:14, 607.58it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 61440/107000 [01:25<01:14, 607.58it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 61472/107000 [01:25<01:14, 607.58it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  57%|█████▋    | 61504/107000 [01:25<01:14, 607.58it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 61536/107000 [01:25<01:11, 633.74it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 61536/107000 [01:25<01:11, 633.74it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 61568/107000 [01:25<01:11, 633.74it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 61600/107000 [01:25<01:11, 633.74it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 61632/107000 [01:25<01:07, 672.24it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 61632/107000 [01:25<01:07, 672.24it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 61664/107000 [01:25<01:07, 672.24it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 61696/107000 [01:25<01:07, 672.24it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 61728/107000 [01:25<01:05, 687.06it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 61728/107000 [01:25<01:05, 687.06it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 61760/107000 [01:25<01:05, 687.06it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 61792/107000 [01:25<01:05, 687.06it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 61824/107000 [01:25<01:04, 696.67it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 61824/107000 [01:25<01:04, 696.67it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 61856/107000 [01:25<01:04, 696.67it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 61888/107000 [01:25<01:04, 696.67it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 61920/107000 [01:25<01:04, 704.15it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 61920/107000 [01:25<01:04, 704.15it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 61952/107000 [01:25<01:03, 704.15it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 61984/107000 [01:25<01:03, 704.15it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62016/107000 [01:25<01:03, 705.34it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62016/107000 [01:26<01:03, 705.34it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62048/107000 [01:26<01:03, 705.34it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62080/107000 [01:26<01:03, 705.34it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62112/107000 [01:26<01:02, 718.71it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62112/107000 [01:26<01:02, 718.71it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62144/107000 [01:26<01:02, 718.71it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62176/107000 [01:26<01:02, 718.71it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62208/107000 [01:26<01:01, 732.31it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62208/107000 [01:26<01:01, 732.31it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62240/107000 [01:26<01:01, 732.31it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62272/107000 [01:26<01:01, 732.31it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62304/107000 [01:26<01:00, 736.35it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62304/107000 [01:26<01:00, 736.35it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62336/107000 [01:26<01:00, 736.35it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62368/107000 [01:26<01:00, 736.35it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62400/107000 [01:26<00:59, 747.88it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62400/107000 [01:26<00:59, 747.88it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62432/107000 [01:26<00:59, 747.88it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62464/107000 [01:26<00:59, 747.88it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62496/107000 [01:26<00:59, 743.11it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62496/107000 [01:26<00:59, 743.11it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62528/107000 [01:26<00:59, 743.11it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62560/107000 [01:26<00:59, 743.11it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62592/107000 [01:26<01:00, 738.31it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  58%|█████▊    | 62592/107000 [01:26<01:00, 738.31it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 62624/107000 [01:26<01:00, 738.31it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 62656/107000 [01:26<01:00, 738.31it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 62688/107000 [01:26<01:00, 727.19it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 62688/107000 [01:26<01:00, 727.19it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 62720/107000 [01:26<01:00, 727.19it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 62752/107000 [01:26<01:00, 727.19it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 62784/107000 [01:27<01:00, 730.86it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 62784/107000 [01:27<01:00, 730.86it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 62816/107000 [01:27<01:00, 730.86it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  59%|█████▊    | 62848/107000 [01:27<01:00, 730.86it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 62880/107000 [01:27<01:00, 732.51it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 62880/107000 [01:27<01:00, 732.51it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 62912/107000 [01:27<01:00, 732.51it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 62944/107000 [01:27<01:00, 732.51it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 62976/107000 [01:27<01:00, 731.24it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 62976/107000 [01:27<01:00, 731.24it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63008/107000 [01:27<01:00, 731.24it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63040/107000 [01:27<01:00, 731.24it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63072/107000 [01:27<00:59, 732.60it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63072/107000 [01:27<00:59, 732.60it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63104/107000 [01:27<00:59, 732.60it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63136/107000 [01:27<00:59, 732.60it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63168/107000 [01:27<00:59, 737.14it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63168/107000 [01:27<00:59, 737.14it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63200/107000 [01:27<00:59, 737.14it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63232/107000 [01:27<00:59, 737.14it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63264/107000 [01:27<00:59, 730.91it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63264/107000 [01:27<00:59, 730.91it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63296/107000 [01:27<00:59, 730.91it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63328/107000 [01:27<00:59, 730.91it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63360/107000 [01:27<00:59, 738.50it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63360/107000 [01:27<00:59, 738.50it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63392/107000 [01:27<00:59, 738.50it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63424/107000 [01:27<00:59, 738.50it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63456/107000 [01:27<00:59, 727.85it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63456/107000 [01:27<00:59, 727.85it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63488/107000 [01:28<00:59, 727.85it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63520/107000 [01:28<00:59, 727.85it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63552/107000 [01:28<00:59, 731.90it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63552/107000 [01:28<00:59, 731.90it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63584/107000 [01:28<00:59, 731.90it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63616/107000 [01:28<00:59, 731.90it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63648/107000 [01:28<00:59, 731.59it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  59%|█████▉    | 63648/107000 [01:28<00:59, 731.59it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 63680/107000 [01:28<00:59, 731.59it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 63712/107000 [01:28<00:59, 731.59it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 63744/107000 [01:28<00:58, 733.62it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 63744/107000 [01:28<00:58, 733.62it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 63776/107000 [01:28<00:58, 733.62it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 63808/107000 [01:28<00:58, 733.62it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 63840/107000 [01:28<00:59, 722.21it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 63840/107000 [01:28<00:59, 722.21it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 63872/107000 [01:28<00:59, 722.21it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 63904/107000 [01:28<00:59, 722.21it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 63936/107000 [01:28<00:58, 735.14it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 63936/107000 [01:28<00:58, 735.14it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 63968/107000 [01:28<00:58, 735.14it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 64000/107000 [01:28<00:58, 735.14it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 64032/107000 [01:28<00:57, 746.95it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 64032/107000 [01:28<00:57, 746.95it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 64064/107000 [01:28<00:57, 746.95it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 64096/107000 [01:28<00:57, 746.95it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 64128/107000 [01:28<00:57, 744.50it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 64128/107000 [01:28<00:57, 744.50it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 64160/107000 [01:28<00:57, 744.50it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  60%|█████▉    | 64192/107000 [01:28<00:57, 744.50it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  60%|██████    | 64224/107000 [01:28<00:58, 735.92it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  60%|██████    | 64224/107000 [01:29<00:58, 735.92it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  60%|██████    | 64256/107000 [01:29<00:58, 735.92it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  60%|██████    | 64288/107000 [01:29<00:58, 735.92it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  60%|██████    | 64320/107000 [01:29<00:57, 746.94it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  60%|██████    | 64320/107000 [01:29<00:57, 746.94it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  60%|██████    | 64352/107000 [01:29<00:57, 746.94it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  60%|██████    | 64384/107000 [01:29<00:57, 746.94it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  60%|██████    | 64416/107000 [01:29<00:56, 753.87it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  60%|██████    | 64416/107000 [01:29<00:56, 753.87it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  60%|██████    | 64448/107000 [01:29<00:56, 753.87it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  60%|██████    | 64480/107000 [01:29<00:56, 753.87it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  60%|██████    | 64512/107000 [01:29<00:57, 738.41it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  60%|██████    | 64512/107000 [01:29<00:57, 738.41it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  60%|██████    | 64544/107000 [01:29<00:57, 738.41it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  60%|██████    | 64576/107000 [01:29<00:57, 738.41it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  60%|██████    | 64608/107000 [01:29<00:57, 741.86it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  60%|██████    | 64608/107000 [01:29<00:57, 741.86it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  60%|██████    | 64640/107000 [01:29<00:57, 741.86it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  60%|██████    | 64672/107000 [01:29<00:57, 741.86it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  60%|██████    | 64704/107000 [01:29<00:56, 743.80it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  60%|██████    | 64704/107000 [01:29<00:56, 743.80it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████    | 64736/107000 [01:29<00:56, 743.80it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████    | 64768/107000 [01:29<00:56, 743.80it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████    | 64800/107000 [01:29<00:56, 748.23it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████    | 64800/107000 [01:29<00:56, 748.23it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████    | 64832/107000 [01:29<00:56, 748.23it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████    | 64864/107000 [01:29<00:56, 748.23it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  61%|██████    | 64896/107000 [01:29<00:56, 751.04it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  61%|██████    | 64896/107000 [01:29<00:56, 751.04it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████    | 64928/107000 [01:29<00:56, 751.04it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████    | 64960/107000 [01:29<00:55, 751.04it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████    | 64992/107000 [01:29<00:56, 743.02it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████    | 64992/107000 [01:30<00:56, 743.02it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████    | 65024/107000 [01:30<00:56, 743.02it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████    | 65056/107000 [01:30<00:56, 743.02it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████    | 65088/107000 [01:30<00:57, 734.63it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████    | 65088/107000 [01:30<00:57, 734.63it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████    | 65120/107000 [01:30<00:57, 734.63it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████    | 65152/107000 [01:30<00:56, 734.63it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████    | 65184/107000 [01:30<00:57, 732.77it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████    | 65184/107000 [01:30<00:57, 732.77it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████    | 65216/107000 [01:30<00:57, 732.77it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████    | 65248/107000 [01:30<00:56, 732.77it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████    | 65280/107000 [01:30<00:56, 739.56it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████    | 65280/107000 [01:30<00:56, 739.56it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  61%|██████    | 65312/107000 [01:30<00:56, 739.56it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  61%|██████    | 65344/107000 [01:30<00:56, 739.56it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  61%|██████    | 65376/107000 [01:30<00:56, 735.37it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  61%|██████    | 65376/107000 [01:30<00:56, 735.37it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  61%|██████    | 65408/107000 [01:30<00:56, 735.37it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  61%|██████    | 65440/107000 [01:30<00:56, 735.37it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  61%|██████    | 65472/107000 [01:30<00:56, 736.28it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  61%|██████    | 65472/107000 [01:30<00:56, 736.28it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  61%|██████    | 65504/107000 [01:30<00:56, 736.28it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  61%|██████    | 65536/107000 [01:30<00:56, 736.28it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 65568/107000 [01:30<00:56, 739.51it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 65568/107000 [01:30<00:56, 739.51it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 65600/107000 [01:30<00:55, 739.51it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 65632/107000 [01:30<00:55, 739.51it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 65664/107000 [01:30<00:56, 732.92it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 65664/107000 [01:30<00:56, 732.92it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 65696/107000 [01:30<00:56, 732.92it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 65728/107000 [01:31<00:56, 732.92it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 65760/107000 [01:31<00:56, 729.94it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 65760/107000 [01:31<00:56, 729.94it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  61%|██████▏   | 65792/107000 [01:31<00:56, 729.94it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 65824/107000 [01:31<00:56, 729.94it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 65856/107000 [01:31<00:56, 728.50it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 65856/107000 [01:31<00:56, 728.50it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 65888/107000 [01:31<00:56, 728.50it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 65920/107000 [01:31<00:56, 728.50it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 65952/107000 [01:31<00:55, 737.13it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 65952/107000 [01:31<00:55, 737.13it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 65984/107000 [01:31<00:55, 737.13it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66016/107000 [01:31<00:55, 737.13it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66048/107000 [01:31<00:56, 728.91it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66048/107000 [01:31<00:56, 728.91it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66080/107000 [01:31<00:56, 728.91it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66112/107000 [01:31<00:56, 728.91it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66144/107000 [01:31<00:55, 729.86it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66144/107000 [01:31<00:55, 729.86it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66176/107000 [01:31<00:55, 729.86it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66208/107000 [01:31<00:55, 729.86it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66240/107000 [01:31<00:56, 725.07it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66240/107000 [01:31<00:56, 725.07it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66272/107000 [01:31<00:56, 725.07it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66304/107000 [01:31<00:56, 725.07it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66336/107000 [01:31<00:54, 742.27it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66336/107000 [01:31<00:54, 742.27it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66368/107000 [01:31<00:54, 742.27it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66400/107000 [01:31<00:54, 742.27it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66432/107000 [01:31<00:54, 748.45it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66432/107000 [01:31<00:54, 748.45it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66464/107000 [01:32<00:54, 748.45it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66496/107000 [01:32<00:54, 748.45it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66528/107000 [01:32<00:54, 735.88it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66528/107000 [01:32<00:54, 735.88it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66560/107000 [01:32<00:54, 735.88it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66592/107000 [01:32<00:54, 735.88it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66624/107000 [01:32<00:54, 745.18it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66624/107000 [01:32<00:54, 745.18it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66656/107000 [01:32<00:54, 745.18it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66688/107000 [01:32<00:54, 745.18it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66720/107000 [01:32<00:54, 745.89it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66720/107000 [01:32<00:54, 745.89it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66752/107000 [01:32<00:53, 745.89it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66784/107000 [01:32<00:53, 745.89it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66816/107000 [01:32<00:54, 740.76it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66816/107000 [01:32<00:54, 740.76it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  62%|██████▏   | 66848/107000 [01:32<00:54, 740.76it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 66880/107000 [01:32<00:54, 740.76it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 66912/107000 [01:32<00:53, 747.17it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 66912/107000 [01:32<00:53, 747.17it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 66944/107000 [01:32<00:53, 747.17it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 66976/107000 [01:32<00:53, 747.17it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67008/107000 [01:32<00:54, 739.04it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67008/107000 [01:32<00:54, 739.04it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67040/107000 [01:32<00:54, 739.04it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67072/107000 [01:32<00:54, 739.04it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67104/107000 [01:32<00:54, 734.76it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67104/107000 [01:32<00:54, 734.76it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67136/107000 [01:32<00:54, 734.76it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67168/107000 [01:32<00:54, 734.76it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67200/107000 [01:32<00:54, 734.09it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67200/107000 [01:33<00:54, 734.09it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67232/107000 [01:33<00:54, 734.09it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67264/107000 [01:33<00:54, 734.09it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67296/107000 [01:33<00:54, 734.66it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67296/107000 [01:33<00:54, 734.66it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67328/107000 [01:33<00:54, 734.66it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67360/107000 [01:33<00:53, 734.66it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67392/107000 [01:33<00:53, 738.37it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67392/107000 [01:33<00:53, 738.37it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67424/107000 [01:33<00:53, 738.37it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67456/107000 [01:33<00:53, 738.37it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67488/107000 [01:33<00:54, 731.56it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67488/107000 [01:33<00:54, 731.56it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67520/107000 [01:33<00:53, 731.56it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67552/107000 [01:33<00:53, 731.56it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67584/107000 [01:33<00:54, 729.44it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67584/107000 [01:33<00:54, 729.44it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67616/107000 [01:33<00:53, 729.44it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67648/107000 [01:33<00:53, 729.44it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67680/107000 [01:33<00:54, 727.58it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67680/107000 [01:33<00:54, 727.58it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67712/107000 [01:33<00:53, 727.58it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67744/107000 [01:33<00:53, 727.58it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67776/107000 [01:33<00:53, 733.66it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67776/107000 [01:33<00:53, 733.66it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67808/107000 [01:33<00:53, 733.66it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67840/107000 [01:33<00:53, 733.66it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67872/107000 [01:33<00:54, 722.77it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67872/107000 [01:33<00:54, 722.77it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67904/107000 [01:33<00:54, 722.77it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  63%|██████▎   | 67936/107000 [01:34<00:54, 722.77it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 67968/107000 [01:34<00:53, 725.93it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 67968/107000 [01:34<00:53, 725.93it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 68000/107000 [01:34<00:53, 725.93it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 68032/107000 [01:34<00:53, 725.93it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 68064/107000 [01:34<00:53, 723.82it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 68064/107000 [01:34<00:53, 723.82it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 68096/107000 [01:34<00:53, 723.82it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 68128/107000 [01:34<00:53, 723.82it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 68160/107000 [01:34<00:54, 718.76it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 68160/107000 [01:34<00:54, 718.76it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  64%|██████▎   | 68192/107000 [01:34<00:53, 718.76it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68224/107000 [01:34<00:53, 718.76it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68256/107000 [01:34<00:53, 729.62it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68256/107000 [01:34<00:53, 729.62it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68288/107000 [01:34<00:53, 729.62it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68320/107000 [01:34<00:53, 729.62it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68352/107000 [01:34<00:53, 718.68it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68352/107000 [01:34<00:53, 718.68it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68384/107000 [01:34<00:53, 718.68it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68416/107000 [01:34<00:53, 718.68it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68448/107000 [01:34<00:53, 714.10it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68448/107000 [01:34<00:53, 714.10it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68480/107000 [01:34<00:53, 714.10it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68512/107000 [01:34<00:53, 714.10it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68544/107000 [01:34<00:54, 710.55it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68544/107000 [01:34<00:54, 710.55it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68576/107000 [01:34<00:54, 710.55it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68608/107000 [01:34<00:54, 710.55it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68640/107000 [01:34<00:53, 713.28it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68640/107000 [01:35<00:53, 713.28it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68672/107000 [01:35<00:53, 713.28it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68704/107000 [01:35<00:53, 713.28it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68736/107000 [01:35<00:52, 723.33it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68736/107000 [01:35<00:52, 723.33it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68768/107000 [01:35<00:52, 723.33it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68800/107000 [01:35<00:52, 723.33it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68832/107000 [01:35<00:52, 723.59it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68832/107000 [01:35<00:52, 723.59it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68864/107000 [01:35<00:52, 723.59it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68896/107000 [01:35<00:52, 723.59it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68928/107000 [01:35<00:51, 736.67it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68928/107000 [01:35<00:51, 736.67it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68960/107000 [01:35<00:51, 736.67it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  64%|██████▍   | 68992/107000 [01:35<00:51, 736.67it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 69024/107000 [01:35<00:50, 754.90it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 69024/107000 [01:35<00:50, 754.90it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 69056/107000 [01:35<00:50, 754.90it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 69088/107000 [01:35<00:50, 754.90it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 69120/107000 [01:35<00:49, 760.96it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 69120/107000 [01:35<00:49, 760.96it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 69152/107000 [01:35<00:49, 760.96it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 69184/107000 [01:35<00:49, 760.96it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 69216/107000 [01:35<00:49, 768.16it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 69216/107000 [01:35<00:49, 768.16it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 69248/107000 [01:35<00:49, 768.16it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 69280/107000 [01:35<00:49, 768.16it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 69312/107000 [01:35<00:49, 758.58it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 69312/107000 [01:35<00:49, 758.58it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 69344/107000 [01:35<00:49, 758.58it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 69376/107000 [01:35<00:49, 758.58it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 69408/107000 [01:35<00:50, 748.64it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 69408/107000 [01:36<00:50, 748.64it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 69440/107000 [01:36<00:50, 748.64it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 69472/107000 [01:36<00:50, 748.64it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 69504/107000 [01:36<00:49, 759.68it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 69504/107000 [01:36<00:49, 759.68it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▍   | 69536/107000 [01:36<00:49, 759.68it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 69568/107000 [01:36<00:49, 759.68it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 69600/107000 [01:36<00:49, 753.92it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 69600/107000 [01:36<00:49, 753.92it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 69632/107000 [01:36<00:49, 753.92it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 69664/107000 [01:36<00:49, 753.92it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 69696/107000 [01:36<00:50, 744.17it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 69696/107000 [01:36<00:50, 744.17it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 69728/107000 [01:36<00:50, 744.17it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 69760/107000 [01:36<00:50, 744.17it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 69792/107000 [01:36<00:49, 745.81it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 69792/107000 [01:36<00:49, 745.81it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 69824/107000 [01:36<00:49, 745.81it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 69856/107000 [01:36<00:49, 745.81it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 69888/107000 [01:36<00:49, 746.68it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 69888/107000 [01:36<00:49, 746.68it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 69920/107000 [01:36<00:49, 746.68it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 69952/107000 [01:36<00:49, 746.68it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 69984/107000 [01:36<00:49, 741.52it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 69984/107000 [01:36<00:49, 741.52it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 70016/107000 [01:36<00:49, 741.52it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 70048/107000 [01:36<00:49, 741.52it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 70080/107000 [01:36<00:49, 744.07it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  65%|██████▌   | 70080/107000 [01:36<00:49, 744.07it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70112/107000 [01:36<00:49, 744.07it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70144/107000 [01:37<00:49, 744.07it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70176/107000 [01:37<00:50, 729.58it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70176/107000 [01:37<00:50, 729.58it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70208/107000 [01:37<00:50, 729.58it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70240/107000 [01:37<00:50, 729.58it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70272/107000 [01:37<00:51, 718.86it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70272/107000 [01:37<00:51, 718.86it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70304/107000 [01:37<00:51, 718.86it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70336/107000 [01:37<00:51, 718.86it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70368/107000 [01:37<00:52, 702.99it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70368/107000 [01:37<00:52, 702.99it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70400/107000 [01:37<00:52, 702.99it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70432/107000 [01:37<00:52, 702.99it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70464/107000 [01:37<00:53, 683.16it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70464/107000 [01:37<00:53, 683.16it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70496/107000 [01:37<00:53, 683.16it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70528/107000 [01:37<00:53, 683.16it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70560/107000 [01:37<00:52, 687.69it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70560/107000 [01:37<00:52, 687.69it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70592/107000 [01:37<00:52, 687.69it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70624/107000 [01:37<00:52, 687.69it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70656/107000 [01:37<00:51, 703.75it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70656/107000 [01:37<00:51, 703.75it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70688/107000 [01:37<00:51, 703.75it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70720/107000 [01:37<00:51, 703.75it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70752/107000 [01:37<00:51, 698.63it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70752/107000 [01:37<00:51, 698.63it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70784/107000 [01:37<00:51, 698.63it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70816/107000 [01:38<00:51, 698.63it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70848/107000 [01:38<00:51, 705.96it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70848/107000 [01:38<00:51, 705.96it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  66%|██████▌   | 70880/107000 [01:38<00:51, 705.96it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 70912/107000 [01:38<00:51, 705.96it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 70944/107000 [01:38<00:51, 695.37it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 70944/107000 [01:38<00:51, 695.37it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 70976/107000 [01:38<00:51, 695.37it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 71008/107000 [01:38<00:51, 695.37it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 71040/107000 [01:38<00:50, 711.79it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 71040/107000 [01:38<00:50, 711.79it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 71072/107000 [01:38<00:50, 711.79it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  66%|██████▋   | 71104/107000 [01:38<00:50, 711.79it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 71136/107000 [01:38<00:49, 719.38it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  66%|██████▋   | 71136/107000 [01:38<00:49, 719.38it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71168/107000 [01:38<00:49, 719.38it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71200/107000 [01:38<00:49, 719.38it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71232/107000 [01:38<00:49, 719.35it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71232/107000 [01:38<00:49, 719.35it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71264/107000 [01:38<00:49, 719.35it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71296/107000 [01:38<00:49, 719.35it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71328/107000 [01:38<00:49, 725.12it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71328/107000 [01:38<00:49, 725.12it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71360/107000 [01:38<00:49, 725.12it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71392/107000 [01:38<00:49, 725.12it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71424/107000 [01:38<00:48, 735.11it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71424/107000 [01:38<00:48, 735.11it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71456/107000 [01:38<00:48, 735.11it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71488/107000 [01:38<00:48, 735.11it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71520/107000 [01:38<00:47, 747.69it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71520/107000 [01:38<00:47, 747.69it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71552/107000 [01:39<00:47, 747.69it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71584/107000 [01:39<00:47, 747.69it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71616/107000 [01:39<00:47, 740.97it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71616/107000 [01:39<00:47, 740.97it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71648/107000 [01:39<00:47, 740.97it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71680/107000 [01:39<00:47, 740.97it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71712/107000 [01:39<00:48, 725.83it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71712/107000 [01:39<00:48, 725.83it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71744/107000 [01:39<00:48, 725.83it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71776/107000 [01:39<00:48, 725.83it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71808/107000 [01:39<00:49, 718.11it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71808/107000 [01:39<00:49, 718.11it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71840/107000 [01:39<00:48, 718.11it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71872/107000 [01:39<00:48, 718.11it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71904/107000 [01:39<00:48, 719.20it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71904/107000 [01:39<00:48, 719.20it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71936/107000 [01:39<00:48, 719.20it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 71968/107000 [01:39<00:48, 719.20it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 72000/107000 [01:39<00:48, 721.77it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 72000/107000 [01:39<00:48, 721.77it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 72032/107000 [01:39<00:48, 721.77it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 72064/107000 [01:39<00:48, 721.77it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 72096/107000 [01:39<00:48, 719.64it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 72096/107000 [01:39<00:48, 719.64it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 72128/107000 [01:39<00:48, 719.64it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 72160/107000 [01:39<00:48, 719.64it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 72192/107000 [01:39<00:48, 715.96it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 72192/107000 [01:39<00:48, 715.96it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  67%|██████▋   | 72224/107000 [01:39<00:48, 715.96it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72256/107000 [01:39<00:48, 715.96it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72288/107000 [01:39<00:48, 717.69it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72288/107000 [01:40<00:48, 717.69it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72320/107000 [01:40<00:48, 717.69it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72352/107000 [01:40<00:48, 717.69it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72384/107000 [01:40<00:48, 709.67it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72384/107000 [01:40<00:48, 709.67it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72416/107000 [01:40<00:48, 709.67it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72448/107000 [01:40<00:48, 709.67it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72480/107000 [01:40<00:48, 718.08it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72480/107000 [01:40<00:48, 718.08it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72512/107000 [01:40<00:48, 718.08it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72544/107000 [01:40<00:47, 718.08it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72576/107000 [01:40<00:48, 708.75it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72576/107000 [01:40<00:48, 708.75it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72608/107000 [01:40<00:48, 708.75it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72640/107000 [01:40<00:48, 708.75it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72672/107000 [01:40<00:47, 720.87it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72672/107000 [01:40<00:47, 720.87it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72704/107000 [01:40<00:47, 720.87it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72736/107000 [01:40<00:47, 720.87it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72768/107000 [01:40<00:47, 722.32it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72768/107000 [01:40<00:47, 722.32it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72800/107000 [01:40<00:47, 722.32it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72832/107000 [01:40<00:47, 722.32it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72864/107000 [01:40<00:46, 736.20it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72864/107000 [01:40<00:46, 736.20it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72896/107000 [01:40<00:46, 736.20it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72928/107000 [01:40<00:46, 736.20it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72960/107000 [01:40<00:46, 737.72it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72960/107000 [01:40<00:46, 737.72it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 72992/107000 [01:41<00:46, 737.72it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 73024/107000 [01:41<00:46, 737.72it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 73056/107000 [01:41<00:46, 728.75it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 73056/107000 [01:41<00:46, 728.75it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 73088/107000 [01:41<00:46, 728.75it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 73120/107000 [01:41<00:46, 728.75it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 73152/107000 [01:41<00:45, 736.39it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 73152/107000 [01:41<00:45, 736.39it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 73184/107000 [01:41<00:45, 736.39it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 73216/107000 [01:41<00:45, 736.39it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 73248/107000 [01:41<00:45, 739.08it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 73248/107000 [01:41<00:45, 739.08it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  68%|██████▊   | 73280/107000 [01:41<00:45, 739.08it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 73312/107000 [01:41<00:45, 739.08it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 73344/107000 [01:41<00:45, 745.46it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 73344/107000 [01:41<00:45, 745.46it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 73376/107000 [01:41<00:45, 745.46it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 73408/107000 [01:41<00:45, 745.46it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 73440/107000 [01:41<00:45, 744.45it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 73440/107000 [01:41<00:45, 744.45it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 73472/107000 [01:41<00:45, 744.45it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 73504/107000 [01:41<00:44, 744.45it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 73536/107000 [01:41<00:45, 736.51it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▊   | 73536/107000 [01:41<00:45, 736.51it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 73568/107000 [01:41<00:45, 736.51it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 73600/107000 [01:41<00:45, 736.51it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 73632/107000 [01:41<00:44, 746.98it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 73632/107000 [01:41<00:44, 746.98it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 73664/107000 [01:41<00:44, 746.98it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 73696/107000 [01:41<00:44, 746.98it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 73728/107000 [01:41<00:44, 753.35it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 73728/107000 [01:41<00:44, 753.35it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 73760/107000 [01:42<00:44, 753.35it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 73792/107000 [01:42<00:44, 753.35it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 73824/107000 [01:42<00:44, 750.61it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 73824/107000 [01:42<00:44, 750.61it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 73856/107000 [01:42<00:44, 750.61it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 73888/107000 [01:42<00:44, 750.61it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 73920/107000 [01:42<00:44, 748.43it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 73920/107000 [01:42<00:44, 748.43it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 73952/107000 [01:42<00:44, 748.43it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 73984/107000 [01:42<00:44, 748.43it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 74016/107000 [01:42<00:45, 732.68it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 74016/107000 [01:42<00:45, 732.68it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 74048/107000 [01:42<00:44, 732.68it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 74080/107000 [01:42<00:44, 732.68it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 74112/107000 [01:42<00:45, 727.34it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 74112/107000 [01:42<00:45, 727.34it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 74144/107000 [01:42<00:45, 727.34it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 74176/107000 [01:42<00:45, 727.34it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 74208/107000 [01:42<00:45, 725.96it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 74208/107000 [01:42<00:45, 725.96it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 74240/107000 [01:42<00:45, 725.96it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 74272/107000 [01:42<00:45, 725.96it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 74304/107000 [01:42<00:44, 731.30it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 74304/107000 [01:42<00:44, 731.30it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  69%|██████▉   | 74336/107000 [01:42<00:44, 731.30it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 74368/107000 [01:42<00:44, 731.30it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 74400/107000 [01:42<00:44, 729.90it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 74400/107000 [01:42<00:44, 729.90it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 74432/107000 [01:42<00:44, 729.90it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 74464/107000 [01:42<00:44, 729.90it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 74496/107000 [01:42<00:44, 736.59it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 74496/107000 [01:43<00:44, 736.59it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 74528/107000 [01:43<00:44, 736.59it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 74560/107000 [01:43<00:44, 736.59it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 74592/107000 [01:43<00:43, 740.51it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 74592/107000 [01:43<00:43, 740.51it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 74624/107000 [01:43<00:43, 740.51it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 74656/107000 [01:43<00:43, 740.51it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 74688/107000 [01:43<00:44, 729.96it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 74688/107000 [01:43<00:44, 729.96it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 74720/107000 [01:43<00:44, 729.96it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 74752/107000 [01:43<00:44, 729.96it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 74784/107000 [01:43<00:43, 733.00it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 74784/107000 [01:43<00:43, 733.00it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 74816/107000 [01:43<00:43, 733.00it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 74848/107000 [01:43<00:43, 733.00it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 74880/107000 [01:43<00:43, 733.28it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  70%|██████▉   | 74880/107000 [01:43<00:43, 733.28it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  70%|███████   | 74912/107000 [01:43<00:43, 733.28it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  70%|███████   | 74944/107000 [01:43<00:43, 733.28it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  70%|███████   | 74976/107000 [01:43<00:43, 734.99it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  70%|███████   | 74976/107000 [01:43<00:43, 734.99it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  70%|███████   | 75008/107000 [01:43<00:43, 734.99it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  70%|███████   | 75040/107000 [01:43<00:43, 734.99it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  70%|███████   | 75072/107000 [01:43<00:44, 724.14it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  70%|███████   | 75072/107000 [01:43<00:44, 724.14it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  70%|███████   | 75104/107000 [01:43<00:44, 724.14it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  70%|███████   | 75136/107000 [01:43<00:44, 724.14it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  70%|███████   | 75168/107000 [01:43<00:44, 720.17it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  70%|███████   | 75168/107000 [01:43<00:44, 720.17it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  70%|███████   | 75200/107000 [01:44<00:44, 720.17it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  70%|███████   | 75232/107000 [01:44<00:44, 720.17it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  70%|███████   | 75264/107000 [01:44<00:43, 729.34it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  70%|███████   | 75264/107000 [01:44<00:43, 729.34it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  70%|███████   | 75296/107000 [01:44<00:43, 729.34it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  70%|███████   | 75328/107000 [01:44<00:43, 729.34it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  70%|███████   | 75360/107000 [01:44<00:44, 712.85it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  70%|███████   | 75360/107000 [01:44<00:44, 712.85it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  70%|███████   | 75392/107000 [01:44<00:44, 712.85it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  70%|███████   | 75424/107000 [01:44<00:44, 712.85it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  71%|███████   | 75456/107000 [01:44<00:43, 717.83it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  71%|███████   | 75456/107000 [01:44<00:43, 717.83it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  71%|███████   | 75488/107000 [01:44<00:43, 717.83it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  71%|███████   | 75520/107000 [01:44<00:43, 717.83it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  71%|███████   | 75552/107000 [01:44<00:43, 729.22it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  71%|███████   | 75552/107000 [01:44<00:43, 729.22it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  71%|███████   | 75584/107000 [01:44<00:43, 729.22it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  71%|███████   | 75616/107000 [01:44<00:43, 729.22it/s, train_loss=0.64] \u001b[A\n",
            "Epoch 1:  71%|███████   | 75648/107000 [01:44<00:43, 727.28it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  71%|███████   | 75648/107000 [01:44<00:43, 727.28it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  71%|███████   | 75680/107000 [01:44<00:43, 727.28it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  71%|███████   | 75712/107000 [01:44<00:43, 727.28it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  71%|███████   | 75744/107000 [01:44<00:42, 730.39it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  71%|███████   | 75744/107000 [01:44<00:42, 730.39it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  71%|███████   | 75776/107000 [01:44<00:42, 730.39it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  71%|███████   | 75808/107000 [01:44<00:42, 730.39it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  71%|███████   | 75840/107000 [01:44<00:42, 733.73it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  71%|███████   | 75840/107000 [01:44<00:42, 733.73it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  71%|███████   | 75872/107000 [01:44<00:42, 733.73it/s, train_loss=0.64] \u001b[A\n",
            "Epoch 1:  71%|███████   | 75904/107000 [01:44<00:42, 733.73it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  71%|███████   | 75936/107000 [01:44<00:42, 725.74it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  71%|███████   | 75936/107000 [01:45<00:42, 725.74it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  71%|███████   | 75968/107000 [01:45<00:42, 725.74it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  71%|███████   | 76000/107000 [01:45<00:42, 725.74it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  71%|███████   | 76032/107000 [01:45<00:42, 720.56it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  71%|███████   | 76032/107000 [01:45<00:42, 720.56it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  71%|███████   | 76064/107000 [01:45<00:42, 720.56it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  71%|███████   | 76096/107000 [01:45<00:42, 720.56it/s, train_loss=0.64] \u001b[A\n",
            "Epoch 1:  71%|███████   | 76128/107000 [01:45<00:42, 721.23it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  71%|███████   | 76128/107000 [01:45<00:42, 721.23it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  71%|███████   | 76160/107000 [01:45<00:42, 721.23it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  71%|███████   | 76192/107000 [01:45<00:42, 721.23it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:  71%|███████   | 76224/107000 [01:45<00:43, 709.73it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:  71%|███████   | 76224/107000 [01:45<00:43, 709.73it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 76256/107000 [01:45<00:43, 709.73it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 76288/107000 [01:45<00:43, 709.73it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 76320/107000 [01:45<00:44, 695.54it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 76320/107000 [01:45<00:44, 695.54it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 76352/107000 [01:45<00:44, 695.54it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 76384/107000 [01:45<00:44, 695.54it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 76416/107000 [01:45<00:43, 699.73it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 76416/107000 [01:45<00:43, 699.73it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 76448/107000 [01:45<00:43, 699.73it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:  71%|███████▏  | 76480/107000 [01:45<00:43, 699.73it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 76512/107000 [01:45<00:42, 719.71it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 76512/107000 [01:45<00:42, 719.71it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 76544/107000 [01:45<00:42, 719.71it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 76576/107000 [01:45<00:42, 719.71it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 76608/107000 [01:45<00:41, 725.02it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 76608/107000 [01:45<00:41, 725.02it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 76640/107000 [01:46<00:41, 725.02it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 76672/107000 [01:46<00:41, 725.02it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 76704/107000 [01:46<00:41, 723.35it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 76704/107000 [01:46<00:41, 723.35it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 76736/107000 [01:46<00:41, 723.35it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 76768/107000 [01:46<00:41, 723.35it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 76800/107000 [01:46<00:41, 726.54it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 76800/107000 [01:46<00:41, 726.54it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 76832/107000 [01:46<00:41, 726.54it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 76864/107000 [01:46<00:41, 726.54it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 76896/107000 [01:46<00:41, 721.92it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 76896/107000 [01:46<00:41, 721.92it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 76928/107000 [01:46<00:41, 721.92it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 76960/107000 [01:46<00:41, 721.92it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 76992/107000 [01:46<00:41, 718.12it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 76992/107000 [01:46<00:41, 718.12it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77024/107000 [01:46<00:41, 718.12it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77056/107000 [01:46<00:41, 718.12it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77088/107000 [01:46<00:42, 698.30it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77088/107000 [01:46<00:42, 698.30it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77120/107000 [01:46<00:42, 698.30it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77152/107000 [01:46<00:42, 698.30it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77184/107000 [01:46<00:43, 688.45it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77184/107000 [01:46<00:43, 688.45it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77216/107000 [01:46<00:43, 688.45it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77248/107000 [01:46<00:43, 688.45it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77280/107000 [01:46<00:43, 689.83it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77280/107000 [01:46<00:43, 689.83it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77312/107000 [01:46<00:43, 689.83it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77344/107000 [01:47<00:42, 689.83it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77376/107000 [01:47<00:42, 695.14it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77376/107000 [01:47<00:42, 695.14it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77408/107000 [01:47<00:42, 695.14it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77440/107000 [01:47<00:42, 695.14it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77472/107000 [01:47<00:41, 703.84it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77472/107000 [01:47<00:41, 703.84it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77504/107000 [01:47<00:41, 703.84it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77536/107000 [01:47<00:41, 703.84it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77568/107000 [01:47<00:41, 713.17it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  72%|███████▏  | 77568/107000 [01:47<00:41, 713.17it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 77600/107000 [01:47<00:41, 713.17it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 77632/107000 [01:47<00:41, 713.17it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 77664/107000 [01:47<00:40, 718.32it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 77664/107000 [01:47<00:40, 718.32it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 77696/107000 [01:47<00:40, 718.32it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 77728/107000 [01:47<00:40, 718.32it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 77760/107000 [01:47<00:40, 719.68it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 77760/107000 [01:47<00:40, 719.68it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 77792/107000 [01:47<00:40, 719.68it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 77824/107000 [01:47<00:40, 719.68it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 77856/107000 [01:47<00:40, 717.01it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 77856/107000 [01:47<00:40, 717.01it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 77888/107000 [01:47<00:40, 717.01it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 77920/107000 [01:47<00:40, 717.01it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 77952/107000 [01:47<00:41, 708.04it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 77952/107000 [01:47<00:41, 708.04it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 77984/107000 [01:47<00:40, 708.04it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78016/107000 [01:47<00:40, 708.04it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78048/107000 [01:47<00:40, 708.61it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78048/107000 [01:48<00:40, 708.61it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78080/107000 [01:48<00:40, 708.61it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78112/107000 [01:48<00:40, 708.61it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78144/107000 [01:48<00:40, 712.73it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78144/107000 [01:48<00:40, 712.73it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78176/107000 [01:48<00:40, 712.73it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78208/107000 [01:48<00:40, 712.73it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78240/107000 [01:48<00:40, 713.33it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78240/107000 [01:48<00:40, 713.33it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78272/107000 [01:48<00:40, 713.33it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78304/107000 [01:48<00:40, 713.33it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78336/107000 [01:48<00:39, 726.00it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78336/107000 [01:48<00:39, 726.00it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78368/107000 [01:48<00:39, 726.00it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78400/107000 [01:48<00:39, 726.00it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78432/107000 [01:48<00:39, 730.60it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78432/107000 [01:48<00:39, 730.60it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78464/107000 [01:48<00:39, 730.60it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78496/107000 [01:48<00:39, 730.60it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78528/107000 [01:48<00:38, 736.03it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78528/107000 [01:48<00:38, 736.03it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78560/107000 [01:48<00:38, 736.03it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78592/107000 [01:48<00:38, 736.03it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78624/107000 [01:48<00:39, 719.74it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  73%|███████▎  | 78624/107000 [01:48<00:39, 719.74it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 78656/107000 [01:48<00:39, 719.74it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 78688/107000 [01:48<00:39, 719.74it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 78720/107000 [01:48<00:39, 714.70it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 78720/107000 [01:48<00:39, 714.70it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 78752/107000 [01:48<00:39, 714.70it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 78784/107000 [01:49<00:39, 714.70it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 78816/107000 [01:49<00:39, 705.96it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 78816/107000 [01:49<00:39, 705.96it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 78848/107000 [01:49<00:39, 705.96it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 78880/107000 [01:49<00:39, 705.96it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 78912/107000 [01:49<00:40, 700.92it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  74%|███████▎  | 78912/107000 [01:49<00:40, 700.92it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 78944/107000 [01:49<00:40, 700.92it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 78976/107000 [01:49<00:39, 700.92it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79008/107000 [01:49<00:39, 702.33it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79008/107000 [01:49<00:39, 702.33it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79040/107000 [01:49<00:39, 702.33it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79072/107000 [01:49<00:39, 702.33it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79104/107000 [01:49<00:39, 706.12it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79104/107000 [01:49<00:39, 706.12it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79136/107000 [01:49<00:39, 706.12it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79168/107000 [01:49<00:39, 706.12it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79200/107000 [01:49<00:38, 717.83it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79200/107000 [01:49<00:38, 717.83it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79232/107000 [01:49<00:38, 717.83it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79264/107000 [01:49<00:38, 717.83it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79296/107000 [01:49<00:38, 723.96it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79296/107000 [01:49<00:38, 723.96it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79328/107000 [01:49<00:38, 723.96it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79360/107000 [01:49<00:38, 723.96it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79392/107000 [01:49<00:38, 714.12it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79392/107000 [01:49<00:38, 714.12it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79424/107000 [01:49<00:38, 714.12it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79456/107000 [01:49<00:38, 714.12it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79488/107000 [01:49<00:38, 709.49it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79488/107000 [01:50<00:38, 709.49it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79520/107000 [01:50<00:38, 709.49it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79552/107000 [01:50<00:38, 709.49it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79584/107000 [01:50<00:38, 719.43it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79584/107000 [01:50<00:38, 719.43it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79616/107000 [01:50<00:38, 719.43it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79648/107000 [01:50<00:38, 719.43it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79680/107000 [01:50<00:38, 717.21it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79680/107000 [01:50<00:38, 717.21it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  74%|███████▍  | 79712/107000 [01:50<00:38, 717.21it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 79744/107000 [01:50<00:38, 717.21it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 79776/107000 [01:50<00:38, 708.95it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 79776/107000 [01:50<00:38, 708.95it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 79808/107000 [01:50<00:38, 708.95it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 79840/107000 [01:50<00:38, 708.95it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 79872/107000 [01:50<00:38, 709.53it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 79872/107000 [01:50<00:38, 709.53it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 79904/107000 [01:50<00:38, 709.53it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 79936/107000 [01:50<00:38, 709.53it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 79968/107000 [01:50<00:37, 716.16it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 79968/107000 [01:50<00:37, 716.16it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 80000/107000 [01:50<00:37, 716.16it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 80032/107000 [01:50<00:37, 716.16it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 80064/107000 [01:50<00:36, 731.23it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 80064/107000 [01:50<00:36, 731.23it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 80096/107000 [01:50<00:36, 731.23it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 80128/107000 [01:50<00:36, 731.23it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 80160/107000 [01:50<00:36, 737.49it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 80160/107000 [01:50<00:36, 737.49it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 80192/107000 [01:50<00:36, 737.49it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▍  | 80224/107000 [01:51<00:36, 737.49it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 80256/107000 [01:51<00:36, 730.63it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 80256/107000 [01:51<00:36, 730.63it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 80288/107000 [01:51<00:36, 730.63it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 80320/107000 [01:51<00:36, 730.63it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 80352/107000 [01:51<00:36, 730.23it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 80352/107000 [01:51<00:36, 730.23it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 80384/107000 [01:51<00:36, 730.23it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 80416/107000 [01:51<00:36, 730.23it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 80448/107000 [01:51<00:36, 719.54it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 80448/107000 [01:51<00:36, 719.54it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 80480/107000 [01:51<00:36, 719.54it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 80512/107000 [01:51<00:36, 719.54it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 80544/107000 [01:51<00:37, 709.44it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 80544/107000 [01:51<00:37, 709.44it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 80576/107000 [01:51<00:37, 709.44it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 80608/107000 [01:51<00:37, 709.44it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 80640/107000 [01:51<00:37, 698.17it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 80640/107000 [01:51<00:37, 698.17it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 80672/107000 [01:51<00:37, 698.17it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 80704/107000 [01:51<00:37, 698.17it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 80736/107000 [01:51<00:38, 690.28it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 80736/107000 [01:51<00:38, 690.28it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  75%|███████▌  | 80768/107000 [01:51<00:38, 690.28it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 80800/107000 [01:51<00:37, 690.28it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 80832/107000 [01:51<00:36, 708.04it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 80832/107000 [01:51<00:36, 708.04it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 80864/107000 [01:51<00:36, 708.04it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 80896/107000 [01:51<00:36, 708.04it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 80928/107000 [01:51<00:36, 711.80it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 80928/107000 [01:52<00:36, 711.80it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 80960/107000 [01:52<00:36, 711.80it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 80992/107000 [01:52<00:36, 711.80it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81024/107000 [01:52<00:37, 700.72it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81024/107000 [01:52<00:37, 700.72it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81056/107000 [01:52<00:37, 700.72it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81088/107000 [01:52<00:36, 700.72it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81120/107000 [01:52<00:37, 698.10it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81120/107000 [01:52<00:37, 698.10it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81152/107000 [01:52<00:37, 698.10it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81184/107000 [01:52<00:36, 698.10it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81216/107000 [01:52<00:36, 701.85it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81216/107000 [01:52<00:36, 701.85it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81248/107000 [01:52<00:36, 701.85it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81280/107000 [01:52<00:36, 701.85it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81312/107000 [01:52<00:36, 708.80it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81312/107000 [01:52<00:36, 708.80it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81344/107000 [01:52<00:36, 708.80it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81376/107000 [01:52<00:36, 708.80it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81408/107000 [01:52<00:35, 729.43it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81408/107000 [01:52<00:35, 729.43it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81440/107000 [01:52<00:35, 729.43it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81472/107000 [01:52<00:34, 729.43it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81504/107000 [01:52<00:35, 727.39it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81504/107000 [01:52<00:35, 727.39it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81536/107000 [01:52<00:35, 727.39it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▌  | 81568/107000 [01:52<00:34, 727.39it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 81600/107000 [01:52<00:34, 733.74it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 81600/107000 [01:52<00:34, 733.74it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 81632/107000 [01:53<00:34, 733.74it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 81664/107000 [01:53<00:34, 733.74it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 81696/107000 [01:53<00:34, 724.66it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 81696/107000 [01:53<00:34, 724.66it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 81728/107000 [01:53<00:34, 724.66it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 81760/107000 [01:53<00:34, 724.66it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 81792/107000 [01:53<00:34, 724.89it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 81792/107000 [01:53<00:34, 724.89it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  76%|███████▋  | 81824/107000 [01:53<00:34, 724.89it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 81856/107000 [01:53<00:34, 724.89it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 81888/107000 [01:53<00:34, 723.03it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 81888/107000 [01:53<00:34, 723.03it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 81920/107000 [01:53<00:34, 723.03it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 81952/107000 [01:53<00:34, 723.03it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 81984/107000 [01:53<00:35, 714.17it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 81984/107000 [01:53<00:35, 714.17it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82016/107000 [01:53<00:34, 714.17it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82048/107000 [01:53<00:34, 714.17it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82080/107000 [01:53<00:34, 714.97it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82080/107000 [01:53<00:34, 714.97it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82112/107000 [01:53<00:34, 714.97it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82144/107000 [01:53<00:34, 714.97it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82176/107000 [01:53<00:34, 717.31it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82176/107000 [01:53<00:34, 717.31it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82208/107000 [01:53<00:34, 717.31it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82240/107000 [01:53<00:34, 717.31it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82272/107000 [01:53<00:34, 718.75it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82272/107000 [01:53<00:34, 718.75it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82304/107000 [01:53<00:34, 718.75it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82336/107000 [01:53<00:34, 718.75it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82368/107000 [01:53<00:34, 719.01it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82368/107000 [01:54<00:34, 719.01it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82400/107000 [01:54<00:34, 719.01it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82432/107000 [01:54<00:34, 719.01it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82464/107000 [01:54<00:33, 722.40it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82464/107000 [01:54<00:33, 722.40it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82496/107000 [01:54<00:33, 722.40it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82528/107000 [01:54<00:33, 722.40it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82560/107000 [01:54<00:33, 720.73it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82560/107000 [01:54<00:33, 720.73it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82592/107000 [01:54<00:33, 720.73it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82624/107000 [01:54<00:33, 720.73it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82656/107000 [01:54<00:34, 715.83it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82656/107000 [01:54<00:34, 715.83it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82688/107000 [01:54<00:33, 715.83it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82720/107000 [01:54<00:33, 715.83it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82752/107000 [01:54<00:33, 729.35it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82752/107000 [01:54<00:33, 729.35it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82784/107000 [01:54<00:33, 729.35it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82816/107000 [01:54<00:33, 729.35it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82848/107000 [01:54<00:32, 742.00it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82848/107000 [01:54<00:32, 742.00it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82880/107000 [01:54<00:32, 742.00it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  77%|███████▋  | 82912/107000 [01:54<00:32, 742.00it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 82944/107000 [01:54<00:32, 737.54it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 82944/107000 [01:54<00:32, 737.54it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 82976/107000 [01:54<00:32, 737.54it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83008/107000 [01:54<00:32, 737.54it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83040/107000 [01:54<00:32, 738.85it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83040/107000 [01:54<00:32, 738.85it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83072/107000 [01:54<00:32, 738.85it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83104/107000 [01:55<00:32, 738.85it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83136/107000 [01:55<00:31, 753.34it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83136/107000 [01:55<00:31, 753.34it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83168/107000 [01:55<00:31, 753.34it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83200/107000 [01:55<00:31, 753.34it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83232/107000 [01:55<00:32, 740.27it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83232/107000 [01:55<00:32, 740.27it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83264/107000 [01:55<00:32, 740.27it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83296/107000 [01:55<00:32, 740.27it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83328/107000 [01:55<00:31, 741.21it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83328/107000 [01:55<00:31, 741.21it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83360/107000 [01:55<00:31, 741.21it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83392/107000 [01:55<00:31, 741.21it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83424/107000 [01:55<00:31, 736.79it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83424/107000 [01:55<00:31, 736.79it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83456/107000 [01:55<00:31, 736.79it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83488/107000 [01:55<00:31, 736.79it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83520/107000 [01:55<00:32, 727.33it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83520/107000 [01:55<00:32, 727.33it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83552/107000 [01:55<00:32, 727.33it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83584/107000 [01:55<00:32, 727.33it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83616/107000 [01:55<00:32, 725.14it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83616/107000 [01:55<00:32, 725.14it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83648/107000 [01:55<00:32, 725.14it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83680/107000 [01:55<00:32, 725.14it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83712/107000 [01:55<00:32, 721.60it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83712/107000 [01:55<00:32, 721.60it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83744/107000 [01:55<00:32, 721.60it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83776/107000 [01:55<00:32, 721.60it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83808/107000 [01:55<00:32, 722.35it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83808/107000 [01:55<00:32, 722.35it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83840/107000 [01:56<00:32, 722.35it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83872/107000 [01:56<00:32, 722.35it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83904/107000 [01:56<00:31, 725.98it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83904/107000 [01:56<00:31, 725.98it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83936/107000 [01:56<00:31, 725.98it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  78%|███████▊  | 83968/107000 [01:56<00:31, 725.98it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 84000/107000 [01:56<00:31, 727.83it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 84000/107000 [01:56<00:31, 727.83it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 84032/107000 [01:56<00:31, 727.83it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 84064/107000 [01:56<00:31, 727.83it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 84096/107000 [01:56<00:30, 738.99it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 84096/107000 [01:56<00:30, 738.99it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 84128/107000 [01:56<00:30, 738.99it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 84160/107000 [01:56<00:30, 738.99it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 84192/107000 [01:56<00:30, 739.07it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 84192/107000 [01:56<00:30, 739.07it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 84224/107000 [01:56<00:30, 739.07it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  79%|███████▊  | 84256/107000 [01:56<00:30, 739.07it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84288/107000 [01:56<00:30, 741.29it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84288/107000 [01:56<00:30, 741.29it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84320/107000 [01:56<00:30, 741.29it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84352/107000 [01:56<00:30, 741.29it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84384/107000 [01:56<00:29, 754.10it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84384/107000 [01:56<00:29, 754.10it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84416/107000 [01:56<00:29, 754.10it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84448/107000 [01:56<00:29, 754.10it/s, train_loss=0.63] \u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84480/107000 [01:56<00:30, 748.89it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84480/107000 [01:56<00:30, 748.89it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84512/107000 [01:56<00:30, 748.89it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84544/107000 [01:56<00:29, 748.89it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84576/107000 [01:56<00:30, 732.66it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84576/107000 [01:57<00:30, 732.66it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84608/107000 [01:57<00:30, 732.66it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84640/107000 [01:57<00:30, 732.66it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84672/107000 [01:57<00:30, 731.37it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84672/107000 [01:57<00:30, 731.37it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84704/107000 [01:57<00:30, 731.37it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84736/107000 [01:57<00:30, 731.37it/s, train_loss=0.628]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84768/107000 [01:57<00:30, 732.08it/s, train_loss=0.628]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84768/107000 [01:57<00:30, 732.08it/s, train_loss=0.628]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84800/107000 [01:57<00:30, 732.08it/s, train_loss=0.628]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84832/107000 [01:57<00:30, 732.08it/s, train_loss=0.627]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84864/107000 [01:57<00:30, 728.08it/s, train_loss=0.627]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84864/107000 [01:57<00:30, 728.08it/s, train_loss=0.628]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84896/107000 [01:57<00:30, 728.08it/s, train_loss=0.627]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84928/107000 [01:57<00:30, 728.08it/s, train_loss=0.627]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84960/107000 [01:57<00:30, 729.26it/s, train_loss=0.627]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84960/107000 [01:57<00:30, 729.26it/s, train_loss=0.627]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 84992/107000 [01:57<00:30, 729.26it/s, train_loss=0.627]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 85024/107000 [01:57<00:30, 729.26it/s, train_loss=0.627]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 85056/107000 [01:57<00:29, 746.74it/s, train_loss=0.627]\u001b[A\n",
            "Epoch 1:  79%|███████▉  | 85056/107000 [01:57<00:29, 746.74it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 85088/107000 [01:57<00:29, 746.74it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 85120/107000 [01:57<00:29, 746.74it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 85152/107000 [01:57<00:28, 760.48it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 85152/107000 [01:57<00:28, 760.48it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 85184/107000 [01:57<00:28, 760.48it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 85216/107000 [01:57<00:28, 760.48it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 85248/107000 [01:57<00:28, 759.09it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 85248/107000 [01:57<00:28, 759.09it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 85280/107000 [01:57<00:28, 759.09it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 85312/107000 [01:58<00:28, 759.09it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 85344/107000 [01:58<00:29, 736.40it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 85344/107000 [01:58<00:29, 736.40it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 85376/107000 [01:58<00:29, 736.40it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 85408/107000 [01:58<00:29, 736.40it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 85440/107000 [01:58<00:28, 747.98it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 85440/107000 [01:58<00:28, 747.98it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 85472/107000 [01:58<00:28, 747.98it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 85504/107000 [01:58<00:28, 747.98it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 85536/107000 [01:58<00:29, 732.79it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 85536/107000 [01:58<00:29, 732.79it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  80%|███████▉  | 85568/107000 [01:58<00:29, 732.79it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  80%|████████  | 85600/107000 [01:58<00:29, 732.79it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|████████  | 85632/107000 [01:58<00:29, 733.09it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|████████  | 85632/107000 [01:58<00:29, 733.09it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|████████  | 85664/107000 [01:58<00:29, 733.09it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|████████  | 85696/107000 [01:58<00:29, 733.09it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|████████  | 85728/107000 [01:58<00:29, 718.07it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|████████  | 85728/107000 [01:58<00:29, 718.07it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|████████  | 85760/107000 [01:58<00:29, 718.07it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  80%|████████  | 85792/107000 [01:58<00:29, 718.07it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|████████  | 85824/107000 [01:58<00:29, 713.31it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|████████  | 85824/107000 [01:58<00:29, 713.31it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|████████  | 85856/107000 [01:58<00:29, 713.31it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|████████  | 85888/107000 [01:58<00:29, 713.31it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|████████  | 85920/107000 [01:58<00:29, 709.58it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|████████  | 85920/107000 [01:58<00:29, 709.58it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|████████  | 85952/107000 [01:58<00:29, 709.58it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|████████  | 85984/107000 [01:58<00:29, 709.58it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|████████  | 86016/107000 [01:58<00:29, 709.72it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|████████  | 86016/107000 [01:59<00:29, 709.72it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|████████  | 86048/107000 [01:59<00:29, 709.72it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|████████  | 86080/107000 [01:59<00:29, 709.72it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|████████  | 86112/107000 [01:59<00:29, 704.93it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  80%|████████  | 86112/107000 [01:59<00:29, 704.93it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86144/107000 [01:59<00:29, 704.93it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86176/107000 [01:59<00:29, 704.93it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86208/107000 [01:59<00:28, 731.89it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86208/107000 [01:59<00:28, 731.89it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86240/107000 [01:59<00:28, 731.89it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86272/107000 [01:59<00:28, 731.89it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86304/107000 [01:59<00:28, 726.46it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86304/107000 [01:59<00:28, 726.46it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86336/107000 [01:59<00:28, 726.46it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86368/107000 [01:59<00:28, 726.46it/s, train_loss=0.627]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86400/107000 [01:59<00:28, 729.14it/s, train_loss=0.627]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86400/107000 [01:59<00:28, 729.14it/s, train_loss=0.627]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86432/107000 [01:59<00:28, 729.14it/s, train_loss=0.627]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86464/107000 [01:59<00:28, 729.14it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86496/107000 [01:59<00:27, 752.99it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86496/107000 [01:59<00:27, 752.99it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86528/107000 [01:59<00:27, 752.99it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86560/107000 [01:59<00:27, 752.99it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86592/107000 [01:59<00:27, 746.58it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86592/107000 [01:59<00:27, 746.58it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86624/107000 [01:59<00:27, 746.58it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86656/107000 [01:59<00:27, 746.58it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86688/107000 [01:59<00:27, 743.48it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86688/107000 [01:59<00:27, 743.48it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86720/107000 [01:59<00:27, 743.48it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86752/107000 [01:59<00:27, 743.48it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86784/107000 [01:59<00:27, 748.31it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86784/107000 [02:00<00:27, 748.31it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86816/107000 [02:00<00:26, 748.31it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86848/107000 [02:00<00:26, 748.31it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86880/107000 [02:00<00:26, 753.36it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86880/107000 [02:00<00:26, 753.36it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  81%|████████  | 86912/107000 [02:00<00:26, 753.36it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 86944/107000 [02:00<00:26, 753.36it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 86976/107000 [02:00<00:26, 748.44it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 86976/107000 [02:00<00:26, 748.44it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 87008/107000 [02:00<00:26, 748.44it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 87040/107000 [02:00<00:26, 748.44it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 87072/107000 [02:00<00:26, 740.26it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 87072/107000 [02:00<00:26, 740.26it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 87104/107000 [02:00<00:26, 740.26it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 87136/107000 [02:00<00:26, 740.26it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 87168/107000 [02:00<00:27, 727.78it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 87168/107000 [02:00<00:27, 727.78it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  81%|████████▏ | 87200/107000 [02:00<00:27, 727.78it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87232/107000 [02:00<00:27, 727.78it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87264/107000 [02:00<00:27, 711.73it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87264/107000 [02:00<00:27, 711.73it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87296/107000 [02:00<00:27, 711.73it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87328/107000 [02:00<00:27, 711.73it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87360/107000 [02:00<00:28, 700.08it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87360/107000 [02:00<00:28, 700.08it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87392/107000 [02:00<00:28, 700.08it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87424/107000 [02:00<00:27, 700.08it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87456/107000 [02:00<00:28, 692.56it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87456/107000 [02:00<00:28, 692.56it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87488/107000 [02:01<00:28, 692.56it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87520/107000 [02:01<00:28, 692.56it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87552/107000 [02:01<00:28, 678.23it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87552/107000 [02:01<00:28, 678.23it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87584/107000 [02:01<00:28, 678.23it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87616/107000 [02:01<00:28, 678.23it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87648/107000 [02:01<00:27, 692.62it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87648/107000 [02:01<00:27, 692.62it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87680/107000 [02:01<00:27, 692.62it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87712/107000 [02:01<00:27, 692.62it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87744/107000 [02:01<00:27, 712.97it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87744/107000 [02:01<00:27, 712.97it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87776/107000 [02:01<00:26, 712.97it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87808/107000 [02:01<00:26, 712.97it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87840/107000 [02:01<00:27, 708.11it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87840/107000 [02:01<00:27, 708.11it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87872/107000 [02:01<00:27, 708.11it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87904/107000 [02:01<00:26, 708.11it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87936/107000 [02:01<00:26, 722.27it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87936/107000 [02:01<00:26, 722.27it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 87968/107000 [02:01<00:26, 722.27it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 88000/107000 [02:01<00:26, 722.27it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 88032/107000 [02:01<00:26, 728.56it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 88032/107000 [02:01<00:26, 728.56it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 88064/107000 [02:01<00:25, 728.56it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 88096/107000 [02:01<00:25, 728.56it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 88128/107000 [02:01<00:25, 726.01it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 88128/107000 [02:01<00:25, 726.01it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 88160/107000 [02:01<00:25, 726.01it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 88192/107000 [02:02<00:25, 726.01it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 88224/107000 [02:02<00:25, 722.23it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 88224/107000 [02:02<00:25, 722.23it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  82%|████████▏ | 88256/107000 [02:02<00:25, 722.23it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88288/107000 [02:02<00:25, 722.23it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88320/107000 [02:02<00:26, 711.96it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88320/107000 [02:02<00:26, 711.96it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88352/107000 [02:02<00:26, 711.96it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88384/107000 [02:02<00:26, 711.96it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88416/107000 [02:02<00:26, 699.96it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88416/107000 [02:02<00:26, 699.96it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88448/107000 [02:02<00:26, 699.96it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88480/107000 [02:02<00:26, 699.96it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88512/107000 [02:02<00:26, 694.80it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88512/107000 [02:02<00:26, 694.80it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88544/107000 [02:02<00:26, 694.80it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88576/107000 [02:02<00:26, 694.80it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88608/107000 [02:02<00:26, 694.04it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88608/107000 [02:02<00:26, 694.04it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88640/107000 [02:02<00:26, 694.04it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88672/107000 [02:02<00:26, 694.04it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88704/107000 [02:02<00:26, 691.64it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88704/107000 [02:02<00:26, 691.64it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88736/107000 [02:02<00:26, 691.64it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88768/107000 [02:02<00:26, 691.64it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88800/107000 [02:02<00:26, 679.54it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88800/107000 [02:02<00:26, 679.54it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88832/107000 [02:02<00:26, 679.54it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88864/107000 [02:03<00:26, 679.54it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88896/107000 [02:03<00:27, 664.33it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88896/107000 [02:03<00:27, 664.33it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88928/107000 [02:03<00:27, 664.33it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88960/107000 [02:03<00:27, 664.33it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88992/107000 [02:03<00:26, 669.44it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 88992/107000 [02:03<00:26, 669.44it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 89024/107000 [02:03<00:26, 669.44it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 89056/107000 [02:03<00:26, 669.44it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 89088/107000 [02:03<00:25, 689.65it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 89088/107000 [02:03<00:25, 689.65it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 89120/107000 [02:03<00:25, 689.65it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 89152/107000 [02:03<00:25, 689.65it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 89184/107000 [02:03<00:25, 693.45it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 89184/107000 [02:03<00:25, 693.45it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 89216/107000 [02:03<00:25, 693.45it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 89248/107000 [02:03<00:25, 693.45it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 89280/107000 [02:03<00:25, 693.38it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 89280/107000 [02:03<00:25, 693.38it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 89312/107000 [02:03<00:25, 693.38it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  83%|████████▎ | 89344/107000 [02:03<00:25, 693.38it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 89376/107000 [02:03<00:25, 694.84it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 89376/107000 [02:03<00:25, 694.84it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 89408/107000 [02:03<00:25, 694.84it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 89440/107000 [02:03<00:25, 694.84it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 89472/107000 [02:03<00:25, 698.09it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 89472/107000 [02:03<00:25, 698.09it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 89504/107000 [02:03<00:25, 698.09it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 89536/107000 [02:03<00:25, 698.09it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 89568/107000 [02:03<00:25, 682.67it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 89568/107000 [02:04<00:25, 682.67it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  84%|████████▎ | 89600/107000 [02:04<00:25, 682.67it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 89632/107000 [02:04<00:25, 682.67it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 89664/107000 [02:04<00:25, 669.30it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 89664/107000 [02:04<00:25, 669.30it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 89696/107000 [02:04<00:25, 669.30it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 89728/107000 [02:04<00:25, 669.30it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 89760/107000 [02:04<00:24, 698.78it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 89760/107000 [02:04<00:24, 698.78it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 89792/107000 [02:04<00:24, 698.78it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 89824/107000 [02:04<00:24, 698.78it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 89856/107000 [02:04<00:24, 713.38it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 89856/107000 [02:04<00:24, 713.38it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 89888/107000 [02:04<00:23, 713.38it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 89920/107000 [02:04<00:23, 713.38it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 89952/107000 [02:04<00:24, 708.17it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 89952/107000 [02:04<00:24, 708.17it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 89984/107000 [02:04<00:24, 708.17it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 90016/107000 [02:04<00:23, 708.17it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 90048/107000 [02:04<00:23, 714.80it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 90048/107000 [02:04<00:23, 714.80it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 90080/107000 [02:04<00:23, 714.80it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 90112/107000 [02:04<00:23, 714.80it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 90144/107000 [02:04<00:23, 711.10it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 90144/107000 [02:04<00:23, 711.10it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 90176/107000 [02:04<00:23, 711.10it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 90208/107000 [02:04<00:23, 711.10it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 90240/107000 [02:04<00:23, 706.37it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 90240/107000 [02:04<00:23, 706.37it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 90272/107000 [02:05<00:23, 706.37it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 90304/107000 [02:05<00:23, 706.37it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 90336/107000 [02:05<00:23, 715.42it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 90336/107000 [02:05<00:23, 715.42it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 90368/107000 [02:05<00:23, 715.42it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  84%|████████▍ | 90400/107000 [02:05<00:23, 715.42it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 90432/107000 [02:05<00:22, 720.99it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 90432/107000 [02:05<00:22, 720.99it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 90464/107000 [02:05<00:22, 720.99it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 90496/107000 [02:05<00:22, 720.99it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 90528/107000 [02:05<00:22, 727.47it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 90528/107000 [02:05<00:22, 727.47it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 90560/107000 [02:05<00:22, 727.47it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 90592/107000 [02:05<00:22, 727.47it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 90624/107000 [02:05<00:22, 719.47it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 90624/107000 [02:05<00:22, 719.47it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 90656/107000 [02:05<00:22, 719.47it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 90688/107000 [02:05<00:22, 719.47it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 90720/107000 [02:05<00:22, 722.84it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 90720/107000 [02:05<00:22, 722.84it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 90752/107000 [02:05<00:22, 722.84it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 90784/107000 [02:05<00:22, 722.84it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 90816/107000 [02:05<00:22, 719.61it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 90816/107000 [02:05<00:22, 719.61it/s, train_loss=0.62] \u001b[A\n",
            "Epoch 1:  85%|████████▍ | 90848/107000 [02:05<00:22, 719.61it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 90880/107000 [02:05<00:22, 719.61it/s, train_loss=0.62] \u001b[A\n",
            "Epoch 1:  85%|████████▍ | 90912/107000 [02:05<00:21, 731.67it/s, train_loss=0.62]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 90912/107000 [02:05<00:21, 731.67it/s, train_loss=0.62]\u001b[A\n",
            "Epoch 1:  85%|████████▍ | 90944/107000 [02:05<00:21, 731.67it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 90976/107000 [02:05<00:21, 731.67it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 91008/107000 [02:05<00:22, 707.12it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 91008/107000 [02:06<00:22, 707.12it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 91040/107000 [02:06<00:22, 707.12it/s, train_loss=0.62] \u001b[A\n",
            "Epoch 1:  85%|████████▌ | 91072/107000 [02:06<00:22, 707.12it/s, train_loss=0.62]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 91104/107000 [02:06<00:22, 713.89it/s, train_loss=0.62]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 91104/107000 [02:06<00:22, 713.89it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 91136/107000 [02:06<00:22, 713.89it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 91168/107000 [02:06<00:22, 713.89it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 91200/107000 [02:06<00:22, 716.41it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 91200/107000 [02:06<00:22, 716.41it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 91232/107000 [02:06<00:22, 716.41it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 91264/107000 [02:06<00:21, 716.41it/s, train_loss=0.62] \u001b[A\n",
            "Epoch 1:  85%|████████▌ | 91296/107000 [02:06<00:21, 718.88it/s, train_loss=0.62]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 91296/107000 [02:06<00:21, 718.88it/s, train_loss=0.62]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 91328/107000 [02:06<00:21, 718.88it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 91360/107000 [02:06<00:21, 718.88it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 91392/107000 [02:06<00:21, 723.94it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 91392/107000 [02:06<00:21, 723.94it/s, train_loss=0.62] \u001b[A\n",
            "Epoch 1:  85%|████████▌ | 91424/107000 [02:06<00:21, 723.94it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  85%|████████▌ | 91456/107000 [02:06<00:21, 723.94it/s, train_loss=0.62] \u001b[A\n",
            "Epoch 1:  86%|████████▌ | 91488/107000 [02:06<00:21, 710.25it/s, train_loss=0.62]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 91488/107000 [02:06<00:21, 710.25it/s, train_loss=0.62]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 91520/107000 [02:06<00:21, 710.25it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 91552/107000 [02:06<00:21, 710.25it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 91584/107000 [02:06<00:21, 704.61it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 91584/107000 [02:06<00:21, 704.61it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 91616/107000 [02:06<00:21, 704.61it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 91648/107000 [02:06<00:21, 704.61it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 91680/107000 [02:06<00:21, 704.76it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 91680/107000 [02:06<00:21, 704.76it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 91712/107000 [02:07<00:21, 704.76it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 91744/107000 [02:07<00:21, 704.76it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 91776/107000 [02:07<00:21, 695.73it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 91776/107000 [02:07<00:21, 695.73it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 91808/107000 [02:07<00:21, 695.73it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 91840/107000 [02:07<00:21, 695.73it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 91872/107000 [02:07<00:21, 707.28it/s, train_loss=0.621]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 91872/107000 [02:07<00:21, 707.28it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 91904/107000 [02:07<00:21, 707.28it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 91936/107000 [02:07<00:21, 707.28it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 91968/107000 [02:07<00:21, 709.92it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 91968/107000 [02:07<00:21, 709.92it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 92000/107000 [02:07<00:21, 709.92it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 92032/107000 [02:07<00:21, 709.92it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 92064/107000 [02:07<00:20, 719.85it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 92064/107000 [02:07<00:20, 719.85it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 92096/107000 [02:07<00:20, 719.85it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 92128/107000 [02:07<00:20, 719.85it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 92160/107000 [02:07<00:20, 707.79it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 92160/107000 [02:07<00:20, 707.79it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 92192/107000 [02:07<00:20, 707.79it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 92224/107000 [02:07<00:20, 707.79it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 92256/107000 [02:07<00:21, 697.01it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  86%|████████▌ | 92256/107000 [02:07<00:21, 697.01it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 92288/107000 [02:07<00:21, 697.01it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 92320/107000 [02:07<00:21, 697.01it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 92352/107000 [02:07<00:21, 693.44it/s, train_loss=0.622]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 92352/107000 [02:07<00:21, 693.44it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 92384/107000 [02:07<00:21, 693.44it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 92416/107000 [02:08<00:21, 693.44it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 92448/107000 [02:08<00:21, 690.98it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 92448/107000 [02:08<00:21, 690.98it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 92480/107000 [02:08<00:21, 690.98it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 92512/107000 [02:08<00:20, 690.98it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 92544/107000 [02:08<00:20, 690.79it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  86%|████████▋ | 92544/107000 [02:08<00:20, 690.79it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 92576/107000 [02:08<00:20, 690.79it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 92608/107000 [02:08<00:20, 690.79it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 92640/107000 [02:08<00:20, 686.41it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 92640/107000 [02:08<00:20, 686.41it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 92672/107000 [02:08<00:20, 686.41it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 92704/107000 [02:08<00:20, 686.41it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 92736/107000 [02:08<00:20, 711.10it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 92736/107000 [02:08<00:20, 711.10it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 92768/107000 [02:08<00:20, 711.10it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 92800/107000 [02:08<00:19, 711.10it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 92832/107000 [02:08<00:19, 712.54it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 92832/107000 [02:08<00:19, 712.54it/s, train_loss=0.623]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 92864/107000 [02:08<00:19, 712.54it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 92896/107000 [02:08<00:19, 712.54it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 92928/107000 [02:08<00:19, 713.87it/s, train_loss=0.624]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 92928/107000 [02:08<00:19, 713.87it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 92960/107000 [02:08<00:19, 713.87it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 92992/107000 [02:08<00:19, 713.87it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93024/107000 [02:08<00:19, 720.20it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93024/107000 [02:08<00:19, 720.20it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93056/107000 [02:08<00:19, 720.20it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93088/107000 [02:08<00:19, 720.20it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93120/107000 [02:08<00:19, 718.28it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93120/107000 [02:09<00:19, 718.28it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93152/107000 [02:09<00:19, 718.28it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93184/107000 [02:09<00:19, 718.28it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93216/107000 [02:09<00:19, 713.21it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93216/107000 [02:09<00:19, 713.21it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93248/107000 [02:09<00:19, 713.21it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93280/107000 [02:09<00:19, 713.21it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93312/107000 [02:09<00:19, 711.76it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93312/107000 [02:09<00:19, 711.76it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93344/107000 [02:09<00:19, 711.76it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93376/107000 [02:09<00:19, 711.76it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93408/107000 [02:09<00:19, 686.89it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93408/107000 [02:09<00:19, 686.89it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93440/107000 [02:09<00:19, 686.89it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93472/107000 [02:09<00:19, 686.89it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93504/107000 [02:09<00:19, 704.55it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93504/107000 [02:09<00:19, 704.55it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93536/107000 [02:09<00:19, 704.55it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93568/107000 [02:09<00:19, 704.55it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93600/107000 [02:09<00:18, 713.45it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  87%|████████▋ | 93600/107000 [02:09<00:18, 713.45it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 93632/107000 [02:09<00:18, 713.45it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 93664/107000 [02:09<00:18, 713.45it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 93696/107000 [02:09<00:18, 720.54it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 93696/107000 [02:09<00:18, 720.54it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 93728/107000 [02:09<00:18, 720.54it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 93760/107000 [02:09<00:18, 720.54it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 93792/107000 [02:09<00:18, 720.56it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 93792/107000 [02:09<00:18, 720.56it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 93824/107000 [02:10<00:18, 720.56it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 93856/107000 [02:10<00:18, 720.56it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 93888/107000 [02:10<00:18, 720.40it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 93888/107000 [02:10<00:18, 720.40it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 93920/107000 [02:10<00:18, 720.40it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 93952/107000 [02:10<00:18, 720.40it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 93984/107000 [02:10<00:18, 714.25it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 93984/107000 [02:10<00:18, 714.25it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94016/107000 [02:10<00:18, 714.25it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94048/107000 [02:10<00:18, 714.25it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94080/107000 [02:10<00:18, 710.06it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94080/107000 [02:10<00:18, 710.06it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94112/107000 [02:10<00:18, 710.06it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94144/107000 [02:10<00:18, 710.06it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94176/107000 [02:10<00:17, 721.00it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94176/107000 [02:10<00:17, 721.00it/s, train_loss=0.625]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94208/107000 [02:10<00:17, 721.00it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94240/107000 [02:10<00:17, 721.00it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94272/107000 [02:10<00:17, 719.55it/s, train_loss=0.626]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94272/107000 [02:10<00:17, 719.55it/s, train_loss=0.627]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94304/107000 [02:10<00:17, 719.55it/s, train_loss=0.627]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94336/107000 [02:10<00:17, 719.55it/s, train_loss=0.627]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94368/107000 [02:10<00:17, 720.17it/s, train_loss=0.627]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94368/107000 [02:10<00:17, 720.17it/s, train_loss=0.628]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94400/107000 [02:10<00:17, 720.17it/s, train_loss=0.628]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94432/107000 [02:10<00:17, 720.17it/s, train_loss=0.628]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94464/107000 [02:10<00:17, 717.72it/s, train_loss=0.628]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94464/107000 [02:10<00:17, 717.72it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94496/107000 [02:10<00:17, 717.72it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94528/107000 [02:10<00:17, 717.72it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94560/107000 [02:10<00:17, 706.05it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94560/107000 [02:11<00:17, 706.05it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94592/107000 [02:11<00:17, 706.05it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94624/107000 [02:11<00:17, 706.05it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94656/107000 [02:11<00:17, 724.04it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94656/107000 [02:11<00:17, 724.04it/s, train_loss=0.63] \u001b[A\n",
            "Epoch 1:  88%|████████▊ | 94688/107000 [02:11<00:17, 724.04it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 94720/107000 [02:11<00:16, 724.04it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 94752/107000 [02:11<00:16, 742.51it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 94752/107000 [02:11<00:16, 742.51it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 94784/107000 [02:11<00:16, 742.51it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 94816/107000 [02:11<00:16, 742.51it/s, train_loss=0.63] \u001b[A\n",
            "Epoch 1:  89%|████████▊ | 94848/107000 [02:11<00:16, 725.81it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 94848/107000 [02:11<00:16, 725.81it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 94880/107000 [02:11<00:16, 725.81it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 94912/107000 [02:11<00:16, 725.81it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 94944/107000 [02:11<00:16, 711.20it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  89%|████████▊ | 94944/107000 [02:11<00:16, 711.20it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 94976/107000 [02:11<00:16, 711.20it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95008/107000 [02:11<00:16, 711.20it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95040/107000 [02:11<00:16, 719.90it/s, train_loss=0.629]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95040/107000 [02:11<00:16, 719.90it/s, train_loss=0.63] \u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95072/107000 [02:11<00:16, 719.90it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95104/107000 [02:11<00:16, 719.90it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95136/107000 [02:11<00:16, 723.68it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95136/107000 [02:11<00:16, 723.68it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95168/107000 [02:11<00:16, 723.68it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95200/107000 [02:11<00:16, 723.68it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95232/107000 [02:11<00:16, 724.19it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95232/107000 [02:11<00:16, 724.19it/s, train_loss=0.63] \u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95264/107000 [02:12<00:16, 724.19it/s, train_loss=0.63]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95296/107000 [02:12<00:16, 724.19it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95328/107000 [02:12<00:16, 717.57it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95328/107000 [02:12<00:16, 717.57it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95360/107000 [02:12<00:16, 717.57it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95392/107000 [02:12<00:16, 717.57it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95424/107000 [02:12<00:15, 732.12it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95424/107000 [02:12<00:15, 732.12it/s, train_loss=0.631]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95456/107000 [02:12<00:15, 732.12it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95488/107000 [02:12<00:15, 732.12it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95520/107000 [02:12<00:15, 734.49it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95520/107000 [02:12<00:15, 734.49it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95552/107000 [02:12<00:15, 734.49it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95584/107000 [02:12<00:15, 734.49it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95616/107000 [02:12<00:15, 726.88it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95616/107000 [02:12<00:15, 726.88it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95648/107000 [02:12<00:15, 726.88it/s, train_loss=0.632]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95680/107000 [02:12<00:15, 726.88it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95712/107000 [02:12<00:15, 729.08it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95712/107000 [02:12<00:15, 729.08it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  89%|████████▉ | 95744/107000 [02:12<00:15, 729.08it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 95776/107000 [02:12<00:15, 729.08it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 95808/107000 [02:12<00:15, 723.77it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 95808/107000 [02:12<00:15, 723.77it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 95840/107000 [02:12<00:15, 723.77it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 95872/107000 [02:12<00:15, 723.77it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 95904/107000 [02:12<00:15, 719.00it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 95904/107000 [02:12<00:15, 719.00it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 95936/107000 [02:12<00:15, 719.00it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 95968/107000 [02:12<00:15, 719.00it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 96000/107000 [02:12<00:15, 724.10it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 96000/107000 [02:13<00:15, 724.10it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 96032/107000 [02:13<00:15, 724.10it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 96064/107000 [02:13<00:15, 724.10it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 96096/107000 [02:13<00:15, 715.74it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 96096/107000 [02:13<00:15, 715.74it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 96128/107000 [02:13<00:15, 715.74it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 96160/107000 [02:13<00:15, 715.74it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 96192/107000 [02:13<00:15, 710.15it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 96192/107000 [02:13<00:15, 710.15it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 96224/107000 [02:13<00:15, 710.15it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 96256/107000 [02:13<00:15, 710.15it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 96288/107000 [02:13<00:15, 699.96it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  90%|████████▉ | 96288/107000 [02:13<00:15, 699.96it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 96320/107000 [02:13<00:15, 699.96it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 96352/107000 [02:13<00:15, 699.96it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 96384/107000 [02:13<00:14, 709.43it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 96384/107000 [02:13<00:14, 709.43it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 96416/107000 [02:13<00:14, 709.43it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 96448/107000 [02:13<00:14, 709.43it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 96480/107000 [02:13<00:14, 714.05it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 96480/107000 [02:13<00:14, 714.05it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 96512/107000 [02:13<00:14, 714.05it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 96544/107000 [02:13<00:14, 714.05it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 96576/107000 [02:13<00:14, 715.34it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 96576/107000 [02:13<00:14, 715.34it/s, train_loss=0.633]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 96608/107000 [02:13<00:14, 715.34it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 96640/107000 [02:13<00:14, 715.34it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 96672/107000 [02:13<00:14, 730.78it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 96672/107000 [02:13<00:14, 730.78it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 96704/107000 [02:14<00:14, 730.78it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 96736/107000 [02:14<00:14, 730.78it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 96768/107000 [02:14<00:14, 727.38it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 96768/107000 [02:14<00:14, 727.38it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 96800/107000 [02:14<00:14, 727.38it/s, train_loss=0.634]\u001b[A\n",
            "Epoch 1:  90%|█████████ | 96832/107000 [02:14<00:13, 727.38it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 96864/107000 [02:14<00:13, 740.39it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 96864/107000 [02:14<00:13, 740.39it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 96896/107000 [02:14<00:13, 740.39it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 96928/107000 [02:14<00:13, 740.39it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 96960/107000 [02:14<00:13, 749.30it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 96960/107000 [02:14<00:13, 749.30it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 96992/107000 [02:14<00:13, 749.30it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97024/107000 [02:14<00:13, 749.30it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97056/107000 [02:14<00:13, 733.51it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97056/107000 [02:14<00:13, 733.51it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97088/107000 [02:14<00:13, 733.51it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97120/107000 [02:14<00:13, 733.51it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97152/107000 [02:14<00:14, 702.15it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97152/107000 [02:14<00:14, 702.15it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97184/107000 [02:14<00:13, 702.15it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97216/107000 [02:14<00:13, 702.15it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97248/107000 [02:14<00:14, 695.77it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97248/107000 [02:14<00:14, 695.77it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97280/107000 [02:14<00:13, 695.77it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97312/107000 [02:14<00:13, 695.77it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97344/107000 [02:14<00:13, 695.73it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97344/107000 [02:14<00:13, 695.73it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97376/107000 [02:14<00:13, 695.73it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97408/107000 [02:14<00:13, 695.73it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97440/107000 [02:15<00:13, 695.99it/s, train_loss=0.635]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97440/107000 [02:15<00:13, 695.99it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97472/107000 [02:15<00:13, 695.99it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97504/107000 [02:15<00:13, 695.99it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97536/107000 [02:15<00:13, 701.26it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97536/107000 [02:15<00:13, 701.26it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97568/107000 [02:15<00:13, 701.26it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97600/107000 [02:15<00:13, 701.26it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97632/107000 [02:15<00:13, 709.84it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  91%|█████████ | 97632/107000 [02:15<00:13, 709.84it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 97664/107000 [02:15<00:13, 709.84it/s, train_loss=0.636]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 97696/107000 [02:15<00:13, 709.84it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 97728/107000 [02:15<00:13, 701.65it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 97728/107000 [02:15<00:13, 701.65it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 97760/107000 [02:15<00:13, 701.65it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 97792/107000 [02:15<00:13, 701.65it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 97824/107000 [02:15<00:12, 708.68it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 97824/107000 [02:15<00:12, 708.68it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 97856/107000 [02:15<00:12, 708.68it/s, train_loss=0.637]\u001b[A\n",
            "Epoch 1:  91%|█████████▏| 97888/107000 [02:15<00:12, 708.68it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 97920/107000 [02:15<00:12, 711.60it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 97920/107000 [02:15<00:12, 711.60it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 97952/107000 [02:15<00:12, 711.60it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 97984/107000 [02:15<00:12, 711.60it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98016/107000 [02:15<00:12, 706.28it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98016/107000 [02:15<00:12, 706.28it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98048/107000 [02:15<00:12, 706.28it/s, train_loss=0.638]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98080/107000 [02:15<00:12, 706.28it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98112/107000 [02:15<00:12, 711.21it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98112/107000 [02:15<00:12, 711.21it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98144/107000 [02:16<00:12, 711.21it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98176/107000 [02:16<00:12, 711.21it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98208/107000 [02:16<00:12, 709.05it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98208/107000 [02:16<00:12, 709.05it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98240/107000 [02:16<00:12, 709.05it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98272/107000 [02:16<00:12, 709.05it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98304/107000 [02:16<00:12, 705.82it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98304/107000 [02:16<00:12, 705.82it/s, train_loss=0.639]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98336/107000 [02:16<00:12, 705.82it/s, train_loss=0.64] \u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98368/107000 [02:16<00:12, 705.82it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98400/107000 [02:16<00:12, 711.41it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98400/107000 [02:16<00:12, 711.41it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98432/107000 [02:16<00:12, 711.41it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98464/107000 [02:16<00:11, 711.41it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98496/107000 [02:16<00:11, 709.54it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98496/107000 [02:16<00:11, 709.54it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98528/107000 [02:16<00:11, 709.54it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98560/107000 [02:16<00:11, 709.54it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98592/107000 [02:16<00:12, 678.17it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98592/107000 [02:16<00:12, 678.17it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98624/107000 [02:16<00:12, 678.17it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98656/107000 [02:16<00:12, 678.17it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98688/107000 [02:16<00:12, 668.87it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98688/107000 [02:16<00:12, 668.87it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98720/107000 [02:16<00:12, 668.87it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98752/107000 [02:16<00:12, 668.87it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98784/107000 [02:16<00:12, 658.24it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98784/107000 [02:16<00:12, 658.24it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98816/107000 [02:17<00:12, 658.24it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98848/107000 [02:17<00:12, 658.24it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98880/107000 [02:17<00:12, 659.02it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98880/107000 [02:17<00:12, 659.02it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98912/107000 [02:17<00:12, 659.02it/s, train_loss=0.64] \u001b[A\n",
            "Epoch 1:  92%|█████████▏| 98944/107000 [02:17<00:12, 659.02it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 98976/107000 [02:17<00:11, 687.12it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 98976/107000 [02:17<00:11, 687.12it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99008/107000 [02:17<00:11, 687.12it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99040/107000 [02:17<00:11, 687.12it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99072/107000 [02:17<00:11, 708.99it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99072/107000 [02:17<00:11, 708.99it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99104/107000 [02:17<00:11, 708.99it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99136/107000 [02:17<00:11, 708.99it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99168/107000 [02:17<00:10, 721.15it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99168/107000 [02:17<00:10, 721.15it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99200/107000 [02:17<00:10, 721.15it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99232/107000 [02:17<00:10, 721.15it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99264/107000 [02:17<00:10, 714.10it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99264/107000 [02:17<00:10, 714.10it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99296/107000 [02:17<00:10, 714.10it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99328/107000 [02:17<00:10, 714.10it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99360/107000 [02:17<00:10, 698.92it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99360/107000 [02:17<00:10, 698.92it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99392/107000 [02:17<00:10, 698.92it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99424/107000 [02:17<00:10, 698.92it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99456/107000 [02:17<00:10, 720.29it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99456/107000 [02:17<00:10, 720.29it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99488/107000 [02:17<00:10, 720.29it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99520/107000 [02:18<00:10, 720.29it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99552/107000 [02:18<00:10, 719.60it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99552/107000 [02:18<00:10, 719.60it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99584/107000 [02:18<00:10, 719.60it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99616/107000 [02:18<00:10, 719.60it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99648/107000 [02:18<00:10, 729.25it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99648/107000 [02:18<00:10, 729.25it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99680/107000 [02:18<00:10, 729.25it/s, train_loss=0.64] \u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99712/107000 [02:18<00:09, 729.25it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99744/107000 [02:18<00:09, 745.96it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99744/107000 [02:18<00:09, 745.96it/s, train_loss=0.64]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99776/107000 [02:18<00:09, 745.96it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99808/107000 [02:18<00:09, 745.96it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99840/107000 [02:18<00:09, 757.36it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99840/107000 [02:18<00:09, 757.36it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99872/107000 [02:18<00:09, 757.36it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99904/107000 [02:18<00:09, 757.36it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99936/107000 [02:18<00:09, 754.26it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99936/107000 [02:18<00:09, 754.26it/s, train_loss=0.641]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 99968/107000 [02:18<00:09, 754.26it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 100000/107000 [02:18<00:09, 754.26it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 100032/107000 [02:18<00:09, 725.40it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  93%|█████████▎| 100032/107000 [02:18<00:09, 725.40it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 100064/107000 [02:18<00:09, 725.40it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 100096/107000 [02:18<00:09, 725.40it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 100128/107000 [02:18<00:09, 717.62it/s, train_loss=0.642]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 100128/107000 [02:18<00:09, 717.62it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 100160/107000 [02:18<00:09, 717.62it/s, train_loss=0.643]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 100192/107000 [02:18<00:09, 717.62it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 100224/107000 [02:18<00:09, 721.19it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 100224/107000 [02:18<00:09, 721.19it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 100256/107000 [02:19<00:09, 721.19it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  94%|█████████▎| 100288/107000 [02:19<00:09, 721.19it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100320/107000 [02:19<00:09, 725.79it/s, train_loss=0.644]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100320/107000 [02:19<00:09, 725.79it/s, train_loss=0.645]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100352/107000 [02:19<00:09, 725.79it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100384/107000 [02:19<00:09, 725.79it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100416/107000 [02:19<00:09, 722.74it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100416/107000 [02:19<00:09, 722.74it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100448/107000 [02:19<00:09, 722.74it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100480/107000 [02:19<00:09, 722.74it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100512/107000 [02:19<00:08, 723.27it/s, train_loss=0.646]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100512/107000 [02:19<00:08, 723.27it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100544/107000 [02:19<00:08, 723.27it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100576/107000 [02:19<00:08, 723.27it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100608/107000 [02:19<00:08, 738.45it/s, train_loss=0.647]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100608/107000 [02:19<00:08, 738.45it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100640/107000 [02:19<00:08, 738.45it/s, train_loss=0.648]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100672/107000 [02:19<00:08, 738.45it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100704/107000 [02:19<00:08, 721.90it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100704/107000 [02:19<00:08, 721.90it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100736/107000 [02:19<00:08, 721.90it/s, train_loss=0.649]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100768/107000 [02:19<00:08, 721.90it/s, train_loss=0.65] \u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100800/107000 [02:19<00:08, 716.60it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100800/107000 [02:19<00:08, 716.60it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100832/107000 [02:19<00:08, 716.60it/s, train_loss=0.65]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100864/107000 [02:19<00:08, 716.60it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100896/107000 [02:19<00:08, 717.63it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100896/107000 [02:19<00:08, 717.63it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100928/107000 [02:19<00:08, 717.63it/s, train_loss=0.651]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100960/107000 [02:19<00:08, 717.63it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100992/107000 [02:19<00:08, 721.16it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 100992/107000 [02:20<00:08, 721.16it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 101024/107000 [02:20<00:08, 721.16it/s, train_loss=0.652]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 101056/107000 [02:20<00:08, 721.16it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 101088/107000 [02:20<00:08, 710.68it/s, train_loss=0.653]\u001b[A\n",
            "Epoch 1:  94%|█████████▍| 101088/107000 [02:20<00:08, 710.68it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 101120/107000 [02:20<00:08, 710.68it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 101152/107000 [02:20<00:08, 710.68it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 101184/107000 [02:20<00:08, 709.44it/s, train_loss=0.654]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 101184/107000 [02:20<00:08, 709.44it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 101216/107000 [02:20<00:08, 709.44it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 101248/107000 [02:20<00:08, 709.44it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 101280/107000 [02:20<00:08, 708.42it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 101280/107000 [02:20<00:08, 708.42it/s, train_loss=0.655]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 101312/107000 [02:20<00:08, 708.42it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 101344/107000 [02:20<00:07, 708.42it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 101376/107000 [02:20<00:07, 704.78it/s, train_loss=0.656]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 101376/107000 [02:20<00:07, 704.78it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 101408/107000 [02:20<00:07, 704.78it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 101440/107000 [02:20<00:07, 704.78it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 101472/107000 [02:20<00:07, 719.19it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 101472/107000 [02:20<00:07, 719.19it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 101504/107000 [02:20<00:07, 719.19it/s, train_loss=0.658]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 101536/107000 [02:20<00:07, 719.19it/s, train_loss=0.658]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 101568/107000 [02:20<00:07, 717.93it/s, train_loss=0.658]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 101568/107000 [02:20<00:07, 717.93it/s, train_loss=0.658]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 101600/107000 [02:20<00:07, 717.93it/s, train_loss=0.657]\u001b[A\n",
            "Epoch 1:  95%|█████████▍| 101632/107000 [02:20<00:07, 717.93it/s, train_loss=0.658]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 101664/107000 [02:20<00:07, 726.82it/s, train_loss=0.658]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 101664/107000 [02:20<00:07, 726.82it/s, train_loss=0.658]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 101696/107000 [02:21<00:07, 726.82it/s, train_loss=0.658]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 101728/107000 [02:21<00:07, 726.82it/s, train_loss=0.658]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 101760/107000 [02:21<00:07, 720.71it/s, train_loss=0.658]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 101760/107000 [02:21<00:07, 720.71it/s, train_loss=0.658]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 101792/107000 [02:21<00:07, 720.71it/s, train_loss=0.658]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 101824/107000 [02:21<00:07, 720.71it/s, train_loss=0.658]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 101856/107000 [02:21<00:07, 731.53it/s, train_loss=0.658]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 101856/107000 [02:21<00:07, 731.53it/s, train_loss=0.658]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 101888/107000 [02:21<00:06, 731.53it/s, train_loss=0.659]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 101920/107000 [02:21<00:06, 731.53it/s, train_loss=0.66] \u001b[A\n",
            "Epoch 1:  95%|█████████▌| 101952/107000 [02:21<00:06, 754.28it/s, train_loss=0.66]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 101952/107000 [02:21<00:06, 754.28it/s, train_loss=0.66]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 101984/107000 [02:21<00:06, 754.28it/s, train_loss=0.66]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 102016/107000 [02:21<00:06, 754.28it/s, train_loss=0.66]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 102048/107000 [02:21<00:06, 745.89it/s, train_loss=0.66]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 102048/107000 [02:21<00:06, 745.89it/s, train_loss=0.659]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 102080/107000 [02:21<00:06, 745.89it/s, train_loss=0.66] \u001b[A\n",
            "Epoch 1:  95%|█████████▌| 102112/107000 [02:21<00:06, 745.89it/s, train_loss=0.66]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 102144/107000 [02:21<00:06, 739.20it/s, train_loss=0.66]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 102144/107000 [02:21<00:06, 739.20it/s, train_loss=0.66]\u001b[A\n",
            "Epoch 1:  95%|█████████▌| 102176/107000 [02:21<00:06, 739.20it/s, train_loss=0.66]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102208/107000 [02:21<00:06, 739.20it/s, train_loss=0.66]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102240/107000 [02:21<00:06, 736.94it/s, train_loss=0.66]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102240/107000 [02:21<00:06, 736.94it/s, train_loss=0.66]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102272/107000 [02:21<00:06, 736.94it/s, train_loss=0.66]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102304/107000 [02:21<00:06, 736.94it/s, train_loss=0.661]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102336/107000 [02:21<00:07, 653.23it/s, train_loss=0.661]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102336/107000 [02:21<00:07, 653.23it/s, train_loss=0.66] \u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102368/107000 [02:21<00:07, 653.23it/s, train_loss=0.659]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102400/107000 [02:22<00:07, 653.23it/s, train_loss=0.66] \u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102432/107000 [02:22<00:06, 659.96it/s, train_loss=0.66]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102432/107000 [02:22<00:06, 659.96it/s, train_loss=0.66]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102464/107000 [02:22<00:06, 659.96it/s, train_loss=0.661]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102496/107000 [02:22<00:06, 659.96it/s, train_loss=0.661]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102528/107000 [02:22<00:06, 679.86it/s, train_loss=0.661]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102528/107000 [02:22<00:06, 679.86it/s, train_loss=0.661]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102560/107000 [02:22<00:06, 679.86it/s, train_loss=0.661]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102592/107000 [02:22<00:06, 679.86it/s, train_loss=0.661]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102624/107000 [02:22<00:06, 703.05it/s, train_loss=0.661]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102624/107000 [02:22<00:06, 703.05it/s, train_loss=0.662]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102656/107000 [02:22<00:06, 703.05it/s, train_loss=0.662]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102688/107000 [02:22<00:06, 703.05it/s, train_loss=0.663]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102720/107000 [02:22<00:06, 701.73it/s, train_loss=0.663]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102720/107000 [02:22<00:06, 701.73it/s, train_loss=0.663]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102752/107000 [02:22<00:06, 701.73it/s, train_loss=0.663]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102784/107000 [02:22<00:06, 701.73it/s, train_loss=0.663]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102816/107000 [02:22<00:05, 710.48it/s, train_loss=0.663]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102816/107000 [02:22<00:05, 710.48it/s, train_loss=0.663]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102848/107000 [02:22<00:05, 710.48it/s, train_loss=0.664]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102880/107000 [02:22<00:05, 710.48it/s, train_loss=0.664]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102912/107000 [02:22<00:05, 688.03it/s, train_loss=0.664]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102912/107000 [02:22<00:05, 688.03it/s, train_loss=0.664]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102944/107000 [02:22<00:05, 688.03it/s, train_loss=0.664]\u001b[A\n",
            "Epoch 1:  96%|█████████▌| 102976/107000 [02:22<00:05, 688.03it/s, train_loss=0.664]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 103008/107000 [02:22<00:05, 694.11it/s, train_loss=0.664]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 103008/107000 [02:22<00:05, 694.11it/s, train_loss=0.664]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 103040/107000 [02:22<00:05, 694.11it/s, train_loss=0.665]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 103072/107000 [02:22<00:05, 694.11it/s, train_loss=0.665]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 103104/107000 [02:22<00:05, 660.26it/s, train_loss=0.665]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 103104/107000 [02:23<00:05, 660.26it/s, train_loss=0.666]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 103136/107000 [02:23<00:05, 660.26it/s, train_loss=0.666]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 103168/107000 [02:23<00:05, 660.26it/s, train_loss=0.667]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 103200/107000 [02:23<00:05, 684.41it/s, train_loss=0.667]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 103200/107000 [02:23<00:05, 684.41it/s, train_loss=0.667]\u001b[A\n",
            "Epoch 1:  96%|█████████▋| 103232/107000 [02:23<00:05, 684.41it/s, train_loss=0.667]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103264/107000 [02:23<00:05, 684.41it/s, train_loss=0.667]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103296/107000 [02:23<00:05, 699.41it/s, train_loss=0.667]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103296/107000 [02:23<00:05, 699.41it/s, train_loss=0.667]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103328/107000 [02:23<00:05, 699.41it/s, train_loss=0.667]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103360/107000 [02:23<00:05, 699.41it/s, train_loss=0.668]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103392/107000 [02:23<00:05, 706.90it/s, train_loss=0.668]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103392/107000 [02:23<00:05, 706.90it/s, train_loss=0.668]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103424/107000 [02:23<00:05, 706.90it/s, train_loss=0.667]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103456/107000 [02:23<00:05, 706.90it/s, train_loss=0.667]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103488/107000 [02:23<00:04, 705.91it/s, train_loss=0.667]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103488/107000 [02:23<00:04, 705.91it/s, train_loss=0.667]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103520/107000 [02:23<00:04, 705.91it/s, train_loss=0.667]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103552/107000 [02:23<00:04, 705.91it/s, train_loss=0.668]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103584/107000 [02:23<00:04, 704.11it/s, train_loss=0.668]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103584/107000 [02:23<00:04, 704.11it/s, train_loss=0.668]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103616/107000 [02:23<00:04, 704.11it/s, train_loss=0.668]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103648/107000 [02:23<00:04, 704.11it/s, train_loss=0.669]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103680/107000 [02:23<00:04, 702.79it/s, train_loss=0.669]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103680/107000 [02:23<00:04, 702.79it/s, train_loss=0.669]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103712/107000 [02:23<00:04, 702.79it/s, train_loss=0.669]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103744/107000 [02:23<00:04, 702.79it/s, train_loss=0.67] \u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103776/107000 [02:23<00:04, 687.57it/s, train_loss=0.67]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103776/107000 [02:23<00:04, 687.57it/s, train_loss=0.67]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103808/107000 [02:24<00:04, 687.57it/s, train_loss=0.671]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103840/107000 [02:24<00:04, 687.57it/s, train_loss=0.671]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103872/107000 [02:24<00:04, 676.24it/s, train_loss=0.671]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103872/107000 [02:24<00:04, 676.24it/s, train_loss=0.671]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103904/107000 [02:24<00:04, 676.24it/s, train_loss=0.672]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103936/107000 [02:24<00:04, 676.24it/s, train_loss=0.672]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103968/107000 [02:24<00:04, 684.60it/s, train_loss=0.672]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 103968/107000 [02:24<00:04, 684.60it/s, train_loss=0.672]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 104000/107000 [02:24<00:04, 684.60it/s, train_loss=0.673]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 104032/107000 [02:24<00:04, 684.60it/s, train_loss=0.673]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 104064/107000 [02:24<00:04, 683.86it/s, train_loss=0.673]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 104064/107000 [02:24<00:04, 683.86it/s, train_loss=0.674]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 104096/107000 [02:24<00:04, 683.86it/s, train_loss=0.673]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 104128/107000 [02:24<00:04, 683.86it/s, train_loss=0.674]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 104160/107000 [02:24<00:04, 693.78it/s, train_loss=0.674]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 104160/107000 [02:24<00:04, 693.78it/s, train_loss=0.674]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 104192/107000 [02:24<00:04, 693.78it/s, train_loss=0.675]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 104224/107000 [02:24<00:04, 693.78it/s, train_loss=0.676]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 104256/107000 [02:24<00:03, 713.26it/s, train_loss=0.676]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 104256/107000 [02:24<00:03, 713.26it/s, train_loss=0.676]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 104288/107000 [02:24<00:03, 713.26it/s, train_loss=0.676]\u001b[A\n",
            "Epoch 1:  97%|█████████▋| 104320/107000 [02:24<00:03, 713.26it/s, train_loss=0.676]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104352/107000 [02:24<00:03, 717.84it/s, train_loss=0.676]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104352/107000 [02:24<00:03, 717.84it/s, train_loss=0.676]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104384/107000 [02:24<00:03, 717.84it/s, train_loss=0.675]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104416/107000 [02:24<00:03, 717.84it/s, train_loss=0.676]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104448/107000 [02:24<00:03, 724.12it/s, train_loss=0.676]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104448/107000 [02:24<00:03, 724.12it/s, train_loss=0.676]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104480/107000 [02:24<00:03, 724.12it/s, train_loss=0.676]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104512/107000 [02:25<00:03, 724.12it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104544/107000 [02:25<00:03, 735.83it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104544/107000 [02:25<00:03, 735.83it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104576/107000 [02:25<00:03, 735.83it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104608/107000 [02:25<00:03, 735.83it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104640/107000 [02:25<00:03, 745.68it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104640/107000 [02:25<00:03, 745.68it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104672/107000 [02:25<00:03, 745.68it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104704/107000 [02:25<00:03, 745.68it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104736/107000 [02:25<00:03, 741.35it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104736/107000 [02:25<00:03, 741.35it/s, train_loss=0.678]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104768/107000 [02:25<00:03, 741.35it/s, train_loss=0.678]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104800/107000 [02:25<00:02, 741.35it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104832/107000 [02:25<00:02, 730.25it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104832/107000 [02:25<00:02, 730.25it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104864/107000 [02:25<00:02, 730.25it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104896/107000 [02:25<00:02, 730.25it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104928/107000 [02:25<00:02, 722.89it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104928/107000 [02:25<00:02, 722.89it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104960/107000 [02:25<00:02, 722.89it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 104992/107000 [02:25<00:02, 722.89it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 105024/107000 [02:25<00:02, 697.64it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 105024/107000 [02:25<00:02, 697.64it/s, train_loss=0.676]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 105056/107000 [02:25<00:02, 697.64it/s, train_loss=0.676]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 105088/107000 [02:25<00:02, 697.64it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 105120/107000 [02:25<00:02, 682.01it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 105120/107000 [02:25<00:02, 682.01it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 105152/107000 [02:25<00:02, 682.01it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 105184/107000 [02:25<00:02, 682.01it/s, train_loss=0.678]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 105216/107000 [02:25<00:02, 698.14it/s, train_loss=0.678]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 105216/107000 [02:26<00:02, 698.14it/s, train_loss=0.678]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 105248/107000 [02:26<00:02, 698.14it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 105280/107000 [02:26<00:02, 698.14it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 105312/107000 [02:26<00:02, 696.70it/s, train_loss=0.677]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 105312/107000 [02:26<00:02, 696.70it/s, train_loss=0.678]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 105344/107000 [02:26<00:02, 696.70it/s, train_loss=0.678]\u001b[A\n",
            "Epoch 1:  98%|█████████▊| 105376/107000 [02:26<00:02, 696.70it/s, train_loss=0.678]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 105408/107000 [02:26<00:02, 702.42it/s, train_loss=0.678]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 105408/107000 [02:26<00:02, 702.42it/s, train_loss=0.679]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 105440/107000 [02:26<00:02, 702.42it/s, train_loss=0.679]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 105472/107000 [02:26<00:02, 702.42it/s, train_loss=0.679]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 105504/107000 [02:26<00:02, 710.12it/s, train_loss=0.679]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 105504/107000 [02:26<00:02, 710.12it/s, train_loss=0.679]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 105536/107000 [02:26<00:02, 710.12it/s, train_loss=0.68] \u001b[A\n",
            "Epoch 1:  99%|█████████▊| 105568/107000 [02:26<00:02, 710.12it/s, train_loss=0.68]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 105600/107000 [02:26<00:01, 713.74it/s, train_loss=0.68]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 105600/107000 [02:26<00:01, 713.74it/s, train_loss=0.68]\u001b[A\n",
            "Epoch 1:  99%|█████████▊| 105632/107000 [02:26<00:01, 713.74it/s, train_loss=0.68]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 105664/107000 [02:26<00:01, 713.74it/s, train_loss=0.68]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 105696/107000 [02:26<00:01, 716.21it/s, train_loss=0.68]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 105696/107000 [02:26<00:01, 716.21it/s, train_loss=0.68]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 105728/107000 [02:26<00:01, 716.21it/s, train_loss=0.68]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 105760/107000 [02:26<00:01, 716.21it/s, train_loss=0.68]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 105792/107000 [02:26<00:01, 715.17it/s, train_loss=0.68]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 105792/107000 [02:26<00:01, 715.17it/s, train_loss=0.68]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 105824/107000 [02:26<00:01, 715.17it/s, train_loss=0.68]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 105856/107000 [02:26<00:01, 715.17it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 105888/107000 [02:26<00:01, 722.32it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 105888/107000 [02:26<00:01, 722.32it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 105920/107000 [02:26<00:01, 722.32it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 105952/107000 [02:27<00:01, 722.32it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 105984/107000 [02:27<00:01, 713.40it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 105984/107000 [02:27<00:01, 713.40it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 106016/107000 [02:27<00:01, 713.40it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 106048/107000 [02:27<00:01, 713.40it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 106080/107000 [02:27<00:01, 717.53it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 106080/107000 [02:27<00:01, 717.53it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 106112/107000 [02:27<00:01, 717.53it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 106144/107000 [02:27<00:01, 717.53it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 106176/107000 [02:27<00:01, 721.76it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 106176/107000 [02:27<00:01, 721.76it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 106208/107000 [02:27<00:01, 721.76it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 106240/107000 [02:27<00:01, 721.76it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 106272/107000 [02:27<00:01, 716.61it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 106272/107000 [02:27<00:01, 716.61it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 106304/107000 [02:27<00:00, 716.61it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 106336/107000 [02:27<00:00, 716.61it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 106368/107000 [02:27<00:00, 716.32it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 106368/107000 [02:27<00:00, 716.32it/s, train_loss=0.682]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 106400/107000 [02:27<00:00, 716.32it/s, train_loss=0.681]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 106432/107000 [02:27<00:00, 716.32it/s, train_loss=0.682]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 106464/107000 [02:27<00:00, 716.42it/s, train_loss=0.682]\u001b[A\n",
            "Epoch 1:  99%|█████████▉| 106464/107000 [02:27<00:00, 716.42it/s, train_loss=0.682]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 106496/107000 [02:27<00:00, 716.42it/s, train_loss=0.682]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 106528/107000 [02:27<00:00, 716.42it/s, train_loss=0.682]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 106560/107000 [02:27<00:00, 724.13it/s, train_loss=0.682]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 106560/107000 [02:27<00:00, 724.13it/s, train_loss=0.682]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 106592/107000 [02:27<00:00, 724.13it/s, train_loss=0.682]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 106624/107000 [02:27<00:00, 724.13it/s, train_loss=0.682]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 106656/107000 [02:27<00:00, 715.98it/s, train_loss=0.682]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 106656/107000 [02:28<00:00, 715.98it/s, train_loss=0.682]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 106688/107000 [02:28<00:00, 715.98it/s, train_loss=0.683]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 106720/107000 [02:28<00:00, 715.98it/s, train_loss=0.683]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 106752/107000 [02:28<00:00, 717.43it/s, train_loss=0.683]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 106752/107000 [02:28<00:00, 717.43it/s, train_loss=0.683]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 106784/107000 [02:28<00:00, 717.43it/s, train_loss=0.684]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 106816/107000 [02:28<00:00, 717.43it/s, train_loss=0.684]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 106848/107000 [02:28<00:00, 723.08it/s, train_loss=0.684]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 106848/107000 [02:28<00:00, 723.08it/s, train_loss=0.685]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 106880/107000 [02:28<00:00, 723.08it/s, train_loss=0.685]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 106912/107000 [02:28<00:00, 723.08it/s, train_loss=0.685]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 106944/107000 [02:28<00:00, 715.13it/s, train_loss=0.685]\u001b[A\n",
            "Epoch 1: 100%|█████████▉| 106944/107000 [02:28<00:00, 715.13it/s, train_loss=0.685]\u001b[A\n",
            "Epoch 1: 107008it [02:28, 720.76it/s, train_loss=0.685]                            \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Losses: train - 0.649, test - 0.909\n",
            "F1 test - 0.662\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  32%|███▏      | 33728/107000 [00:43<01:32, 792.82it/s, train_loss=0.616]"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-dd418928d620>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "losses = []\n",
        "best_test_loss = 10.\n",
        "\n",
        "test_f1 = []\n",
        "\n",
        "for n_epoch in range(epochs):\n",
        "\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    test_targets = []\n",
        "    test_pred_class = []\n",
        "\n",
        "    progress_bar = tqdm(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for x, y in train_loader:\n",
        "\n",
        "        x = x.transpose(0, 1).to(device)\n",
        "        y = y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        pred = model(x)\n",
        "        loss = criterion(pred, y)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        train_losses.append(loss.item())\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
        "\n",
        "        progress_bar.update(x.shape[0])\n",
        "\n",
        "    progress_bar.close()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    for x, y in validation_loader:\n",
        "\n",
        "        x = x.transpose(0, 1).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            pred = model(x)\n",
        "\n",
        "            pred = pred.cpu()\n",
        "\n",
        "            test_targets.append(y.numpy())\n",
        "            test_pred_class.append(np.argmax(pred, axis=1))\n",
        "\n",
        "            loss = criterion(pred, y)\n",
        "\n",
        "            test_losses.append(loss.item())\n",
        "\n",
        "    mean_test_loss = np.mean(test_losses)\n",
        "\n",
        "    test_targets = np.concatenate(test_targets).squeeze()\n",
        "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
        "\n",
        "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
        "\n",
        "    test_f1.append(f1)\n",
        "\n",
        "    print()\n",
        "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
        "\n",
        "    print('F1 test - {:.3f}'.format(f1))\n",
        "\n",
        "    # Early stopping:\n",
        "    if mean_test_loss < best_test_loss:\n",
        "        best_test_loss = mean_test_loss\n",
        "    else:\n",
        "        print('Early stopping')\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TMaPbh3oWwc"
      },
      "source": [
        "Если вы запускаете много раз колаб окна и ткдм начинает беситься, можно запустить окно ниже, ткдм обновится и все снова станет хорошо"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "_aPjTQcR0vm2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03b7c01f-4a1d-47ab-c7af-de09e90dd96d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rEpoch 1:   2%|▏         | 5344/214001 [13:30<8:47:24,  6.59it/s, train_loss=0.713]\n"
          ]
        }
      ],
      "source": [
        "for instance in list(tqdm._instances):\n",
        "    tqdm._decr_instances(instance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHd-hVZNFEvq"
      },
      "source": [
        "# Оценка\n",
        "1. Добрались сюда - очень хорошо - получилась такая же точность или около того - 7 баллов.\n",
        "2. Поставили эксперименты и повысили точность относительно своей и не ниже F1 test - 0.841 - 8 баллов.\n",
        "3. Запустили бертовую тетрадку и разобрались. Получился сравнимый результат - 10 баллов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5BgHdtW2sO3"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}